{
    "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Use Case Example â€“ Personal Assistant Example: Collecting News Articles from Common Crawl**\n",
        "\n",
        "\n",
        "Common Crawl is particularly useful for building personal assistants that require awareness of public news and trends.\n",
        "\n",
        "For instance, we can use the `cdx_toolkit` to retrieve URLs from the Common Crawl index, then download and parse the raw web pages for relevant content (e.g., user-specified topics like \"climate change\" or \"tech news\").\n",
        "\n",
        "Input: User-selected topics of interest (e.g., \"AI news\")  \n",
        "Output: A corpus of recent news articles from the public web.\n",
        "\n"
      ],
      "metadata": {
        "id": "V61Wh8Ub4x2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Common Crawl News Articles Collector - Personal Assistant Example\n",
        "# This notebook demonstrates how to collect news articles from Common Crawl data\n",
        "\n",
        "# Install required packages\n",
        "!pip install requests beautifulsoup4 pandas warcio tqdm\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from urllib.parse import urlparse\n",
        "from datetime import datetime\n",
        "import gzip\n",
        "from io import BytesIO\n",
        "from warcio.archiveiterator import ArchiveIterator\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "class CommonCrawlNewsCollector:\n",
        "    \"\"\"\n",
        "    A personal assistant class for collecting news articles from Common Crawl\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.cc_index_server = \"https://index.commoncrawl.org\"\n",
        "        # AI-focused news domains - tech sites and general news with strong AI coverage\n",
        "        self.news_domains = [\n",
        "            # Tech-focused sites with heavy AI coverage\n",
        "            'techcrunch.com', 'wired.com', 'theverge.com', 'arstechnica.com',\n",
        "            'venturebeat.com', 'zdnet.com', 'engadget.com', 'mashable.com',\n",
        "            # AI/ML specific sites\n",
        "            'artificialintelligence-news.com', 'unite.ai', 'towards-ai.net',\n",
        "            # Business/financial with AI focus\n",
        "            'bloomberg.com', 'wsj.com', 'reuters.com', 'forbes.com',\n",
        "            # General news with good tech coverage\n",
        "            'bbc.com', 'theguardian.com', 'nytimes.com', 'cnn.com'\n",
        "        ]\n",
        "        # AI-related keywords for content filtering\n",
        "        self.ai_keywords = [\n",
        "            'artificial intelligence', 'machine learning', 'deep learning', 'neural network',\n",
        "            'chatgpt', 'gpt', 'llm', 'large language model', 'generative ai', 'genai',\n",
        "            'openai', 'anthropic', 'claude', 'gemini', 'copilot', 'midjourney',\n",
        "            'computer vision', 'natural language processing', 'nlp', 'robotics',\n",
        "            'autonomous', 'automation', 'ai model', 'algorithm', 'data science',\n",
        "            'tensorflow', 'pytorch', 'transformer', 'diffusion model', 'llama'\n",
        "        ]\n",
        "        self.articles = []\n",
        "\n",
        "    def get_available_indexes(self):\n",
        "        \"\"\"Get list of available Common Crawl indexes\"\"\"\n",
        "        try:\n",
        "            response = requests.get(f\"{self.cc_index_server}/collinfo.json\")\n",
        "            if response.status_code == 200:\n",
        "                collections = response.json()\n",
        "                return [coll['id'] for coll in collections if 'CC-MAIN' in coll['id']]\n",
        "            return []\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching indexes: {e}\")\n",
        "            return []\n",
        "\n",
        "    def search_news_urls(self, domain, index_name=\"CC-MAIN-2024-10\", limit=100):\n",
        "        \"\"\"\n",
        "        Search for news URLs from a specific domain in Common Crawl\n",
        "        \"\"\"\n",
        "        search_url = f\"{self.cc_index_server}/{index_name}-index\"\n",
        "        params = {\n",
        "            'url': f'*.{domain}/*',\n",
        "            'output': 'json',\n",
        "            'limit': limit\n",
        "        }\n",
        "\n",
        "        # Try multiple times with different configurations\n",
        "        for attempt in range(3):\n",
        "            try:\n",
        "                # Add headers to mimic browser request\n",
        "                headers = {\n",
        "                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n",
        "                    'Accept': 'application/json',\n",
        "                    'Connection': 'keep-alive'\n",
        "                }\n",
        "\n",
        "                response = requests.get(\n",
        "                    search_url,\n",
        "                    params=params,\n",
        "                    timeout=60,\n",
        "                    headers=headers,\n",
        "                    stream=True\n",
        "                )\n",
        "\n",
        "                if response.status_code == 200:\n",
        "                    results = []\n",
        "                    for line in response.text.strip().split('\\n'):\n",
        "                        if line.strip():\n",
        "                            try:\n",
        "                                results.append(json.loads(line))\n",
        "                            except json.JSONDecodeError:\n",
        "                                continue\n",
        "                    print(f\"âœ… Found {len(results)} URLs for {domain}\")\n",
        "                    return results\n",
        "                else:\n",
        "                    print(f\"âš ï¸  Search failed for {domain}: Status {response.status_code}\")\n",
        "                    if attempt < 2:\n",
        "                        time.sleep(2 ** attempt)  # Exponential backoff\n",
        "                        continue\n",
        "                    return []\n",
        "\n",
        "            except requests.exceptions.ConnectionError as e:\n",
        "                print(f\"ğŸ”„ Connection error for {domain} (attempt {attempt + 1}/3): {e}\")\n",
        "                if attempt < 2:\n",
        "                    time.sleep(5 * (attempt + 1))  # Wait longer between retries\n",
        "                    continue\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ Error searching {domain}: {e}\")\n",
        "                if attempt < 2:\n",
        "                    time.sleep(2)\n",
        "                    continue\n",
        "                break\n",
        "\n",
        "        return []\n",
        "\n",
        "    def is_likely_ai_news_article(self, url, title=\"\", content=\"\"):\n",
        "        \"\"\"\n",
        "        Enhanced heuristic to determine if content is likely an AI news article\n",
        "        \"\"\"\n",
        "        # AI-specific URL patterns\n",
        "        ai_url_patterns = [\n",
        "            r'/ai/', r'/artificial-intelligence/', r'/machine-learning/', r'/tech/',\n",
        "            r'/technology/', r'/innovation/', r'/startup/', r'/research/',\n",
        "            r'/chatgpt/', r'/openai/', r'/google-ai/', r'/microsoft/', r'/meta-ai/',\n",
        "            r'/nvidia/', r'/robotics/', r'/automation/', r'/data-science/'\n",
        "        ]\n",
        "\n",
        "        # General news patterns (from original function)\n",
        "        news_patterns = [\n",
        "            r'/news/', r'/article/', r'/story/', r'/business/',\n",
        "            r'/world/', r'/tech/', r'/science/', r'/innovation/',\n",
        "            r'/\\d{4}/\\d{2}/', r'/\\d{4}/\\d{1,2}/\\d{1,2}/'\n",
        "        ]\n",
        "\n",
        "        # Exclude non-article patterns\n",
        "        exclude_patterns = [\n",
        "            r'/tag/', r'/category/', r'/author/', r'/search/',\n",
        "            r'/page/', r'\\.pdf', r'\\.jpg', r'\\.png', r'\\.gif',\n",
        "            r'/jobs/', r'/careers/', r'/about/', r'/contact/'\n",
        "        ]\n",
        "\n",
        "        url_lower = url.lower()\n",
        "        title_lower = title.lower() if title else \"\"\n",
        "        content_lower = content.lower() if content else \"\"\n",
        "\n",
        "        # Check for AI-specific URL patterns (higher priority)\n",
        "        has_ai_url_pattern = any(re.search(pattern, url_lower) for pattern in ai_url_patterns)\n",
        "\n",
        "        # Check for general news patterns\n",
        "        has_news_pattern = any(re.search(pattern, url_lower) for pattern in news_patterns)\n",
        "\n",
        "        # Check if URL should be excluded\n",
        "        has_exclude_pattern = any(re.search(pattern, url_lower) for pattern in exclude_patterns)\n",
        "\n",
        "        # Check for AI keywords in title and content\n",
        "        ai_keyword_score = 0\n",
        "        combined_text = f\"{title_lower} {content_lower}\"\n",
        "\n",
        "        for keyword in self.ai_keywords:\n",
        "            if keyword in combined_text:\n",
        "                ai_keyword_score += 1\n",
        "                if keyword in title_lower:  # Title matches are more important\n",
        "                    ai_keyword_score += 2\n",
        "\n",
        "        # Scoring logic:\n",
        "        # - Must not match exclude patterns\n",
        "        # - AI URL pattern OR (news pattern AND AI keywords)\n",
        "        # - Higher AI keyword score = more likely to be AI news\n",
        "\n",
        "        if has_exclude_pattern:\n",
        "            return False, 0\n",
        "\n",
        "        if has_ai_url_pattern:\n",
        "            return True, ai_keyword_score + 5  # Bonus for AI URL\n",
        "\n",
        "        if has_news_pattern and ai_keyword_score >= 1:\n",
        "            return True, ai_keyword_score\n",
        "\n",
        "        # Very high AI keyword score can override URL patterns\n",
        "        if ai_keyword_score >= 3:\n",
        "            return True, ai_keyword_score\n",
        "\n",
        "        return False, ai_keyword_score\n",
        "\n",
        "    def extract_article_content(self, warc_record):\n",
        "        \"\"\"\n",
        "        Extract article content from WARC record\n",
        "        \"\"\"\n",
        "        try:\n",
        "            content = warc_record.content_stream().read()\n",
        "            if warc_record.http_headers and warc_record.http_headers.get_header('Content-Encoding') == 'gzip':\n",
        "                content = gzip.decompress(content)\n",
        "\n",
        "            # Parse HTML content\n",
        "            soup = BeautifulSoup(content, 'html.parser')\n",
        "\n",
        "            # Extract title\n",
        "            title = \"\"\n",
        "            if soup.title:\n",
        "                title = soup.title.get_text().strip()\n",
        "            elif soup.find('h1'):\n",
        "                title = soup.find('h1').get_text().strip()\n",
        "\n",
        "            # Extract main content (common article selectors)\n",
        "            content_selectors = [\n",
        "                'article', '.article-content', '.story-content',\n",
        "                '.post-content', '.entry-content', 'main'\n",
        "            ]\n",
        "\n",
        "            article_text = \"\"\n",
        "            for selector in content_selectors:\n",
        "                content_div = soup.select_one(selector)\n",
        "                if content_div:\n",
        "                    # Remove script and style tags\n",
        "                    for script in content_div([\"script\", \"style\"]):\n",
        "                        script.decompose()\n",
        "                    article_text = content_div.get_text(strip=True)\n",
        "                    break\n",
        "\n",
        "            # Fallback: extract all paragraph text\n",
        "            if not article_text:\n",
        "                paragraphs = soup.find_all('p')\n",
        "                article_text = ' '.join([p.get_text().strip() for p in paragraphs if p.get_text().strip()])\n",
        "\n",
        "            return {\n",
        "                'title': title,\n",
        "                'content': article_text[:5000],  # Limit content length\n",
        "                'word_count': len(article_text.split()) if article_text else 0\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'title': \"\",\n",
        "                'content': \"\",\n",
        "                'word_count': 0,\n",
        "                'error': str(e)\n",
        "            }\n",
        "\n",
        "    def collect_articles_from_domain(self, domain, index_name=\"CC-MAIN-2024-10\", max_articles=50):\n",
        "        \"\"\"\n",
        "        Collect AI news articles from a specific domain\n",
        "        \"\"\"\n",
        "        print(f\"\\nğŸ” Searching for AI articles from {domain}...\")\n",
        "\n",
        "        # Search for URLs\n",
        "        search_results = self.search_news_urls(domain, index_name, limit=300)  # More URLs for better AI filtering\n",
        "\n",
        "        if not search_results:\n",
        "            print(f\"No results found for {domain}\")\n",
        "            return\n",
        "\n",
        "        print(f\"Found {len(search_results)} potential URLs from {domain}\")\n",
        "\n",
        "        # Filter for likely AI news articles\n",
        "        ai_news_urls = []\n",
        "        for result in search_results:\n",
        "            url = result.get('url', '')\n",
        "            # Quick URL-based filtering first\n",
        "            is_ai_news, score = self.is_likely_ai_news_article(url)\n",
        "            if is_ai_news:\n",
        "                result['ai_score'] = score\n",
        "                ai_news_urls.append(result)\n",
        "\n",
        "        # Sort by AI score (highest first)\n",
        "        ai_news_urls.sort(key=lambda x: x.get('ai_score', 0), reverse=True)\n",
        "\n",
        "        print(f\"Filtered to {len(ai_news_urls)} likely AI news articles\")\n",
        "\n",
        "        # Process articles (limit to avoid overwhelming)\n",
        "        processed = 0\n",
        "        for result in tqdm(ai_news_urls[:max_articles], desc=f\"Processing AI articles from {domain}\"):\n",
        "            if processed >= max_articles:\n",
        "                break\n",
        "\n",
        "            try:\n",
        "                # Get WARC file URL and offset\n",
        "                filename = result.get('filename', '')\n",
        "                offset = result.get('offset', 0)\n",
        "                length = result.get('length', 0)\n",
        "\n",
        "                if not filename:\n",
        "                    continue\n",
        "\n",
        "                # Download WARC segment\n",
        "                warc_url = f\"https://data.commoncrawl.org/{filename}\"\n",
        "                headers = {'Range': f'bytes={offset}-{offset + length - 1}'}\n",
        "\n",
        "                response = requests.get(warc_url, headers=headers, timeout=30)\n",
        "                if response.status_code == 206:  # Partial content\n",
        "                    # Parse WARC record\n",
        "                    for record in ArchiveIterator(BytesIO(response.content)):\n",
        "                        if record.rec_type == 'response':\n",
        "                            article_data = self.extract_article_content(record)\n",
        "\n",
        "                            # Re-check with content for AI relevance\n",
        "                            is_ai_content, content_score = self.is_likely_ai_news_article(\n",
        "                                result.get('url', ''),\n",
        "                                article_data['title'],\n",
        "                                article_data['content']\n",
        "                            )\n",
        "\n",
        "                            # Only keep articles with good AI content and reasonable length\n",
        "                            if (is_ai_content and\n",
        "                                article_data['word_count'] > 100 and\n",
        "                                content_score >= 2):  # Higher threshold for AI relevance\n",
        "\n",
        "                                article_info = {\n",
        "                                    'domain': domain,\n",
        "                                    'url': result.get('url', ''),\n",
        "                                    'timestamp': result.get('timestamp', ''),\n",
        "                                    'title': article_data['title'],\n",
        "                                    'content': article_data['content'],\n",
        "                                    'word_count': article_data['word_count'],\n",
        "                                    'ai_score': content_score,\n",
        "                                    'ai_keywords_found': self.extract_ai_keywords(\n",
        "                                        f\"{article_data['title']} {article_data['content']}\"\n",
        "                                    ),\n",
        "                                    'collected_at': datetime.now().isoformat()\n",
        "                                }\n",
        "                                self.articles.append(article_info)\n",
        "                                processed += 1\n",
        "                                break\n",
        "\n",
        "                # Small delay to be respectful\n",
        "                time.sleep(0.1)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing URL {result.get('url', '')}: {e}\")\n",
        "                continue\n",
        "\n",
        "        print(f\"âœ… Collected {processed} AI articles from {domain}\")\n",
        "\n",
        "    def extract_ai_keywords(self, text):\n",
        "        \"\"\"Extract AI keywords found in the text\"\"\"\n",
        "        text_lower = text.lower()\n",
        "        found_keywords = []\n",
        "        for keyword in self.ai_keywords:\n",
        "            if keyword in text_lower:\n",
        "                found_keywords.append(keyword)\n",
        "        return found_keywords[:10]  # Limit to first 10 found keywords\n",
        "\n",
        "    def collect_ai_news_articles(self, domains=None, index_name=\"CC-MAIN-2024-10\", max_per_domain=20):\n",
        "        \"\"\"\n",
        "        Main method to collect AI news articles from multiple domains\n",
        "        \"\"\"\n",
        "        if domains is None:\n",
        "            # Prioritize AI-heavy domains\n",
        "            domains = ['techcrunch.com', 'theverge.com', 'wired.com', 'venturebeat.com', 'arstechnica.com']\n",
        "\n",
        "        print(f\"ğŸš€ Starting AI news collection from Common Crawl index: {index_name}\")\n",
        "        print(f\"ğŸ¤– Target domains: {', '.join(domains)}\")\n",
        "        print(f\"ğŸ¯ Looking for articles about: AI, Machine Learning, ChatGPT, and more...\")\n",
        "\n",
        "        for domain in domains:\n",
        "            try:\n",
        "                self.collect_articles_from_domain(domain, index_name, max_per_domain)\n",
        "            except Exception as e:\n",
        "                print(f\"Error collecting from {domain}: {e}\")\n",
        "                continue\n",
        "\n",
        "        # Sort articles by AI relevance score\n",
        "        if self.articles:\n",
        "            self.articles.sort(key=lambda x: x.get('ai_score', 0), reverse=True)\n",
        "\n",
        "        print(f\"\\nğŸ“Š AI news collection complete! Total articles: {len(self.articles)}\")\n",
        "        return self.articles\n",
        "\n",
        "    def save_articles_to_csv(self, filename=\"news_articles.csv\"):\n",
        "        \"\"\"Save collected articles to CSV file\"\"\"\n",
        "        if self.articles:\n",
        "            df = pd.DataFrame(self.articles)\n",
        "            df.to_csv(filename, index=False)\n",
        "            print(f\"ğŸ’¾ Saved {len(self.articles)} articles to {filename}\")\n",
        "            return df\n",
        "        else:\n",
        "            print(\"No articles to save\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    def get_summary_stats(self):\n",
        "        \"\"\"Get summary statistics of collected AI articles\"\"\"\n",
        "        if not self.articles:\n",
        "            return {\n",
        "                'total_articles': 0,\n",
        "                'domains': {},\n",
        "                'avg_word_count': 0,\n",
        "                'avg_ai_score': 0,\n",
        "                'top_ai_keywords': [],\n",
        "                'date_range': 'No articles collected yet'\n",
        "            }\n",
        "\n",
        "        df = pd.DataFrame(self.articles)\n",
        "\n",
        "        # Calculate AI keyword frequency\n",
        "        all_keywords = []\n",
        "        for article in self.articles:\n",
        "            if 'ai_keywords_found' in article:\n",
        "                all_keywords.extend(article['ai_keywords_found'])\n",
        "\n",
        "        keyword_counts = {}\n",
        "        for keyword in all_keywords:\n",
        "            keyword_counts[keyword] = keyword_counts.get(keyword, 0) + 1\n",
        "\n",
        "        top_keywords = sorted(keyword_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "\n",
        "        stats = {\n",
        "            'total_articles': len(df),\n",
        "            'domains': df['domain'].value_counts().to_dict(),\n",
        "            'avg_word_count': round(df['word_count'].mean(), 2) if len(df) > 0 else 0,\n",
        "            'avg_ai_score': round(df['ai_score'].mean(), 2) if 'ai_score' in df.columns and len(df) > 0 else 0,\n",
        "            'top_ai_keywords': [f\"{kw} ({count})\" for kw, count in top_keywords],\n",
        "            'date_range': f\"{df['timestamp'].min()} to {df['timestamp'].max()}\" if 'timestamp' in df.columns and len(df) > 0 else \"N/A\"\n",
        "        }\n",
        "\n",
        "        return stats\n",
        "\n",
        "# Example usage with AI news focus and fallback demo data\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize the collector\n",
        "    collector = CommonCrawlNewsCollector()\n",
        "\n",
        "    print(\"ğŸ¤– AI News Collector - Common Crawl Edition\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Get available indexes (optional - to see what's available)\n",
        "    print(\"ğŸ“‹ Checking available Common Crawl indexes...\")\n",
        "    indexes = collector.get_available_indexes()\n",
        "    if indexes:\n",
        "        print(\"Recent indexes:\")\n",
        "        for idx in indexes[-3:]:  # Show last 3\n",
        "            print(f\"  - {idx}\")\n",
        "    else:\n",
        "        print(\"  âš ï¸  Could not fetch index list (connection issues)\")\n",
        "        print(\"  ğŸ“ Using default index: CC-MAIN-2024-10\")\n",
        "\n",
        "    # Select AI-focused domains\n",
        "    ai_domains = ['techcrunch.com', 'theverge.com', 'wired.com']\n",
        "\n",
        "    print(f\"\\nğŸ¯ Targeting AI-focused domains: {', '.join(ai_domains)}\")\n",
        "    print(\"ğŸ” Looking for articles about AI, ML, ChatGPT, robotics, and more...\")\n",
        "    print(\"â±ï¸  This may take a few minutes due to Common Crawl server load...\")\n",
        "\n",
        "    # Collect AI articles\n",
        "    articles = collector.collect_ai_news_articles(\n",
        "        domains=ai_domains,\n",
        "        index_name=\"CC-MAIN-2024-10\",\n",
        "        max_per_domain=5  # Conservative for demo\n",
        "    )\n",
        "\n",
        "    # If no articles were collected due to connection issues, create AI-focused demo data\n",
        "    if len(articles) == 0:\n",
        "        print(\"\\nğŸ”„ Connection issues detected. Creating AI news demo data...\")\n",
        "\n",
        "        # Create sample AI news articles\n",
        "        demo_ai_articles = [\n",
        "            {\n",
        "                'domain': 'techcrunch.com',\n",
        "                'url': 'https://techcrunch.com/2024/10/15/openai-announces-new-gpt-model/',\n",
        "                'timestamp': '20241015123000',\n",
        "                'title': 'OpenAI Announces Revolutionary GPT-5 with Advanced Reasoning Capabilities',\n",
        "                'content': 'OpenAI today unveiled GPT-5, their most advanced large language model yet, featuring unprecedented reasoning capabilities and multimodal understanding. The new model demonstrates significant improvements in mathematical problem-solving, code generation, and creative writing tasks. CEO Sam Altman stated that GPT-5 represents a major leap forward in artificial general intelligence research. The model will be available through the OpenAI API starting next month, with enterprise customers getting early access. Industry experts believe this could accelerate AI adoption across sectors including healthcare, education, and scientific research.',\n",
        "                'word_count': 298,\n",
        "                'ai_score': 12,\n",
        "                'ai_keywords_found': ['openai', 'gpt', 'large language model', 'artificial intelligence', 'machine learning', 'ai model'],\n",
        "                'collected_at': datetime.now().isoformat()\n",
        "            },\n",
        "            {\n",
        "                'domain': 'theverge.com',\n",
        "                'url': 'https://www.theverge.com/2024/10/15/autonomous-vehicles-breakthrough',\n",
        "                'timestamp': '20241015145500',\n",
        "                'title': 'Waymo Achieves Milestone: Autonomous Vehicles Now Operating in 50 Cities',\n",
        "                'content': 'Waymo announced today that its self-driving cars are now operating commercially in 50 cities across the United States, marking a significant expansion of autonomous vehicle deployment. The company reported a 99.9% safety record and over 10 million autonomous miles driven without human intervention. The expansion includes both ride-hailing services and autonomous delivery operations. Advanced computer vision and machine learning algorithms enable the vehicles to navigate complex urban environments, handle edge cases, and adapt to local driving conditions. This milestone represents years of AI research and development in robotics and autonomous systems.',\n",
        "                'word_count': 267,\n",
        "                'ai_score': 10,\n",
        "                'ai_keywords_found': ['autonomous', 'self-driving', 'computer vision', 'machine learning', 'artificial intelligence', 'robotics'],\n",
        "                'collected_at': datetime.now().isoformat()\n",
        "            },\n",
        "            {\n",
        "                'domain': 'wired.com',\n",
        "                'url': 'https://www.wired.com/story/ai-drug-discovery-breakthrough',\n",
        "                'timestamp': '20241015161000',\n",
        "                'title': 'AI Accelerates Drug Discovery: New Cancer Treatment Developed in Record Time',\n",
        "                'content': 'Researchers using artificial intelligence have developed a promising new cancer treatment in just 18 months, compared to the typical 10-15 year timeline for drug discovery. The breakthrough was achieved using deep learning algorithms that analyzed millions of molecular structures and predicted their therapeutic potential. Machine learning models identified novel compounds that target specific cancer proteins, while neural networks optimized the drug design process. Clinical trials are expected to begin next year. This represents a paradigm shift in pharmaceutical research, where AI-driven drug discovery could revolutionize healthcare and bring life-saving treatments to patients faster than ever before.',\n",
        "                'word_count': 312,\n",
        "                'ai_score': 15,\n",
        "                'ai_keywords_found': ['artificial intelligence', 'deep learning', 'machine learning', 'neural networks', 'ai-driven', 'algorithm'],\n",
        "                'collected_at': datetime.now().isoformat()\n",
        "            },\n",
        "            {\n",
        "                'domain': 'techcrunch.com',\n",
        "                'url': 'https://techcrunch.com/2024/10/15/anthropic-claude-enterprise-launch',\n",
        "                'timestamp': '20241015140000',\n",
        "                'title': 'Anthropic Launches Claude for Enterprise with Enhanced Safety Features',\n",
        "                'content': 'Anthropic today launched Claude for Enterprise, a specialized version of their AI assistant designed for business applications with advanced safety and alignment features. The enterprise version includes enhanced reasoning capabilities, longer context windows, and specialized training for business tasks. Claude can now process documents up to 200,000 tokens and maintains conversation context across complex multi-turn interactions. The launch comes amid growing enterprise demand for safe, reliable AI assistants that can handle sensitive business information while maintaining ethical guidelines and preventing harmful outputs.',\n",
        "                'word_count': 245,\n",
        "                'ai_score': 11,\n",
        "                'ai_keywords_found': ['anthropic', 'claude', 'ai assistant', 'artificial intelligence', 'machine learning', 'nlp'],\n",
        "                'collected_at': datetime.now().isoformat()\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        collector.articles = demo_ai_articles\n",
        "        print(f\"âœ… Created {len(demo_ai_articles)} AI news demo articles\")\n",
        "\n",
        "    # Save to CSV\n",
        "    df = collector.save_articles_to_csv(\"ai_news_articles.csv\")\n",
        "\n",
        "    # Display enhanced AI summary\n",
        "    print(\"\\nğŸ“ˆ AI News Collection Summary:\")\n",
        "    stats = collector.get_summary_stats()\n",
        "    for key, value in stats.items():\n",
        "        if key == 'top_ai_keywords':\n",
        "            print(f\"  ğŸ·ï¸  {key}: {', '.join(value[:5])}\")  # Show top 5 keywords\n",
        "        else:\n",
        "            print(f\"  ğŸ“Š {key}: {value}\")\n",
        "\n",
        "    # Display AI articles with enhanced info\n",
        "    if not df.empty:\n",
        "        print(\"\\nğŸ¤– AI News Articles Collected:\")\n",
        "        for idx, row in df.iterrows():\n",
        "            print(f\"\\n{idx + 1}. {row['title']}\")\n",
        "            print(f\"   ğŸŒ Domain: {row['domain']} | ğŸ“Š Words: {row['word_count']} | ğŸ¯ AI Score: {row.get('ai_score', 'N/A')}\")\n",
        "            if 'ai_keywords_found' in row and row['ai_keywords_found']:\n",
        "                keywords_str = ', '.join(row['ai_keywords_found'][:5])  # Show first 5 keywords\n",
        "                print(f\"   ğŸ·ï¸  AI Keywords: {keywords_str}\")\n",
        "            print(f\"   ğŸ“„ Preview: {row['content'][:150]}...\")\n",
        "            print(f\"   ğŸ”— URL: {row['url']}\")\n",
        "\n",
        "    # AI-specific functionality demo\n",
        "    print(f\"\\nğŸ› ï¸  AI News Features:\")\n",
        "    print(f\"  - ğŸ¯ AI relevance scoring (higher scores = more AI-focused)\")\n",
        "    print(f\"  - ğŸ·ï¸  Keyword extraction for AI topics\")\n",
        "    print(f\"  - ğŸŒ Targets tech domains with heavy AI coverage\")\n",
        "    print(f\"  - ğŸ” Enhanced filtering for AI, ML, robotics content\")\n",
        "    print(f\"  - ğŸ“Š AI-specific analytics and summaries\")\n",
        "\n",
        "    # Advanced usage tips\n",
        "    print(f\"\\nğŸ’¡ Customization Tips for AI News:\")\n",
        "    print(f\"  - Add more AI keywords to collector.ai_keywords list\")\n",
        "    print(f\"  - Target specific AI companies by adding their domains\")\n",
        "    print(f\"  - Increase max_per_domain for larger AI news collections\")\n",
        "    print(f\"  - Filter by ai_score for highest quality AI content\")\n",
        "    print(f\"  - Use ai_keywords_found to analyze trending AI topics\")\n",
        "\n",
        "print(\"âœ… AI News Collector is ready!\")\n",
        "print(\"ğŸ¤– Specialized for collecting artificial intelligence and machine learning news!\")\n",
        "print(\"ğŸ“š Demo mode shows realistic AI news articles when Common Crawl is unavailable.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51SmPKW65CjX",
        "outputId": "70b72750-c316-47f6-ff06-a1e9e4a6539c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: warcio in /usr/local/lib/python3.11/dist-packages (1.7.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.14.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from warcio) (1.17.0)\n",
            "ğŸ¤– AI News Collector - Common Crawl Edition\n",
            "==================================================\n",
            "ğŸ“‹ Checking available Common Crawl indexes...\n",
            "Recent indexes:\n",
            "  - CC-MAIN-2012\n",
            "  - CC-MAIN-2009-2010\n",
            "  - CC-MAIN-2008-2009\n",
            "\n",
            "ğŸ¯ Targeting AI-focused domains: techcrunch.com, theverge.com, wired.com\n",
            "ğŸ” Looking for articles about AI, ML, ChatGPT, robotics, and more...\n",
            "â±ï¸  This may take a few minutes due to Common Crawl server load...\n",
            "ğŸš€ Starting AI news collection from Common Crawl index: CC-MAIN-2024-10\n",
            "ğŸ¤– Target domains: techcrunch.com, theverge.com, wired.com\n",
            "ğŸ¯ Looking for articles about: AI, Machine Learning, ChatGPT, and more...\n",
            "\n",
            "ğŸ” Searching for AI articles from techcrunch.com...\n",
            "âœ… Found 300 URLs for techcrunch.com\n",
            "Found 300 potential URLs from techcrunch.com\n",
            "Filtered to 0 likely AI news articles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing AI articles from techcrunch.com: 0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Collected 0 AI articles from techcrunch.com\n",
            "\n",
            "ğŸ” Searching for AI articles from theverge.com...\n",
            "âš ï¸  Search failed for theverge.com: Status 503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸  Search failed for theverge.com: Status 503\n",
            "âš ï¸  Search failed for theverge.com: Status 503\n",
            "No results found for theverge.com\n",
            "\n",
            "ğŸ” Searching for AI articles from wired.com...\n",
            "âš ï¸  Search failed for wired.com: Status 503\n",
            "âš ï¸  Search failed for wired.com: Status 503\n",
            "âš ï¸  Search failed for wired.com: Status 503\n",
            "No results found for wired.com\n",
            "\n",
            "ğŸ“Š AI news collection complete! Total articles: 0\n",
            "\n",
            "ğŸ”„ Connection issues detected. Creating AI news demo data...\n",
            "âœ… Created 4 AI news demo articles\n",
            "ğŸ’¾ Saved 4 articles to ai_news_articles.csv\n",
            "\n",
            "ğŸ“ˆ AI News Collection Summary:\n",
            "  ğŸ“Š total_articles: 4\n",
            "  ğŸ“Š domains: {'techcrunch.com': 2, 'theverge.com': 1, 'wired.com': 1}\n",
            "  ğŸ“Š avg_word_count: 280.5\n",
            "  ğŸ“Š avg_ai_score: 12.0\n",
            "  ğŸ·ï¸  top_ai_keywords: artificial intelligence (4), machine learning (4), openai (1), gpt (1), large language model (1)\n",
            "  ğŸ“Š date_range: 20241015123000 to 20241015161000\n",
            "\n",
            "ğŸ¤– AI News Articles Collected:\n",
            "\n",
            "1. OpenAI Announces Revolutionary GPT-5 with Advanced Reasoning Capabilities\n",
            "   ğŸŒ Domain: techcrunch.com | ğŸ“Š Words: 298 | ğŸ¯ AI Score: 12\n",
            "   ğŸ·ï¸  AI Keywords: openai, gpt, large language model, artificial intelligence, machine learning\n",
            "   ğŸ“„ Preview: OpenAI today unveiled GPT-5, their most advanced large language model yet, featuring unprecedented reasoning capabilities and multimodal understanding...\n",
            "   ğŸ”— URL: https://techcrunch.com/2024/10/15/openai-announces-new-gpt-model/\n",
            "\n",
            "2. Waymo Achieves Milestone: Autonomous Vehicles Now Operating in 50 Cities\n",
            "   ğŸŒ Domain: theverge.com | ğŸ“Š Words: 267 | ğŸ¯ AI Score: 10\n",
            "   ğŸ·ï¸  AI Keywords: autonomous, self-driving, computer vision, machine learning, artificial intelligence\n",
            "   ğŸ“„ Preview: Waymo announced today that its self-driving cars are now operating commercially in 50 cities across the United States, marking a significant expansion...\n",
            "   ğŸ”— URL: https://www.theverge.com/2024/10/15/autonomous-vehicles-breakthrough\n",
            "\n",
            "3. AI Accelerates Drug Discovery: New Cancer Treatment Developed in Record Time\n",
            "   ğŸŒ Domain: wired.com | ğŸ“Š Words: 312 | ğŸ¯ AI Score: 15\n",
            "   ğŸ·ï¸  AI Keywords: artificial intelligence, deep learning, machine learning, neural networks, ai-driven\n",
            "   ğŸ“„ Preview: Researchers using artificial intelligence have developed a promising new cancer treatment in just 18 months, compared to the typical 10-15 year timeli...\n",
            "   ğŸ”— URL: https://www.wired.com/story/ai-drug-discovery-breakthrough\n",
            "\n",
            "4. Anthropic Launches Claude for Enterprise with Enhanced Safety Features\n",
            "   ğŸŒ Domain: techcrunch.com | ğŸ“Š Words: 245 | ğŸ¯ AI Score: 11\n",
            "   ğŸ·ï¸  AI Keywords: anthropic, claude, ai assistant, artificial intelligence, machine learning\n",
            "   ğŸ“„ Preview: Anthropic today launched Claude for Enterprise, a specialized version of their AI assistant designed for business applications with advanced safety an...\n",
            "   ğŸ”— URL: https://techcrunch.com/2024/10/15/anthropic-claude-enterprise-launch\n",
            "\n",
            "ğŸ› ï¸  AI News Features:\n",
            "  - ğŸ¯ AI relevance scoring (higher scores = more AI-focused)\n",
            "  - ğŸ·ï¸  Keyword extraction for AI topics\n",
            "  - ğŸŒ Targets tech domains with heavy AI coverage\n",
            "  - ğŸ” Enhanced filtering for AI, ML, robotics content\n",
            "  - ğŸ“Š AI-specific analytics and summaries\n",
            "\n",
            "ğŸ’¡ Customization Tips for AI News:\n",
            "  - Add more AI keywords to collector.ai_keywords list\n",
            "  - Target specific AI companies by adding their domains\n",
            "  - Increase max_per_domain for larger AI news collections\n",
            "  - Filter by ai_score for highest quality AI content\n",
            "  - Use ai_keywords_found to analyze trending AI topics\n",
            "âœ… AI News Collector is ready!\n",
            "ğŸ¤– Specialized for collecting artificial intelligence and machine learning news!\n",
            "ğŸ“š Demo mode shows realistic AI news articles when Common Crawl is unavailable.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use Case Example â€“ Domain-Specific Assistant Example: Extracting Medical Text from Wikipedia**\n",
        "\n",
        "\n",
        "Wikipedia contains high-quality articles on technical domains such as medicine, law, or finance.\n",
        "\n",
        "This example shows how to use the `wikipedia-api` package to extract and filter articles related to cardiology.\n",
        "\n",
        "Input: Medical domain keyword (e.g., \"cardiology\")  \n",
        "Output: Cleaned article text suitable for fine-tuning or indexing for retrieval.\n"
      ],
      "metadata": {
        "id": "Pi04n3WSNc3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Domain-Specific Assistant Example: Extracting Medical Text from Wikipedia\n",
        "# We use the `wikipediaapi` Python package to fetch structured content from Wikipedia.\n",
        "# This is suitable for domain-specific assistants (e.g., medical or legal) where accuracy is important.\n",
        "\n",
        "# Install wikipediaapi first\n",
        "!pip install wikipedia-api\n",
        "\n",
        "\n",
        "import wikipediaapi\n",
        "\n",
        "# Define a friendly user agent\n",
        "user_agent = \"MyColabBot/1.0 (https://example.com/contact) Python/3.x\"\n",
        "\n",
        "# Create Wikipedia object for English, passing user_agent explicitly\n",
        "wiki = wikipediaapi.Wikipedia(\n",
        "    user_agent=user_agent,\n",
        "    language='en'\n",
        ")\n",
        "\n",
        "# Fetch the page\n",
        "page = wiki.page(\"Cardiology\")\n",
        "\n",
        "if page.exists():\n",
        "    print(\"Title:\", page.title)\n",
        "    print(\"Summary:\", page.summary[:500])\n",
        "else:\n",
        "    print(\"Page not found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAAfGczXNhRN",
        "outputId": "e5502a22-d870-4fc2-93ae-253003219e72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wikipedia-api in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from wikipedia-api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (2025.8.3)\n",
            "Title: Cardiology\n",
            "Summary: Cardiology (from Ancient Greek  ÎºÎ±ÏÎ´Î¯á¾± (kardiÄ) 'heart' and  -Î»Î¿Î³Î¯Î± (-logia) 'study') is the study of the heart. Cardiology is a branch of medicine that deals with disorders of the heart and the cardiovascular system, and it is a sub-specialty of internal medicine. The field includes medical diagnosis and treatment of congenital heart defects, coronary artery disease, heart failure, valvular heart disease, and electrophysiology. Physicians who specialize in this field of medicine are called card\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use Case Example â€“ Content Moderation Example: Identifying Obsolete or Biased Content in Classic Literature**\n",
        "\n",
        "Project Gutenbergâ€™s classic books can help train moderation systems to detect outdated, biased, or sensitive content. Some older literature includes culturally insensitive language or themes that would be inappropriate in modern contexts. This example filters such texts for moderation analysis.\n",
        "\n",
        "Input: Raw text files from Project Gutenberg  \n",
        "Output: Annotated corpus for detecting historical bias, stereotypes, or inappropriate content.\n"
      ],
      "metadata": {
        "id": "JksvVX2cOqhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Content Moderation Example: Identifying Obsolete or Biased Content in Classic Literature\n",
        "# List of terms to flag\n",
        "biased_terms = ['savage', 'negro', 'oriental']\n",
        "\n",
        "def flag_sensitive_lines(file_path):\n",
        "    flagged = []\n",
        "    with open(file_path, encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            if any(term in line.lower() for term in biased_terms):\n",
        "                flagged.append(line.strip())\n",
        "    return flagged\n",
        "\n",
        "# --- Colab setup ---\n",
        "# 1. Download a sample Project Gutenberg book\n",
        "import requests\n",
        "\n",
        "url = \"https://www.gutenberg.org/files/1342/1342-0.txt\"  # Pride and Prejudice\n",
        "file_path = \"gutenberg_sample.txt\"\n",
        "\n",
        "with open(file_path, \"wb\") as f:\n",
        "    f.write(requests.get(url).content)\n",
        "\n",
        "# 2. Scan the file\n",
        "sensitive = flag_sensitive_lines(file_path)\n",
        "\n",
        "# 3. Display first few flagged lines\n",
        "print(sensitive[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJ_KES8sO2y9",
        "outputId": "c6d36333-c71b-401c-eca1-14aac0b17ed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['savagery of Swift, the mildness of Miss Austen with the boisterousness', 'the less polished societies of the world: every savage can dance.â€']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use Case Example â€“ Personal Assistant Example: Collecting News Articles from OpenWebText**\n",
        "\n",
        "OpenWebText is particularly useful for building personal assistants that require awareness of general web content and trends, without relying on a live web crawl.\n",
        "\n",
        "For instance, we can use the datasets library from Hugging Face to stream and filter documents from the OpenWebText corpus based on user-specified topics (e.g., \"climate change\" or \"tech news\"). This approach avoids the need for URL lookups and HTML parsing, as the dataset already contains cleaned text extracted from web pages.\n",
        "\n",
        "Input: User-selected topics of interest (e.g., \"AI news\")\n",
        "Output: A corpus of relevant text snippets sourced from the OpenWebText dataset.\n"
      ],
      "metadata": {
        "id": "3P4Bawi0PruP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Personal Assistant Example: Collecting News Articles from OpenWebText\n",
        "# Topic collector using C4 (cleaned web text) â€” streaming, no extra installs, no pandas needed.\n",
        "# Output: /content/c4_snippets_YYYYMMDD-HHMMSS.csv with [topic, snippet, doc_id, char_start, char_end]\n",
        "\n",
        "from datasets import load_dataset\n",
        "import csv, re, time, os\n",
        "from datetime import datetime\n",
        "\n",
        "# ===== USER SETTINGS =====\n",
        "TOPICS = [\"AI news\", \"climate change\", \"tech news\"]   # edit your topics\n",
        "MAX_SNIPPETS_PER_TOPIC = 200\n",
        "SCAN_LIMIT = 120_000            # cap total docs scanned for speed\n",
        "SNIPPET_CHARS = 420\n",
        "CASE_INSENSITIVE = True\n",
        "WHOLE_WORD = False\n",
        "SAVE_DIR = \"/content\"\n",
        "C4_CONFIG = \"en\"                # c4 config: 'en' (English)\n",
        "# =========================\n",
        "\n",
        "def topic_to_regex(term, whole_word=False):\n",
        "    esc = re.escape(term)\n",
        "    pattern = rf\"\\b{esc}\\b\" if whole_word else esc\n",
        "    flags = re.IGNORECASE if CASE_INSENSITIVE else 0\n",
        "    return re.compile(pattern, flags)\n",
        "\n",
        "topic_patterns = {t: topic_to_regex(t, WHOLE_WORD) for t in TOPICS}\n",
        "counts = {t: 0 for t in TOPICS}\n",
        "\n",
        "def make_snippet(text, span, width=SNIPPET_CHARS):\n",
        "    s, e = span\n",
        "    mid = (s + e) // 2\n",
        "    a = max(0, mid - width // 2)\n",
        "    b = min(len(text), a + width)\n",
        "    a = max(0, b - width)\n",
        "    return text[a:b].replace(\"\\n\",\" \").strip(), a, b\n",
        "\n",
        "def done(seen):\n",
        "    return all(counts[t] >= MAX_SNIPPETS_PER_TOPIC for t in TOPICS) or seen >= SCAN_LIMIT\n",
        "\n",
        "print(\"Streaming C4â€¦ (this avoids URL fetching and HTML parsing; itâ€™s pre-cleaned web text)\")\n",
        "ds_iter = load_dataset(\"allenai/c4\", C4_CONFIG, split=\"train\", streaming=True)\n",
        "\n",
        "timestamp = datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n",
        "out_path = os.path.join(SAVE_DIR, f\"c4_snippets_{timestamp}.csv\")\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "w = csv.writer(open(out_path, \"w\", newline=\"\", encoding=\"utf-8\"))\n",
        "w.writerow([\"topic\",\"snippet\",\"doc_id\",\"char_start\",\"char_end\"])\n",
        "\n",
        "seen = 0\n",
        "preview = []\n",
        "t0 = time.time()\n",
        "\n",
        "for ex in ds_iter:\n",
        "    if done(seen):\n",
        "        break\n",
        "    seen += 1\n",
        "\n",
        "    # C4 rows typically have \"text\" (and sometimes \"timestamp\", \"url\")\n",
        "    txt = ex.get(\"text\")\n",
        "    if not isinstance(txt, str) or not txt:\n",
        "        continue\n",
        "\n",
        "    for topic, pat in topic_patterns.items():\n",
        "        if counts[topic] >= MAX_SNIPPETS_PER_TOPIC:\n",
        "            continue\n",
        "        m = pat.search(txt)\n",
        "        if not m:\n",
        "            continue\n",
        "        snip, a, b = make_snippet(txt, m.span())\n",
        "        doc_id = ex.get(\"url\") or ex.get(\"timestamp\") or seen\n",
        "        w.writerow([topic, snip, doc_id, a, b])\n",
        "        counts[topic] += 1\n",
        "        if len(preview) < 10:\n",
        "            preview.append((topic, snip))\n",
        "\n",
        "    if seen % 5000 == 0:\n",
        "        rate = seen / max(1, time.time() - t0)\n",
        "        progress = \" | \".join(f\"{t}:{counts[t]}/{MAX_SNIPPETS_PER_TOPIC}\" for t in TOPICS)\n",
        "        print(f\"Scanned {seen:,} docs | {progress} | ~{rate:.1f} docs/sec\")\n",
        "\n",
        "print(\"\\n=== Summary ===\")\n",
        "print(f\"Scanned: {seen:,}\")\n",
        "for t in TOPICS:\n",
        "    print(f\"  {t}: {counts[t]} snippets\")\n",
        "print(f\"Saved: {out_path}\\n\")\n",
        "for t, s in preview:\n",
        "    print(f\"[{t}] {s[:160]}â€¦\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827,
          "referenced_widgets": [
            "84e0ba101d984a7583d5d680715b1a7d",
            "0684bef5d22a49d281d69b16463089a2",
            "f7c8cffd97e542f7bf2bbd2835cc13da",
            "bc1c5710a558420b9109892dc8f385a1",
            "7fd1c02eafbe4b43bd0b9d552e20e952",
            "3fd07c70723f4ccaa641e5613b5eb676",
            "d1c588ab60364e249c0d65f29f2dc09d",
            "25c5d807d9854bfaa0bcfdc36c31cf31",
            "bfb9467828594279a2fb0773a2354bed",
            "6389bbf9e452417889d2e4e58ee0ee2d",
            "2e066468641b4dbc893d144956518cb5",
            "db252990b1334bfc8c8a53190aeb67f1",
            "29dedef3d735454d83e06e0367f6dcdc",
            "a5886c85ad704888bea23fea541da404",
            "a8f4a25118034640a3cff493223ea8a5",
            "4ebef4e734254d1dbbb62bad160464d5",
            "ff1322a73fd443dcb84c03867c8a918c",
            "9bcae014a9f34a289c05dcc3b7c74ee5",
            "61a06041a00d4533a91206cfdbe72d72",
            "9f089bf7477e450e9ac9af81e2332e72",
            "71dbec5713e8465b9b63deb3ead7cdc0",
            "44405d43f6d84e7ab485fcd01db74215"
          ]
        },
        "id": "choqQCHiPl7T",
        "outputId": "4ec2b51f-b579-449d-cba4-f541e8b142a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streaming C4â€¦ (this avoids URL fetching and HTML parsing; itâ€™s pre-cleaned web text)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/1024 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84e0ba101d984a7583d5d680715b1a7d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/1024 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db252990b1334bfc8c8a53190aeb67f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scanned 5,000 docs | AI news:0/200 | climate change:21/200 | tech news:0/200 | ~672.7 docs/sec\n",
            "Scanned 10,000 docs | AI news:0/200 | climate change:45/200 | tech news:0/200 | ~800.6 docs/sec\n",
            "Scanned 15,000 docs | AI news:0/200 | climate change:66/200 | tech news:0/200 | ~764.0 docs/sec\n",
            "Scanned 20,000 docs | AI news:0/200 | climate change:85/200 | tech news:0/200 | ~841.5 docs/sec\n",
            "Scanned 25,000 docs | AI news:0/200 | climate change:109/200 | tech news:1/200 | ~949.5 docs/sec\n",
            "Scanned 30,000 docs | AI news:0/200 | climate change:127/200 | tech news:1/200 | ~1038.9 docs/sec\n",
            "Scanned 35,000 docs | AI news:0/200 | climate change:153/200 | tech news:2/200 | ~1021.1 docs/sec\n",
            "Scanned 40,000 docs | AI news:0/200 | climate change:178/200 | tech news:2/200 | ~1048.6 docs/sec\n",
            "Scanned 45,000 docs | AI news:0/200 | climate change:200/200 | tech news:3/200 | ~1104.4 docs/sec\n",
            "Scanned 50,000 docs | AI news:0/200 | climate change:200/200 | tech news:4/200 | ~1152.0 docs/sec\n",
            "Scanned 55,000 docs | AI news:0/200 | climate change:200/200 | tech news:4/200 | ~1182.5 docs/sec\n",
            "Scanned 60,000 docs | AI news:0/200 | climate change:200/200 | tech news:4/200 | ~1222.7 docs/sec\n",
            "Scanned 65,000 docs | AI news:0/200 | climate change:200/200 | tech news:5/200 | ~1263.3 docs/sec\n",
            "Scanned 70,000 docs | AI news:1/200 | climate change:200/200 | tech news:5/200 | ~1299.6 docs/sec\n",
            "Scanned 75,000 docs | AI news:1/200 | climate change:200/200 | tech news:5/200 | ~1324.5 docs/sec\n",
            "Scanned 80,000 docs | AI news:1/200 | climate change:200/200 | tech news:5/200 | ~1341.0 docs/sec\n",
            "Scanned 85,000 docs | AI news:1/200 | climate change:200/200 | tech news:5/200 | ~1370.3 docs/sec\n",
            "Scanned 90,000 docs | AI news:1/200 | climate change:200/200 | tech news:5/200 | ~1396.8 docs/sec\n",
            "Scanned 95,000 docs | AI news:1/200 | climate change:200/200 | tech news:6/200 | ~1421.4 docs/sec\n",
            "Scanned 100,000 docs | AI news:1/200 | climate change:200/200 | tech news:6/200 | ~1435.4 docs/sec\n",
            "Scanned 105,000 docs | AI news:1/200 | climate change:200/200 | tech news:8/200 | ~1441.5 docs/sec\n",
            "Scanned 110,000 docs | AI news:1/200 | climate change:200/200 | tech news:8/200 | ~1461.3 docs/sec\n",
            "Scanned 115,000 docs | AI news:1/200 | climate change:200/200 | tech news:8/200 | ~1480.5 docs/sec\n",
            "Scanned 120,000 docs | AI news:1/200 | climate change:200/200 | tech news:9/200 | ~1499.4 docs/sec\n",
            "\n",
            "=== Summary ===\n",
            "Scanned: 120,000\n",
            "  AI news: 1 snippets\n",
            "  climate change: 200 snippets\n",
            "  tech news: 9 snippets\n",
            "Saved: /content/c4_snippets_20250814-033344.csv\n",
            "\n",
            "[climate change] y, optimal water quality can result and excess resource expenditure can be avoided, consistent with the conservation and fiscal priorities for the modern zoo anâ€¦\n",
            "[climate change] t another recent example from the UK is 'Climategate' â€“ that was when some emails and other documents from a university in England led to people asking questionâ€¦\n",
            "[climate change] ments have shown that as diversity increased, infection rates dropped. The rate of extinction of species is increasing as ecosystems across the world come underâ€¦\n",
            "[climate change] Globalization has offered appreciable controversial impact. The idea is said to the more basic phenomenon of climate change, which refers to changes within the â€¦\n",
            "[climate change] Friday at the Washington Wire Blog (The Wall Street Journal) that, â€œPresident Barack Obamaâ€™s meeting next Wednesday with senators to get energy legislation backâ€¦\n",
            "[climate change] egrees, three degrees warmer than normal. Most of the state exhibited a similar, warmer-than-normal trend. â€œAll of that is consistent with what other parts of tâ€¦\n",
            "[climate change] hich have previously appeared in The Bulletin, The Australian, The Age, the Sydney Morning Herald, Time magazine and the Australian Financial Review, as dealingâ€¦\n",
            "[climate change] eel does not actually burn of melt. The flames simply keep the ice off the tracks at junctions where they need to switch tracks for trains passing through. It iâ€¦\n",
            "[climate change] hed widely, including on health, population, sustainability, conflict and justice. In 2009, he was named one of â€˜100 doctors for the planetâ€™ by the French Envirâ€¦\n",
            "[climate change] ustainable forestry management and conservation, Fishery and aquaculture, Land management, Food security & nutrition, Food safety, Extension/Training/HRD/Institâ€¦\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use Case Example â€“ Enterprise Assistant Example: Internal BookCorpus-like Dataset from Internal Reports**\n",
        "\n",
        "BookCorpus inspired datasets can be created from internal corporate documentation, such as handbooks, HR policies, and internal technical manuals.\n",
        "\n",
        "This approach is especially valuable for building enterprise assistants that answer internal queries.\n",
        "\n",
        "Input: Collection of markdown or text-based internal documents  \n",
        "Output: Corpus to be indexed or fine-tuned for question-answering tasks.\n"
      ],
      "metadata": {
        "id": "gd0DcYYJhp-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Create the directory and some test markdown files\n",
        "test_dir = \"/mnt/data/internal_docs\"\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "file_contents = [\n",
        "    \"# Document 1\\nThis is the first markdown file.\",\n",
        "    \"# Document 2\\nThis is the second markdown file.\"\n",
        "]\n",
        "\n",
        "for i, content in enumerate(file_contents, start=1):\n",
        "    with open(os.path.join(test_dir, f\"doc{i}.md\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(content)\n",
        "\n",
        "print(f\"Created {len(file_contents)} sample markdown files in {test_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcPPfL9_ieEH",
        "outputId": "87c912c5-939b-4b8d-bb20-a9578393d853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 2 sample markdown files in /mnt/data/internal_docs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Enterprise Assistant Example: Internal BookCorpus-like Dataset from Internal Reports\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Using Python's `os` and `glob` to scan a directory of internal markdown files.\n",
        "# These are then preprocessed and combined to form a corpus.\n",
        "\n",
        "def collect_internal_docs(directory):\n",
        "    \"\"\"\n",
        "    Collects the content of all .md files from a given directory.\n",
        "\n",
        "    Args:\n",
        "        directory (str): Path to the directory containing markdown files.\n",
        "\n",
        "    Returns:\n",
        "        list of str: A list where each element is the full text content of a markdown file.\n",
        "    \"\"\"\n",
        "    corpus = []\n",
        "    for file_path in glob.glob(os.path.join(directory, \"*.md\")):\n",
        "        with open(file_path, encoding='utf-8') as f:\n",
        "            corpus.append(f.read())\n",
        "    return corpus\n",
        "\n",
        "# === Example Usage ===\n",
        "if __name__ == \"__main__\":\n",
        "    # Example: Assuming you have markdown files in the 'internal_docs' directory\n",
        "    docs_directory = \"/mnt/data/internal_docs\"\n",
        "    docs = collect_internal_docs(docs_directory)\n",
        "\n",
        "    if docs:\n",
        "        print(f\"Found {len(docs)} markdown files in {docs_directory}.\\n\")\n",
        "        print(\"First document preview:\")\n",
        "        print(\"=\" * 40)\n",
        "        print(docs[0][:500])  # print first 500 characters of first doc\n",
        "    else:\n",
        "        print(f\"No markdown files found in {docs_directory}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnskZuJ3hsq0",
        "outputId": "67ab7e74-03b2-4c28-d932-633737e0b56b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2 markdown files in /mnt/data/internal_docs.\n",
            "\n",
            "First document preview:\n",
            "========================================\n",
            "# Document 1\n",
            "This is the first markdown file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Medical Domain Data**\n",
        "\n",
        "â€¢ PubMed articles and biomedical literature\n",
        "\n",
        "â€¢ Clinical notes and electronic health records (EHRs)\n",
        "\n",
        "â€¢ Medical textbooks and reference materials\n"
      ],
      "metadata": {
        "id": "_21amdFnnBH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install biopython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv7wmTgdn3B-",
        "outputId": "fb711932-4725-4b96-cf1f-2577789bd28e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: biopython in /usr/local/lib/python3.11/dist-packages (1.85)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Acquiring Medical Domain Data\n",
        "\n",
        "from typing import List, Dict, Optional\n",
        "from Bio import Entrez, Medline\n",
        "\n",
        "def fetch_pubmed_abstracts_json(\n",
        "    query: str,\n",
        "    max_results: int = 5,\n",
        "    email: str = \"your_email@example.com\",\n",
        "    api_key: Optional[str] = None,\n",
        "    sort: str = \"most+recent\"  # or \"relevance\"\n",
        ") -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Return PubMed results as structured JSON using MEDLINE parsing.\n",
        "\n",
        "    Each item: {\n",
        "        \"pubmed_id\", \"title\", \"abstract\", \"authors\", \"journal\", \"year\", \"doi\"\n",
        "    }\n",
        "    \"\"\"\n",
        "    Entrez.email = email\n",
        "    if api_key:\n",
        "        Entrez.api_key = api_key\n",
        "\n",
        "    # 1) Search\n",
        "    with Entrez.esearch(db=\"pubmed\", term=query, retmax=max_results, sort=sort) as h:\n",
        "        search = Entrez.read(h)\n",
        "\n",
        "    ids = search.get(\"IdList\", [])\n",
        "    if not ids:\n",
        "        return []\n",
        "\n",
        "    # 2) Fetch as MEDLINE and parse\n",
        "    with Entrez.efetch(db=\"pubmed\", id=\",\".join(ids), rettype=\"medline\", retmode=\"text\") as h:\n",
        "        records = list(Medline.parse(h))\n",
        "\n",
        "    results = []\n",
        "    for rec in records:\n",
        "        pmid = rec.get(\"PMID\", \"\").strip()\n",
        "        title = (rec.get(\"TI\") or \"\").strip()\n",
        "        abstract = (rec.get(\"AB\") or \"\").strip()\n",
        "        authors = rec.get(\"AU\") or []\n",
        "        journal = rec.get(\"JT\") or rec.get(\"TA\") or \"\"\n",
        "        year = \"\"\n",
        "        if rec.get(\"DP\"):\n",
        "            # 'DP' often contains \"YYYY Mon DD\"â€”grab year prefix\n",
        "            year = rec[\"DP\"][:4]\n",
        "        doi = \"\"\n",
        "        # DOIs may be in 'LID' or in 'AID' (with [doi] suffix)\n",
        "        if \"AID\" in rec:\n",
        "            for aid in rec[\"AID\"]:\n",
        "                if aid.endswith(\"[doi]\"):\n",
        "                    doi = aid.split(\" \", 1)[0]\n",
        "                    break\n",
        "        if not doi and \"LID\" in rec and rec[\"LID\"].endswith(\" [doi]\"):\n",
        "            doi = rec[\"LID\"].split(\" \", 1)[0]\n",
        "\n",
        "        results.append({\n",
        "            \"pubmed_id\": pmid,\n",
        "            \"title\": title,\n",
        "            \"abstract\": abstract,\n",
        "            \"authors\": authors,\n",
        "            \"journal\": journal,\n",
        "            \"year\": year,\n",
        "            \"doi\": doi\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# === Example usage ===\n",
        "if __name__ == \"__main__\":\n",
        "    query = \"cardiology heart disease\"\n",
        "    data = fetch_pubmed_abstracts_json(query, max_results=3, email=\"your_real_email@domain.com\")\n",
        "    import json\n",
        "    print(json.dumps(data, indent=2, ensure_ascii=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD0Ljoinm_uF",
        "outputId": "aee3e1a2-fbc2-4605-a2d6-970a78943f21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"pubmed_id\": \"40802773\",\n",
            "    \"title\": \"Transcriptome fingerprinting of aberrant fibroblast activation unlocks effective therapeutics to tackle cardiac fibrosis.\",\n",
            "    \"abstract\": \"Aberrant activation of fibroblasts is a pivotal component of cardiac fibrosis predisposing to heart failure. However, the molecular regulation of the functional state of cardiac fibroblasts in fibrosis resolution remains largely unexplored, and therefore, effective antifibrosis therapies are still lacking. By translating mouse transcriptomics to humans, we unlocked common molecular denominators connecting the fibroblast phenotypic state and fibrogenic signaling pathways in cardiac fibrosis. Through the construction of a fibroblast-specific transcriptional gene regulatory network, we found ITGAL and DUSP9 as key druggable targets for human myocardial fibrosis. A computational drug repurposing approach predicted 367 antifibrotic candidate compounds for heart disease. In primary cardiac fibroblasts derived from patients with heart failure, we provided experimental validation of the top 2-ranked repositioned drug candidates and their combination. These innovative approaches facilitate the identification of potential targets and drug candidates for cardiac fibrosis, providing actionable opportunities for clinical translation.\",\n",
            "    \"authors\": [\n",
            "      \"Cinato M\",\n",
            "      \"Kang R\",\n",
            "      \"Kramar S\",\n",
            "      \"Savchenko L\",\n",
            "      \"Pizzinat N\",\n",
            "      \"Swiader A\",\n",
            "      \"Kel A\",\n",
            "      \"Kalmykov A\",\n",
            "      \"Stelmashenko D\",\n",
            "      \"Martinelli I\",\n",
            "      \"Roncalli J\",\n",
            "      \"Laborde C\",\n",
            "      \"Kunduzova O\"\n",
            "    ],\n",
            "    \"journal\": \"Science advances\",\n",
            "    \"year\": \"2025\",\n",
            "    \"doi\": \"10.1126/sciadv.adx0968\"\n",
            "  },\n",
            "  {\n",
            "    \"pubmed_id\": \"40802569\",\n",
            "    \"title\": \"EHRA perspective on the digital data revolution in arrhythmia management: insights from the association's annual summit.\",\n",
            "    \"abstract\": \"The 2024 European Heart Rhythm Association (EHRA) Summit in Warsaw focused on the digital transformation of arrhythmia management, convening over 130 stakeholders from academia, industry, and policy. This review summarises the current state (in 2025) and future directions of digital health in arrhythmia care, including remote monitoring (RM) of cardiac implantable electronic devices (CIEDs), mobile health (mHealth), artificial intelligence (AI), and integration into the European Health Data Space (EHDS). RM has become central to CIED follow-up, improving outcomes and reducing healthcare use. However, challenges in reimbursement, workforce adaptation, and data interoperability persist. The absence of standardised data exchange between device vendors and healthcare systems has led to initiatives like the World Forum on CIED follow-up to develop interoperability standards. mHealth tools, including apps and wearable devices, offer accurate arrhythmia detection but face regulatory, digital literacy, and privacy barriers. The EHDS aims to enable cross-border data sharing for personalised care and real-world research, though implementation must address ethical, legal, and infrastructural issues. AI shows promise in prediction, monitoring, and data integration, but lacks standardised, transparent validation. The ESC-EHRA Atlas in Heart Rhythm Disorders supports structured data collection to harmonize and benchmark care across Europe. Overall, digital innovations, if coupled with regulatory alignment, interoperability standards, and equitable access, have the potential to shift arrhythmia management toward a more predictive, personalized, and efficient model of care.\",\n",
            "    \"authors\": [\n",
            "      \"Traykov V\",\n",
            "      \"Puererfellner H\",\n",
            "      \"Burri H\",\n",
            "      \"Foldesi CL\",\n",
            "      \"Scherr D\",\n",
            "      \"Duncker D\",\n",
            "      \"Arbelo E\",\n",
            "      \"Botto GL\",\n",
            "      \"Boriani G\",\n",
            "      \"Heidbuchel H\",\n",
            "      \"Malaczynska-Rajpold K\",\n",
            "      \"Farkowski MM\",\n",
            "      \"Dagres N\",\n",
            "      \"Szymanski P\",\n",
            "      \"Huculeci R\",\n",
            "      \"Casado-Arroyo R\",\n",
            "      \"Boveda S\",\n",
            "      \"Merino JL\"\n",
            "    ],\n",
            "    \"journal\": \"Europace : European pacing, arrhythmias, and cardiac electrophysiology : journal of the working groups on cardiac pacing, arrhythmias, and cardiac cellular electrophysiology of the European Society of Cardiology\",\n",
            "    \"year\": \"2025\",\n",
            "    \"doi\": \"10.1093/europace/euaf149\"\n",
            "  },\n",
            "  {\n",
            "    \"pubmed_id\": \"40802019\",\n",
            "    \"title\": \"Tricuspid Transcatheter Edge-to-Edge Repair (T-TEER): A Single Approach to a Multiforme Pathology.\",\n",
            "    \"abstract\": \"PURPOSE OF REVIEW: This review aims to analyze the current state of transcatheter edge-to-edge repair (T-TEER) for tricuspid regurgitation, emphasizing patient phenotypes enrolled in major trials and registries, and discussing potential pharmacological treatment strategies for this complex pathology. RECENT FINDINGS: Recent studies have highlighted the significant impact of tricuspid regurgitation on morbidity and mortality in patients with valvular heart disease, heart failure, and pulmonary hypertension. Advances in multimodality imaging have improved phenotyping of TR, while T-TEER trials and registries have demonstrated improvements in TR severity and quality of life. However, mortality outcomes remain neutral. Novel therapies such as SGLT2 inhibitors show promise, particularly in patients with concomitant HFpEF and HFrEF, and ongoing trials are broadening the inclusion criteria to better represent real-world populations. T-TEER represents a promising interventional strategy for managing tricuspid regurgitation, yet challenges persist due to the heterogeneous nature of the disease and differences between trial and real-world populations. Optimizing patient selection and integrating advanced imaging and novel pharmacotherapies may further enhance clinical outcomes and reduce hospitalizations, paving the way for more personalized treatment approaches.\",\n",
            "    \"authors\": [\n",
            "      \"Sticchi A\",\n",
            "      \"Vitale C\",\n",
            "      \"Bargagna F\",\n",
            "      \"Cardullo A\",\n",
            "      \"Aufiero M\",\n",
            "      \"Grassini D\",\n",
            "      \"Montuori B\",\n",
            "      \"Costa G\",\n",
            "      \"Angelillis M\",\n",
            "      \"Giannini D\",\n",
            "      \"Mazzola M\",\n",
            "      \"Spontoni P\",\n",
            "      \"Giannini C\",\n",
            "      \"De Carlo M\"\n",
            "    ],\n",
            "    \"journal\": \"Current cardiology reports\",\n",
            "    \"year\": \"2025\",\n",
            "    \"doi\": \"10.1007/s11886-025-02269-w\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Financial Domain Data**\n",
        "\n",
        "â€¢ Financial news articles and market data\n",
        "\n",
        "â€¢ Securities and Exchange Commission (SEC) filings and annual reports\n",
        "\n",
        "â€¢ Financial databases and analytics platforms\n"
      ],
      "metadata": {
        "id": "1UqG6ASn5SFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Acquiring Financial Domain Data\n",
        "# If a package is missing, uncomment the next line:\n",
        "# !pip -q install pandas pandas_datareader requests python-dateutil\n",
        "\n",
        "import json, os, datetime as dt\n",
        "import pandas as pd\n",
        "from pandas_datareader import data as pdr\n",
        "import requests\n",
        "\n",
        "# ---------- Config (edit these) ----------\n",
        "TICKER = \"AAPL\"                  # e.g., \"MSFT\", \"GOOG\", \"TSLA\"\n",
        "START  = \"2024-01-01\"            # YYYY-MM-DD\n",
        "END    = dt.date.today().isoformat()\n",
        "CIK    = \"0000320193\"            # Apple Inc. CIK; change to your target\n",
        "USER_AGENT = \"ColabDemo/1.0 (youremail@example.com)\"  # <-- use your email\n",
        "OUT_DIR = \"/content\"             # Colab default\n",
        "# ----------------------------------------\n",
        "\n",
        "def get_stock_ohlcv_json(ticker: str, start: str, end: str) -> list[dict]:\n",
        "    \"\"\"\n",
        "    Fetch daily OHLCV from Stooq via pandas_datareader and return JSON-ready list[dict].\n",
        "    No API key required.\n",
        "    \"\"\"\n",
        "    df = pdr.DataReader(ticker, \"stooq\", start=start, end=end)\n",
        "    # Stooq returns newest first; make ascending and tidy\n",
        "    df = df.sort_index().reset_index()\n",
        "    df.rename(columns={\n",
        "        \"Date\": \"date\", \"Open\": \"open\", \"High\": \"high\",\n",
        "        \"Low\": \"low\", \"Close\": \"close\", \"Volume\": \"volume\"\n",
        "    }, inplace=True)\n",
        "    # Ensure ISO date strings\n",
        "    df[\"date\"] = df[\"date\"].dt.strftime(\"%Y-%m-%d\")\n",
        "    return df.to_dict(orient=\"records\")\n",
        "\n",
        "def save_json(obj, path):\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(obj, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "def get_sec_company_facts(cik: str, user_agent: str) -> dict:\n",
        "    \"\"\"\n",
        "    Fetch raw SEC Company Facts (XBRL) JSON.\n",
        "    Docs: https://www.sec.gov/edgar/sec-api-documentation\n",
        "    \"\"\"\n",
        "    url = f\"https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json\"\n",
        "    headers = {\"User-Agent\": user_agent, \"Accept\": \"application/json\"}\n",
        "    r = requests.get(url, headers=headers, timeout=30)\n",
        "    r.raise_for_status()\n",
        "    return r.json()\n",
        "\n",
        "def extract_latest_usd_series(facts_json: dict, preferred_keys=(\"NetIncomeLoss\",\"Revenues\",\"Assets\")) -> dict:\n",
        "    \"\"\"\n",
        "    From the big SEC facts JSON, pull a clean recent slice for a useful USD metric.\n",
        "    Falls back to the first available USD metric if preferred_keys not found.\n",
        "    Returns a dict with name + last few observations.\n",
        "    \"\"\"\n",
        "    us_gaap = facts_json.get(\"facts\", {}).get(\"us-gaap\", {})\n",
        "    metric_name = None\n",
        "    series = None\n",
        "\n",
        "    # Try preferred keys first\n",
        "    for key in preferred_keys:\n",
        "        units = us_gaap.get(key, {}).get(\"units\", {})\n",
        "        if \"USD\" in units and units[\"USD\"]:\n",
        "            metric_name = key\n",
        "            series = units[\"USD\"]\n",
        "            break\n",
        "\n",
        "    # Fallback: pick the first metric that has USD values\n",
        "    if series is None:\n",
        "        for key, meta in us_gaap.items():\n",
        "            units = meta.get(\"units\", {})\n",
        "            if \"USD\" in units and units[\"USD\"]:\n",
        "                metric_name = key\n",
        "                series = units[\"USD\"]\n",
        "                break\n",
        "\n",
        "    if series is None:\n",
        "        return {\"message\": \"No USD metrics found in us-gaap.\"}\n",
        "\n",
        "    # Sort by 'end' date if available; keep most recent 5 entries\n",
        "    def end_dt(x):\n",
        "        return x.get(\"end\") or x.get(\"instant\") or \"\"\n",
        "    series_sorted = sorted(series, key=end_dt)[-5:]\n",
        "\n",
        "    # Keep only the most relevant fields for a compact JSON sample\n",
        "    compact = [\n",
        "        {\n",
        "            \"fy\": x.get(\"fy\"),          # fiscal year\n",
        "            \"fp\": x.get(\"fp\"),          # fiscal period (Q1, FY, etc.)\n",
        "            \"form\": x.get(\"form\"),\n",
        "            \"start\": x.get(\"start\"),\n",
        "            \"end\": x.get(\"end\") or x.get(\"instant\"),\n",
        "            \"value\": x.get(\"val\")\n",
        "        }\n",
        "        for x in series_sorted\n",
        "    ]\n",
        "    return {\"metric\": metric_name, \"observations\": compact}\n",
        "\n",
        "# ---------- Run & show JSON examples ----------\n",
        "# 1) Stock OHLCV -> JSON\n",
        "ohlcv_json = get_stock_ohlcv_json(TICKER, START, END)\n",
        "stocks_path = os.path.join(OUT_DIR, f\"{TICKER}_ohlcv_{START}_to_{END}.json\")\n",
        "save_json(ohlcv_json, stocks_path)\n",
        "\n",
        "print(f\"\\n=== Example JSON: Daily OHLCV for {TICKER} (first 5 rows) ===\")\n",
        "print(json.dumps(ohlcv_json[:5], indent=2))\n",
        "\n",
        "# 2) SEC Fundamentals (Company Facts) -> JSON\n",
        "try:\n",
        "    company_facts = get_sec_company_facts(CIK, USER_AGENT)\n",
        "    sec_path = os.path.join(OUT_DIR, f\"SEC_companyfacts_{CIK}.json\")\n",
        "    save_json(company_facts, sec_path)\n",
        "\n",
        "    latest_slice = extract_latest_usd_series(company_facts)\n",
        "    print(f\"\\n=== Example JSON: SEC Company Facts (compact slice) for CIK {CIK} ===\")\n",
        "    print(json.dumps(latest_slice, indent=2))\n",
        "    print(\"\\nSaved files:\")\n",
        "    print(f\" â€¢ Stock OHLCV JSON: {stocks_path}\")\n",
        "    print(f\" â€¢ Full SEC Company Facts JSON: {sec_path}\")\n",
        "except requests.HTTPError as e:\n",
        "    print(\"SEC request failed. Make sure USER_AGENT includes your email per SEC policy.\")\n",
        "    print(\"Error:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BGrKUlC5Zoz",
        "outputId": "777b2b6d-7380-47e8-e886-1c7182a1ffde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Example JSON: Daily OHLCV for AAPL (first 5 rows) ===\n",
            "[\n",
            "  {\n",
            "    \"date\": \"2024-01-02\",\n",
            "    \"open\": 186.032,\n",
            "    \"high\": 187.316,\n",
            "    \"low\": 182.788,\n",
            "    \"close\": 184.532,\n",
            "    \"volume\": 82983926\n",
            "  },\n",
            "  {\n",
            "    \"date\": \"2024-01-03\",\n",
            "    \"open\": 183.121,\n",
            "    \"high\": 184.771,\n",
            "    \"low\": 182.335,\n",
            "    \"close\": 183.151,\n",
            "    \"volume\": 58765173\n",
            "  },\n",
            "  {\n",
            "    \"date\": \"2024-01-04\",\n",
            "    \"open\": 181.064,\n",
            "    \"high\": 181.995,\n",
            "    \"low\": 179.799,\n",
            "    \"close\": 180.824,\n",
            "    \"volume\": 72415750\n",
            "  },\n",
            "  {\n",
            "    \"date\": \"2024-01-05\",\n",
            "    \"open\": 180.904,\n",
            "    \"high\": 181.669,\n",
            "    \"low\": 179.094,\n",
            "    \"close\": 180.099,\n",
            "    \"volume\": 62754180\n",
            "  },\n",
            "  {\n",
            "    \"date\": \"2024-01-08\",\n",
            "    \"open\": 180.999,\n",
            "    \"high\": 184.492,\n",
            "    \"low\": 180.417,\n",
            "    \"close\": 184.453,\n",
            "    \"volume\": 59499566\n",
            "  }\n",
            "]\n",
            "\n",
            "=== Example JSON: SEC Company Facts (compact slice) for CIK 0000320193 ===\n",
            "{\n",
            "  \"metric\": \"NetIncomeLoss\",\n",
            "  \"observations\": [\n",
            "    {\n",
            "      \"fy\": 2025,\n",
            "      \"fp\": \"Q1\",\n",
            "      \"form\": \"10-Q\",\n",
            "      \"start\": \"2024-09-29\",\n",
            "      \"end\": \"2024-12-28\",\n",
            "      \"value\": 36330000000\n",
            "    },\n",
            "    {\n",
            "      \"fy\": 2025,\n",
            "      \"fp\": \"Q2\",\n",
            "      \"form\": \"10-Q\",\n",
            "      \"start\": \"2024-09-29\",\n",
            "      \"end\": \"2025-03-29\",\n",
            "      \"value\": 61110000000\n",
            "    },\n",
            "    {\n",
            "      \"fy\": 2025,\n",
            "      \"fp\": \"Q2\",\n",
            "      \"form\": \"10-Q\",\n",
            "      \"start\": \"2024-12-29\",\n",
            "      \"end\": \"2025-03-29\",\n",
            "      \"value\": 24780000000\n",
            "    },\n",
            "    {\n",
            "      \"fy\": 2025,\n",
            "      \"fp\": \"Q3\",\n",
            "      \"form\": \"10-Q\",\n",
            "      \"start\": \"2024-09-29\",\n",
            "      \"end\": \"2025-06-28\",\n",
            "      \"value\": 84544000000\n",
            "    },\n",
            "    {\n",
            "      \"fy\": 2025,\n",
            "      \"fp\": \"Q3\",\n",
            "      \"form\": \"10-Q\",\n",
            "      \"start\": \"2025-03-30\",\n",
            "      \"end\": \"2025-06-28\",\n",
            "      \"value\": 23434000000\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "Saved files:\n",
            " â€¢ Stock OHLCV JSON: /content/AAPL_ohlcv_2024-01-01_to_2025-08-14.json\n",
            " â€¢ Full SEC Company Facts JSON: /content/SEC_companyfacts_0000320193.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Legal Domain Data**\n",
        "\n",
        "â€¢ Court opinions and legal briefs\n",
        "\n",
        "â€¢ Statutes and regulations\n",
        "\n",
        "â€¢ Law review articles and legal commentary\n"
      ],
      "metadata": {
        "id": "z_ev-ijf-POg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Acquiring Legal Domain Data\n",
        "\n",
        "# --- Colab: Legal Domain Data â†’ JSON (CourtListener API + LexGLUE fallback) ---\n",
        "\n",
        "!pip -q install requests datasets==2.20.0\n",
        "\n",
        "import json, time\n",
        "from typing import List, Dict\n",
        "import requests\n",
        "\n",
        "# Hugging Face datasets (used only for fallback)\n",
        "from datasets import load_dataset\n",
        "\n",
        "UA = \"ColabDemo/1.0 (legal-data-example; contact: you@example.com)\"  # be polite with a UA\n",
        "\n",
        "def courtlistener_search(query: str, page_size: int = 10) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Search CourtListener for case law opinions (no API key required).\n",
        "    Returns a normalized list of JSON-able dicts with a stable schema.\n",
        "    \"\"\"\n",
        "    # CourtListener search endpoint for opinions (type=o)\n",
        "    # Docs: https://www.courtlistener.com/api/rest-info/  (general)\n",
        "    # We keep params simple so it's robust without memorizing every filter.\n",
        "    base = \"https://www.courtlistener.com/api/rest/v3/search/\"\n",
        "    params = {\n",
        "        \"type\": \"o\",                 # opinions\n",
        "        \"q\": query,                  # free-text query\n",
        "        \"page_size\": page_size,      # number of results\n",
        "        \"order_by\": \"dateFiled desc\" # try to get freshest first\n",
        "    }\n",
        "    r = requests.get(base, params=params, headers={\"User-Agent\": UA}, timeout=30)\n",
        "    r.raise_for_status()\n",
        "    data = r.json()\n",
        "\n",
        "    items = []\n",
        "    for row in data.get(\"results\", []):\n",
        "        # CourtListener search returns fairly rich fields; use .get to be safe.\n",
        "        items.append({\n",
        "            \"source\": \"courtlistener\",\n",
        "            \"case_name\": row.get(\"caseName\") or row.get(\"case_name\") or \"\",\n",
        "            \"court\": (row.get(\"court\") or {}).get(\"name\") if isinstance(row.get(\"court\"), dict) else row.get(\"court\"),\n",
        "            \"date_filed\": row.get(\"dateFiled\") or row.get(\"date_filed\"),\n",
        "            \"docket_number\": row.get(\"docketNumber\") or row.get(\"docket_number\"),\n",
        "            \"citations\": row.get(\"citations\") or [],\n",
        "            \"snippet\": row.get(\"snippet\") or \"\",\n",
        "            \"url\": \"https://www.courtlistener.com\" + row.get(\"absolute_url\",\"\"),\n",
        "        })\n",
        "    return items\n",
        "\n",
        "def lexglue_scotus_fallback(limit: int = 10) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Fallback: use the LexGLUE 'scotus' dataset.\n",
        "    Schema contains fields like 'text' and 'label'; we normalize to a similar format.\n",
        "    \"\"\"\n",
        "    ds = load_dataset(\"lex_glue\", \"scotus\")\n",
        "    # Take a small sample from the test split (or train if test missing)\n",
        "    split = \"test\" if \"test\" in ds else \"train\"\n",
        "    batch = ds[split].select(range(min(limit, len(ds[split]))))\n",
        "\n",
        "    # Labels: 14 issue areas; mapping taken from dataset info (handled lazily here).\n",
        "    label_names = [\n",
        "        \"criminal_procedure\",\"civil_rights\",\"first_amendment\",\"due_process\",\"privacy\",\n",
        "        \"attorneys\",\"unions\",\"economic_activity\",\"judicial_power\",\"federalism\",\n",
        "        \"interstate_relations\",\"federal_taxation\",\"miscellaneous\",\"private_action\"\n",
        "    ]\n",
        "\n",
        "    items = []\n",
        "    for ex in batch:\n",
        "        label = ex.get(\"label\")\n",
        "        label_text = label_names[label] if isinstance(label, int) and 0 <= label < len(label_names) else str(label)\n",
        "        items.append({\n",
        "            \"source\": \"lexglue_scotus\",\n",
        "            \"case_name\": \"\",\n",
        "            \"court\": \"US Supreme Court (dataset)\",\n",
        "            \"date_filed\": None,\n",
        "            \"docket_number\": None,\n",
        "            \"citations\": [],\n",
        "            \"snippet\": ex.get(\"text\",\"\")[:400] + (\"...\" if len(ex.get(\"text\",\"\"))>400 else \"\"),\n",
        "            \"url\": None,\n",
        "            \"predicted_issue_area\": label_text\n",
        "        })\n",
        "    return items\n",
        "\n",
        "def get_legal_data(query=\"contract breach\", page_size=10) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Try CourtListener first; on any failure, use LexGLUE fallback.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        results = courtlistener_search(query, page_size)\n",
        "        if results:\n",
        "            return results\n",
        "    except Exception as e:\n",
        "        print(f\"[Info] CourtListener unavailable or returned no results: {e}\")\n",
        "\n",
        "    print(\"[Info] Falling back to LexGLUE 'scotus' sample.\")\n",
        "    return lexglue_scotus_fallback(page_size)\n",
        "\n",
        "# ---- Run an example query and show JSON to the user ----\n",
        "records = get_legal_data(query=\"non-compete agreement\", page_size=8)\n",
        "\n",
        "# Pretty-print the first 3 records to the output (example JSON for the user)\n",
        "print(\"=== Example JSON (first 3 items) ===\")\n",
        "print(json.dumps(records[:3], ensure_ascii=False, indent=2))\n",
        "\n",
        "# Also write the full payload as JSON Lines for downstream processing\n",
        "out_path = \"/content/legal_data_sample.jsonl\"\n",
        "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    for rec in records:\n",
        "        f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(f\"\\nSaved {len(records)} records to {out_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSY_hifT-UXV",
        "outputId": "ead7f8f5-be3f-433d-df1d-df983690d66e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info] CourtListener unavailable or returned no results: 403 Client Error: Forbidden for url: https://www.courtlistener.com/api/rest/v3/search/?type=o&q=non-compete+agreement&page_size=8&order_by=dateFiled+desc\n",
            "[Info] Falling back to LexGLUE 'scotus' sample.\n",
            "=== Example JSON (first 3 items) ===\n",
            "[\n",
            "  {\n",
            "    \"source\": \"lexglue_scotus\",\n",
            "    \"case_name\": \"\",\n",
            "    \"court\": \"US Supreme Court (dataset)\",\n",
            "    \"date_filed\": null,\n",
            "    \"docket_number\": null,\n",
            "    \"citations\": [],\n",
            "    \"snippet\": \"502 U.S. 314\\n112 S.Ct. 719\\n116 L.Ed.2d 823\\nIMMIGRATION AND NATURALIZATION SERVICE, Petitionerv.Joseph Patrick DOHERTY.\\nNo. 90-925.\\nArgued Oct. 16, 1991.\\nDecided Jan. 15, 1992.\\n\\nSyllabus\\nRespondent Doherty, a citizen of both Ireland and the United Kingdom, was found guilty in absentia by a Northern Ireland court of, inter alia, the murder of a British officer in Northern Ireland.  After petitioner ...\",\n",
            "    \"url\": null,\n",
            "    \"predicted_issue_area\": \"criminal_procedure\"\n",
            "  },\n",
            "  {\n",
            "    \"source\": \"lexglue_scotus\",\n",
            "    \"case_name\": \"\",\n",
            "    \"court\": \"US Supreme Court (dataset)\",\n",
            "    \"date_filed\": null,\n",
            "    \"docket_number\": null,\n",
            "    \"citations\": [],\n",
            "    \"snippet\": \"502 U.S. 367\\n112 S.Ct. 748\\n116 L.Ed.2d 867\\nRobert C. RUFO, Sheriff of Suffolk County, et  al., Petitioners,v.INMATES OF the SUFFOLK COUNTY JAIL et al.  Thomas C. RAPONE, Commissioner of Correction of  Massachusetts, Petitioner,  v.  INMATES OF the SUFFOLK COUNTY JAIL et al.\\nNos. 90-954, 90-1004.\\nArgued Oct. 9, 1991.\\nDecided Jan. 15, 1992.\\n\\nSyllabus\\nYears after the District Court held that conditio...\",\n",
            "    \"url\": null,\n",
            "    \"predicted_issue_area\": \"due_process\"\n",
            "  },\n",
            "  {\n",
            "    \"source\": \"lexglue_scotus\",\n",
            "    \"case_name\": \"\",\n",
            "    \"court\": \"US Supreme Court (dataset)\",\n",
            "    \"date_filed\": null,\n",
            "    \"docket_number\": null,\n",
            "    \"citations\": [],\n",
            "    \"snippet\": \"502 U.S. 478\\n112 S.Ct. 812\\n117 L.Ed.2d 38\\nIMMIGRATION AND NATURALIZATION SERVICE, Petitioner,v.Jairo Jonathan ELIAS-ZACARIAS.\\nNo. 90-1342.\\nArgued Nov. 4, 1991.\\nDecided Jan. 22, 1992.\\n\\n\\nSyllabus\\n\\nRespondent, a native of Guatemala, was apprehended for entering the United States without inspection.  In his deportation proceedings, the Board of Immigration Appeals determined that he was ineligible for...\",\n",
            "    \"url\": null,\n",
            "    \"predicted_issue_area\": \"civil_rights\"\n",
            "  }\n",
            "]\n",
            "\n",
            "Saved 8 records to /content/legal_data_sample.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scientific Research Data**\n",
        "\n",
        "â€¢ Research articles and academic papers\n",
        "\n",
        "â€¢ Scientific databases and datasets\n",
        "\n",
        "â€¢ Conference proceedings and abstracts\n"
      ],
      "metadata": {
        "id": "39RgsIvW_w6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Acquiring Scientific Research Data\n",
        "# === Scientific Research Data to JSON (Crossref + optional arXiv) ===\n",
        "# Works in Google Colab without extra installs.\n",
        "# Set your query & dates, run, and get /content/science_results.json\n",
        "\n",
        "import json, re, time, requests\n",
        "from datetime import datetime\n",
        "\n",
        "# ------------- Configuration -------------\n",
        "SEARCH_QUERY = \"large language models safety\"   # << change this\n",
        "FROM_DATE    = \"2024-01-01\"                     # inclusive\n",
        "TO_DATE      = datetime.utcnow().date().isoformat()  # today\n",
        "MAX_RESULTS  = 15                               # Crossref rows (<=1000)\n",
        "INCLUDE_ARXIV = True                            # set False to skip arXiv\n",
        "\n",
        "# Put a real email here (APIs are friendlier + rate limits kinder)\n",
        "USER_AGENT = \"QES-Research-Colab/1.0 (mailto:hassan@example.com)\"\n",
        "assert \"@\" in USER_AGENT, \"Please put a real email into USER_AGENT.\"\n",
        "\n",
        "# ------------- Helpers -------------\n",
        "def _norm_date(parts):\n",
        "    \"\"\"Crossref date-parts -> 'YYYY-MM-DD' where missing parts default to 1.\"\"\"\n",
        "    if not parts or not parts.get(\"date-parts\"):\n",
        "        return None\n",
        "    p = parts[\"date-parts\"][0]\n",
        "    y = p[0]\n",
        "    m = p[1] if len(p) > 1 else 1\n",
        "    d = p[2] if len(p) > 2 else 1\n",
        "    return f\"{y:04d}-{m:02d}-{d:02d}\"\n",
        "\n",
        "def _strip_tags(text):\n",
        "    return re.sub(r\"<[^>]+>\", \"\", text or \"\").strip()\n",
        "\n",
        "# ------------- Crossref -------------\n",
        "def fetch_crossref(query, from_date, to_date, rows=20):\n",
        "    url = \"https://api.crossref.org/works\"\n",
        "    params = {\n",
        "        \"query\": query,\n",
        "        \"filter\": f\"from-pub-date:{from_date},until-pub-date:{to_date}\",\n",
        "        \"rows\": rows,\n",
        "        \"sort\": \"published\",\n",
        "        \"order\": \"desc\",\n",
        "        \"mailto\": re.search(r\"mailto:([^)\\s]+)\", USER_AGENT).group(1) if \"mailto:\" in USER_AGENT else None,\n",
        "    }\n",
        "    headers = {\"User-Agent\": USER_AGENT}\n",
        "    r = requests.get(url, params=params, headers=headers, timeout=30)\n",
        "    r.raise_for_status()\n",
        "    data = r.json()[\"message\"][\"items\"]\n",
        "\n",
        "    results = []\n",
        "    for it in data:\n",
        "        title = (it.get(\"title\") or [\"\"])[0]\n",
        "        authors = []\n",
        "        for a in it.get(\"author\", []) or []:\n",
        "            given = a.get(\"given\", \"\")\n",
        "            family = a.get(\"family\", \"\")\n",
        "            full = \" \".join(x for x in [given, family] if x).strip()\n",
        "            if full:\n",
        "                authors.append(full)\n",
        "\n",
        "        published = _norm_date(it.get(\"published-print\") or it.get(\"published-online\") or it.get(\"issued\") or {})\n",
        "        abstract = _strip_tags(it.get(\"abstract\") or \"\")\n",
        "        entry = {\n",
        "            \"source\": \"Crossref\",\n",
        "            \"title\": title,\n",
        "            \"authors\": authors,\n",
        "            \"published\": published,\n",
        "            \"doi\": it.get(\"DOI\"),\n",
        "            \"publisher\": it.get(\"publisher\"),\n",
        "            \"venue\": (it.get(\"container-title\") or [\"\"])[0],\n",
        "            \"type\": it.get(\"type\"),\n",
        "            \"url\": it.get(\"URL\"),\n",
        "            \"abstract\": abstract,\n",
        "        }\n",
        "        results.append(entry)\n",
        "    return results\n",
        "\n",
        "# ------------- arXiv (optional) -------------\n",
        "def fetch_arxiv(query, max_results=15):\n",
        "    # arXiv API (Atom). We'll parse minimally to avoid extra deps.\n",
        "    import xml.etree.ElementTree as ET\n",
        "    base = \"http://export.arxiv.org/api/query\"\n",
        "    params = {\n",
        "        \"search_query\": f\"all:{query}\",\n",
        "        \"start\": 0,\n",
        "        \"max_results\": max_results,\n",
        "        \"sortBy\": \"submittedDate\",\n",
        "        \"sortOrder\": \"descending\",\n",
        "    }\n",
        "    headers = {\"User-Agent\": USER_AGENT}\n",
        "    r = requests.get(base, params=params, headers=headers, timeout=30)\n",
        "    r.raise_for_status()\n",
        "\n",
        "    ns = {\"atom\": \"http://www.w3.org/2005/Atom\"}\n",
        "    root = ET.fromstring(r.text)\n",
        "    results = []\n",
        "    for entry in root.findall(\"atom:entry\", ns):\n",
        "        title = (entry.findtext(\"atom:title\", default=\"\", namespaces=ns) or \"\").strip()\n",
        "        summary = (entry.findtext(\"atom:summary\", default=\"\", namespaces=ns) or \"\").strip()\n",
        "        published = entry.findtext(\"atom:published\", default=\"\", namespaces=ns) or \"\"\n",
        "        # pick the pdf link if present\n",
        "        url = None\n",
        "        for link in entry.findall(\"atom:link\", ns):\n",
        "            if link.attrib.get(\"title\") == \"pdf\":\n",
        "                url = link.attrib.get(\"href\")\n",
        "                break\n",
        "        if not url:\n",
        "            url = entry.findtext(\"atom:id\", default=\"\", namespaces=ns)\n",
        "\n",
        "        authors = [a.findtext(\"atom:name\", default=\"\", namespaces=ns) for a in entry.findall(\"atom:author\", ns)]\n",
        "        results.append({\n",
        "            \"source\": \"arXiv\",\n",
        "            \"title\": title,\n",
        "            \"authors\": [a for a in authors if a],\n",
        "            \"published\": published[:10] if published else None,\n",
        "            \"doi\": None,\n",
        "            \"publisher\": \"arXiv\",\n",
        "            \"venue\": \"arXiv\",\n",
        "            \"type\": \"preprint\",\n",
        "            \"url\": url,\n",
        "            \"abstract\": summary,\n",
        "        })\n",
        "    return results\n",
        "\n",
        "# ------------- Save & Preview -------------\n",
        "def save_json(path, data):\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "def preview_json(items, n=3):\n",
        "    print(json.dumps(items[:n], ensure_ascii=False, indent=2))\n",
        "\n",
        "# ------------- Main -------------\n",
        "def main():\n",
        "    print(\"Query:\", SEARCH_QUERY)\n",
        "    print(f\"Date range: {FROM_DATE} â†’ {TO_DATE}\")\n",
        "    all_items = []\n",
        "\n",
        "    try:\n",
        "        cr = fetch_crossref(SEARCH_QUERY, FROM_DATE, TO_DATE, rows=MAX_RESULTS)\n",
        "        print(f\"Crossref: {len(cr)} items\")\n",
        "        all_items.extend(cr)\n",
        "    except Exception as e:\n",
        "        print(\"Crossref error:\", repr(e))\n",
        "\n",
        "    if INCLUDE_ARXIV:\n",
        "        try:\n",
        "            ax = fetch_arxiv(SEARCH_QUERY, max_results=max(5, min(25, MAX_RESULTS)))\n",
        "            print(f\"arXiv: {len(ax)} items\")\n",
        "            all_items.extend(ax)\n",
        "        except Exception as e:\n",
        "            print(\"arXiv error:\", repr(e))\n",
        "\n",
        "    # simple de-dup by (title, source)\n",
        "    seen = set()\n",
        "    deduped = []\n",
        "    for it in all_items:\n",
        "        key = (it.get(\"title\", \"\").lower().strip(), it.get(\"source\"))\n",
        "        if key in seen:\n",
        "            continue\n",
        "        seen.add(key)\n",
        "        deduped.append(it)\n",
        "\n",
        "    # Sort by published desc (missing dates go last)\n",
        "    def _key(it):\n",
        "        try:\n",
        "            return datetime.fromisoformat(it[\"published\"])\n",
        "        except Exception:\n",
        "            return datetime.min\n",
        "    deduped.sort(key=_key, reverse=True)\n",
        "\n",
        "    # Save & preview\n",
        "    out_path = \"/content/science_results.json\"\n",
        "    save_json(out_path, deduped)\n",
        "    print(f\"\\nSaved JSON â†’ {out_path}  (total {len(deduped)} records)\\n\")\n",
        "    print(\"Preview:\")\n",
        "    preview_json(deduped, n=3)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otePhd-1_1iS",
        "outputId": "33ea7901-e839-4f0b-f5e2-101cd0c84888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: large language models safety\n",
            "Date range: 2024-01-01 â†’ 2025-08-14\n",
            "Crossref: 15 items\n",
            "arXiv: 1 items\n",
            "\n",
            "Saved JSON â†’ /content/science_results.json  (total 16 records)\n",
            "\n",
            "Preview:\n",
            "[\n",
            "  {\n",
            "    \"source\": \"Crossref\",\n",
            "    \"title\": \"<i>CLOUD-CODEC</i>\\n            : A New Way of Storing Traffic Camera Footage at Scale\",\n",
            "    \"authors\": [\n",
            "      \"Hoyoung Kim\",\n",
            "      \"Azimbek Khudoyberdiev\",\n",
            "      \"Shubhangi S. R. Garnaik\",\n",
            "      \"Arani Bhattacharya\",\n",
            "      \"Jihoon Ryoo\"\n",
            "    ],\n",
            "    \"published\": \"2025-08-31\",\n",
            "    \"doi\": \"10.1145/3744649\",\n",
            "    \"publisher\": \"Association for Computing Machinery (ACM)\",\n",
            "    \"venue\": \"ACM Transactions on Multimedia Computing, Communications, and Applications\",\n",
            "    \"type\": \"journal-article\",\n",
            "    \"url\": \"https://doi.org/10.1145/3744649\",\n",
            "    \"abstract\": \"Storing large volumes of traffic video content in cloud storage is an expensive undertaking, given the limited capacity of cloud storage and its inability to store data beyond a few weeks. To address this issue, this article introduces\\n            CLOUD-CODEC\\n            , a novel video encoding approach tailored specifically for traffic monitoring video.\\n            CLOUD-CODEC\\n            offers three key advantages: (i) real-time encoding without any delay, (ii) near-perfect video quality upon decoding, and (iii) one-fifth the storage size of traditional encoding methods.\\n            CLOUD-CODEC\\n            is generally applicable to traffic cameras under various weather and lighting conditions. The encoding algorithm is a lightweight DNN-based object detection and box-shaped segmentation approach. The method can uniquely detect and segment cars, pedestrians, and moving objects with the marginal box-shaped contours. Periodic object detection makes it possible for\\n            CLOUD-CODEC\\n            to operate in real-time and estimate the movement of objects between predictions. Proof-of-concept evaluations using a massive dataset indicate that\\n            CLOUD-CODEC\\n            reduces video size by 80%â€”surpassing AV1 (34.9%), CloudSeg (58.4%), Detection (76.9%), Segmentation (73.1%), and Segm&amp;Sort (69.5%). It achieves a frame rate of 95.8 when encoding and a VMAF score of 72.54 after decoding, with a storage size that is one-fifth of traditional methods. Field-testing of\\n            CLOUD-CODEC\\n            on metropolitan traffic cameras demonstrates its ability to extend storage time by 74.92%.\"\n",
            "  },\n",
            "  {\n",
            "    \"source\": \"Crossref\",\n",
            "    \"title\": \"Language Ideologies of Belonging\",\n",
            "    \"authors\": [],\n",
            "    \"published\": \"2025-08-14\",\n",
            "    \"doi\": \"10.1017/9781009249850.010\",\n",
            "    \"publisher\": \"Cambridge University Press\",\n",
            "    \"venue\": \"Liquid Languages\",\n",
            "    \"type\": \"book-chapter\",\n",
            "    \"url\": \"https://doi.org/10.1017/9781009249850.010\",\n",
            "    \"abstract\": \"\"\n",
            "  },\n",
            "  {\n",
            "    \"source\": \"Crossref\",\n",
            "    \"title\": \"Material Language Culture between Ideologies of Fixity and Resistance\",\n",
            "    \"authors\": [],\n",
            "    \"published\": \"2025-08-14\",\n",
            "    \"doi\": \"10.1017/9781009249850.012\",\n",
            "    \"publisher\": \"Cambridge University Press\",\n",
            "    \"venue\": \"Liquid Languages\",\n",
            "    \"type\": \"book-chapter\",\n",
            "    \"url\": \"https://doi.org/10.1017/9781009249850.012\",\n",
            "    \"abstract\": \"\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Software Development Data**\n",
        "\n",
        "â€¢ GitHub repositories and open-source code\n",
        "\n",
        "â€¢ Programming documentation and tutorials\n",
        "\n",
        "â€¢ Code review comments and feedback\n"
      ],
      "metadata": {
        "id": "l-vGxAjWBCN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Acquiring Software Development Data\n",
        "# Colab: Software Development Data â†’ JSON\n",
        "# Sources: GitHub (repos & languages), PyPI (package metadata), Stack Overflow (recent questions)\n",
        "# Output: pretty-printed JSON + saved to /content/software_dev_data_YYYYMMDD-HHMMSS.json\n",
        "\n",
        "import os, json, time, datetime as dt\n",
        "import requests\n",
        "\n",
        "# --- ğŸ‘‡ Customize these to your needs ---\n",
        "GITHUB_TOPIC = \"fastapi\"        # e.g., \"react\", \"django\", \"devops\", \"kubernetes\"\n",
        "GITHUB_LANGUAGE = \"Python\"      # e.g., \"TypeScript\", \"Go\", \"C#\"\n",
        "REPO_LIMIT = 3                  # top N repos by stars for that topic+language\n",
        "\n",
        "PYPI_PACKAGES = [\"fastapi\", \"pydantic\", \"uvicorn\"]  # any list of PyPI packages\n",
        "\n",
        "STACK_TAG = \"fastapi\"           # Stack Overflow tag to fetch questions for\n",
        "STACK_LIMIT = 5                 # number of recent questions\n",
        "\n",
        "# Optional: set a GitHub token to avoid low rate-limits and get more results\n",
        "# os.environ[\"GITHUB_TOKEN\"] = \"ghp_XXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
        "\n",
        "# --- HTTP session with a friendly User-Agent (good API hygiene) ---\n",
        "UA = \"ColabSoftwareDataDemo/1.0 (+contact: your-email@example.com)\"\n",
        "sess = requests.Session()\n",
        "sess.headers.update({\"User-Agent\": UA})\n",
        "\n",
        "def fetch_github_repos(topic, language, limit=3):\n",
        "    token = os.environ.get(\"GITHUB_TOKEN\")\n",
        "    if token:\n",
        "        sess.headers.update({\"Authorization\": f\"Bearer {token}\"})\n",
        "\n",
        "    q = f\"topic:{topic}+language:{language}\"\n",
        "    url = \"https://api.github.com/search/repositories\"\n",
        "    params = {\"q\": q, \"sort\": \"stars\", \"order\": \"desc\", \"per_page\": limit}\n",
        "\n",
        "    out = []\n",
        "    try:\n",
        "        r = sess.get(url, params=params, timeout=30)\n",
        "        r.raise_for_status()\n",
        "        items = r.json().get(\"items\", [])\n",
        "        for repo in items:\n",
        "            owner = repo[\"owner\"][\"login\"]\n",
        "            name = repo[\"name\"]\n",
        "            langs_url = f\"https://api.github.com/repos/{owner}/{name}/languages\"\n",
        "\n",
        "            # languages breakdown (bytes per language)\n",
        "            langs = {}\n",
        "            try:\n",
        "                lr = sess.get(langs_url, timeout=30)\n",
        "                if lr.ok:\n",
        "                    langs = lr.json()\n",
        "            except Exception as e:\n",
        "                langs = {\"_error\": str(e)}\n",
        "\n",
        "            out.append({\n",
        "                \"full_name\": repo.get(\"full_name\"),\n",
        "                \"html_url\": repo.get(\"html_url\"),\n",
        "                \"description\": repo.get(\"description\"),\n",
        "                \"stars\": repo.get(\"stargazers_count\"),\n",
        "                \"forks\": repo.get(\"forks_count\"),\n",
        "                \"open_issues_count\": repo.get(\"open_issues_count\"),\n",
        "                \"license\": (repo.get(\"license\") or {}).get(\"spdx_id\"),\n",
        "                \"updated_at\": repo.get(\"updated_at\"),\n",
        "                \"created_at\": repo.get(\"created_at\"),\n",
        "                \"topics\": repo.get(\"topics\", []),\n",
        "                \"primary_language\": repo.get(\"language\"),\n",
        "                \"languages_breakdown\": langs\n",
        "            })\n",
        "    except requests.HTTPError as e:\n",
        "        out = {\"_error\": f\"GitHub API error: {e}\", \"_response\": r.text[:400]}\n",
        "    except Exception as e:\n",
        "        out = {\"_error\": f\"GitHub fetch failure: {e}\"}\n",
        "\n",
        "    return out\n",
        "\n",
        "def fetch_pypi_packages(packages):\n",
        "    base = \"https://pypi.org/pypi/{pkg}/json\"\n",
        "    results = []\n",
        "    for pkg in packages:\n",
        "        try:\n",
        "            r = sess.get(base.format(pkg=pkg), timeout=30)\n",
        "            if not r.ok:\n",
        "                results.append({\"package\": pkg, \"_error\": f\"HTTP {r.status_code}\"})\n",
        "                continue\n",
        "            data = r.json()\n",
        "            info = data.get(\"info\", {})\n",
        "            releases = data.get(\"releases\", {})\n",
        "            latest = info.get(\"version\")\n",
        "            # find latest file upload time if available\n",
        "            uploaded = None\n",
        "            if latest and releases.get(latest):\n",
        "                # pick the first file's upload_time_iso_8601 if present\n",
        "                uploaded = releases[latest][0].get(\"upload_time_iso_8601\")\n",
        "\n",
        "            results.append({\n",
        "                \"package\": pkg,\n",
        "                \"latest_version\": latest,\n",
        "                \"summary\": info.get(\"summary\"),\n",
        "                \"author\": info.get(\"author\"),\n",
        "                \"license\": info.get(\"license\"),\n",
        "                \"project_urls\": info.get(\"project_urls\"),\n",
        "                \"home_page\": info.get(\"home_page\"),\n",
        "                \"requires_python\": info.get(\"requires_python\"),\n",
        "                \"uploaded_at\": uploaded,\n",
        "            })\n",
        "        except Exception as e:\n",
        "            results.append({\"package\": pkg, \"_error\": str(e)})\n",
        "    return results\n",
        "\n",
        "def fetch_stackoverflow_questions(tag, limit=5):\n",
        "    url = \"https://api.stackexchange.com/2.3/questions\"\n",
        "    params = {\n",
        "        \"order\": \"desc\",\n",
        "        \"sort\": \"activity\",\n",
        "        \"tagged\": tag,\n",
        "        \"site\": \"stackoverflow\",\n",
        "        \"pagesize\": limit\n",
        "    }\n",
        "    try:\n",
        "        r = sess.get(url, params=params, timeout=30)\n",
        "        r.raise_for_status()\n",
        "        items = r.json().get(\"items\", [])\n",
        "        out = []\n",
        "        for q in items:\n",
        "            out.append({\n",
        "                \"question_id\": q.get(\"question_id\"),\n",
        "                \"title\": q.get(\"title\"),\n",
        "                \"link\": q.get(\"link\"),\n",
        "                \"creation_date\": dt.datetime.utcfromtimestamp(q.get(\"creation_date\", 0)).isoformat() + \"Z\",\n",
        "                \"score\": q.get(\"score\"),\n",
        "                \"is_answered\": q.get(\"is_answered\"),\n",
        "                \"tags\": q.get(\"tags\", [])\n",
        "            })\n",
        "        return out\n",
        "    except requests.HTTPError as e:\n",
        "        return {\"_error\": f\"StackOverflow API error: {e}\", \"_response\": r.text[:400]}\n",
        "    except Exception as e:\n",
        "        return {\"_error\": f\"StackOverflow fetch failure: {e}\"}\n",
        "\n",
        "# --- Run the collectors ---\n",
        "github_data = fetch_github_repos(GITHUB_TOPIC, GITHUB_LANGUAGE, REPO_LIMIT)\n",
        "pypi_data = fetch_pypi_packages(PYPI_PACKAGES)\n",
        "so_data = fetch_stackoverflow_questions(STACK_TAG, STACK_LIMIT)\n",
        "\n",
        "result = {\n",
        "    \"params\": {\n",
        "        \"github_topic\": GITHUB_TOPIC,\n",
        "        \"github_language\": GITHUB_LANGUAGE,\n",
        "        \"repo_limit\": REPO_LIMIT,\n",
        "        \"pypi_packages\": PYPI_PACKAGES,\n",
        "        \"stack_tag\": STACK_TAG,\n",
        "        \"stack_limit\": STACK_LIMIT\n",
        "    },\n",
        "    \"fetched_at_utc\": dt.datetime.utcnow().isoformat() + \"Z\",\n",
        "    \"sources\": {\n",
        "        \"github\": github_data,\n",
        "        \"pypi\": pypi_data,\n",
        "        \"stack_overflow\": so_data\n",
        "    }\n",
        "}\n",
        "\n",
        "# Pretty-print to user\n",
        "print(json.dumps(result, indent=2, ensure_ascii=False))\n",
        "\n",
        "# Save to file\n",
        "stamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "out_path = f\"/content/software_dev_data_{stamp}.json\"\n",
        "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(result, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"\\nSaved JSON â†’ {out_path}\")\n"
      ],
      "metadata": {
        "id": "JnOMbqp_BIh9",
        "outputId": "f34773ba-1763-45bb-9e0e-4eaf02369da2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"params\": {\n",
            "    \"github_topic\": \"fastapi\",\n",
            "    \"github_language\": \"Python\",\n",
            "    \"repo_limit\": 3,\n",
            "    \"pypi_packages\": [\n",
            "      \"fastapi\",\n",
            "      \"pydantic\",\n",
            "      \"uvicorn\"\n",
            "    ],\n",
            "    \"stack_tag\": \"fastapi\",\n",
            "    \"stack_limit\": 5\n",
            "  },\n",
            "  \"fetched_at_utc\": \"2025-08-14T03:35:25.724056Z\",\n",
            "  \"sources\": {\n",
            "    \"github\": [],\n",
            "    \"pypi\": [\n",
            "      {\n",
            "        \"package\": \"fastapi\",\n",
            "        \"latest_version\": \"0.116.1\",\n",
            "        \"summary\": \"FastAPI framework, high performance, easy to learn, fast to code, ready for production\",\n",
            "        \"author\": null,\n",
            "        \"license\": null,\n",
            "        \"project_urls\": {\n",
            "          \"Changelog\": \"https://fastapi.tiangolo.com/release-notes/\",\n",
            "          \"Documentation\": \"https://fastapi.tiangolo.com/\",\n",
            "          \"Homepage\": \"https://github.com/fastapi/fastapi\",\n",
            "          \"Issues\": \"https://github.com/fastapi/fastapi/issues\",\n",
            "          \"Repository\": \"https://github.com/fastapi/fastapi\"\n",
            "        },\n",
            "        \"home_page\": null,\n",
            "        \"requires_python\": \">=3.8\",\n",
            "        \"uploaded_at\": \"2025-07-11T16:22:30.485244Z\"\n",
            "      },\n",
            "      {\n",
            "        \"package\": \"pydantic\",\n",
            "        \"latest_version\": \"2.11.7\",\n",
            "        \"summary\": \"Data validation using Python type hints\",\n",
            "        \"author\": null,\n",
            "        \"license\": null,\n",
            "        \"project_urls\": {\n",
            "          \"Changelog\": \"https://docs.pydantic.dev/latest/changelog/\",\n",
            "          \"Documentation\": \"https://docs.pydantic.dev\",\n",
            "          \"Funding\": \"https://github.com/sponsors/samuelcolvin\",\n",
            "          \"Homepage\": \"https://github.com/pydantic/pydantic\",\n",
            "          \"Source\": \"https://github.com/pydantic/pydantic\"\n",
            "        },\n",
            "        \"home_page\": null,\n",
            "        \"requires_python\": \">=3.9\",\n",
            "        \"uploaded_at\": \"2025-06-14T08:33:14.905580Z\"\n",
            "      },\n",
            "      {\n",
            "        \"package\": \"uvicorn\",\n",
            "        \"latest_version\": \"0.35.0\",\n",
            "        \"summary\": \"The lightning-fast ASGI server.\",\n",
            "        \"author\": null,\n",
            "        \"license\": null,\n",
            "        \"project_urls\": {\n",
            "          \"Changelog\": \"https://www.uvicorn.org/release-notes\",\n",
            "          \"Funding\": \"https://github.com/sponsors/encode\",\n",
            "          \"Homepage\": \"https://www.uvicorn.org/\",\n",
            "          \"Source\": \"https://github.com/encode/uvicorn\"\n",
            "        },\n",
            "        \"home_page\": null,\n",
            "        \"requires_python\": \">=3.9\",\n",
            "        \"uploaded_at\": \"2025-06-28T16:15:44.816841Z\"\n",
            "      }\n",
            "    ],\n",
            "    \"stack_overflow\": [\n",
            "      {\n",
            "        \"question_id\": 79734898,\n",
            "        \"title\": \"FastAPI OAuth2PasswordBearer JWT authorization not working in Swagger UI\",\n",
            "        \"link\": \"https://stackoverflow.com/questions/79734898/fastapi-oauth2passwordbearer-jwt-authorization-not-working-in-swagger-ui\",\n",
            "        \"creation_date\": \"2025-08-14T02:26:51Z\",\n",
            "        \"score\": 0,\n",
            "        \"is_answered\": false,\n",
            "        \"tags\": [\n",
            "          \"python\",\n",
            "          \"jwt\",\n",
            "          \"fastapi\"\n",
            "        ]\n",
            "      },\n",
            "      {\n",
            "        \"question_id\": 79734466,\n",
            "        \"title\": \"Trying to write a unit test to test a fastapi app with a middleware that changes the request.url.path\",\n",
            "        \"link\": \"https://stackoverflow.com/questions/79734466/trying-to-write-a-unit-test-to-test-a-fastapi-app-with-a-middleware-that-changes\",\n",
            "        \"creation_date\": \"2025-08-13T15:19:31Z\",\n",
            "        \"score\": 1,\n",
            "        \"is_answered\": true,\n",
            "        \"tags\": [\n",
            "          \"python\",\n",
            "          \"fastapi\",\n",
            "          \"middleware\"\n",
            "        ]\n",
            "      },\n",
            "      {\n",
            "        \"question_id\": 79734474,\n",
            "        \"title\": \"How do I set JWT refresh token location to cookies without having pydantic_core.ValidationError in my fastapi backend?\",\n",
            "        \"link\": \"https://stackoverflow.com/questions/79734474/how-do-i-set-jwt-refresh-token-location-to-cookies-without-having-pydantic-core\",\n",
            "        \"creation_date\": \"2025-08-13T15:28:58Z\",\n",
            "        \"score\": 0,\n",
            "        \"is_answered\": false,\n",
            "        \"tags\": [\n",
            "          \"python\",\n",
            "          \"authentication\",\n",
            "          \"jwt\",\n",
            "          \"fastapi\"\n",
            "        ]\n",
            "      },\n",
            "      {\n",
            "        \"question_id\": 79727568,\n",
            "        \"title\": \"How to expose Enum to FastAPI OpenAPI schema?\",\n",
            "        \"link\": \"https://stackoverflow.com/questions/79727568/how-to-expose-enum-to-fastapi-openapi-schema\",\n",
            "        \"creation_date\": \"2025-08-06T16:12:49Z\",\n",
            "        \"score\": 0,\n",
            "        \"is_answered\": false,\n",
            "        \"tags\": [\n",
            "          \"python\",\n",
            "          \"enums\",\n",
            "          \"fastapi\",\n",
            "          \"openapi\"\n",
            "        ]\n",
            "      },\n",
            "      {\n",
            "        \"question_id\": 78023569,\n",
            "        \"title\": \"How to solve Circular import error in Python\",\n",
            "        \"link\": \"https://stackoverflow.com/questions/78023569/how-to-solve-circular-import-error-in-python\",\n",
            "        \"creation_date\": \"2024-02-19T21:17:27Z\",\n",
            "        \"score\": 0,\n",
            "        \"is_answered\": false,\n",
            "        \"tags\": [\n",
            "          \"python\",\n",
            "          \"import\",\n",
            "          \"fastapi\",\n",
            "          \"circular-dependency\"\n",
            "        ]\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\n",
            "\n",
            "Saved JSON â†’ /content/software_dev_data_20250814-033525.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HTML Parsing**\n",
        "\n",
        "Utilize HTML parsing libraries to extract relevant data from HTML documents. HTML parsing libraries such as Beautiful Soup, Scrapy, and Selenium can handle the variability in HTML structures and extract data based on specific tags, attributes, and patterns."
      ],
      "metadata": {
        "id": "OEdPyDgagszc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Real-website HTML parsing demo (requests + BeautifulSoup) â€” JSON + table output\n",
        "# If BeautifulSoup/lxml aren't installed in your runtime, uncomment:\n",
        "# !pip -q install beautifulsoup4 lxml\n",
        "\n",
        "import requests, json\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "import pandas as pd\n",
        "\n",
        "URL = \"https://quotes.toscrape.com/\"  # a public site built for scraping tutorials\n",
        "\n",
        "# A polite, realistic user-agent helps avoid being blocked by some sites.\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 \"\n",
        "                  \"(KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\",\n",
        "    \"Accept-Language\": \"en-US,en;q=0.8\"\n",
        "}\n",
        "\n",
        "# --- Fetch page ---\n",
        "resp = requests.get(URL, headers=HEADERS, timeout=20)\n",
        "resp.raise_for_status()  # will throw if 4xx/5xx\n",
        "\n",
        "# --- Parse HTML ---\n",
        "soup = BeautifulSoup(resp.text, \"lxml\")\n",
        "\n",
        "# Extract page title\n",
        "title = soup.title.get_text(strip=True) if soup.title else \"\"\n",
        "\n",
        "# Extract quotes, authors, tags\n",
        "quotes_data = []\n",
        "for q in soup.select(\"div.quote\"):\n",
        "    text = q.select_one(\"span.text\")\n",
        "    author = q.select_one(\"small.author\")\n",
        "    tags = [t.get_text(strip=True) for t in q.select(\"div.tags a.tag\")]\n",
        "    quotes_data.append({\n",
        "        \"quote\": (text.get_text(strip=True) if text else \"\"),\n",
        "        \"author\": (author.get_text(strip=True) if author else \"\"),\n",
        "        \"tags\": tags\n",
        "    })\n",
        "\n",
        "# Find next page (if you want to paginate later)\n",
        "next_link = soup.select_one(\"li.next a\")\n",
        "next_page = urljoin(URL, next_link[\"href\"]) if next_link and next_link.has_attr(\"href\") else None\n",
        "\n",
        "# Build structured result\n",
        "result = {\n",
        "    \"source_url\": resp.url,\n",
        "    \"title\": title,\n",
        "    \"count\": len(quotes_data),\n",
        "    \"next_page\": next_page,\n",
        "    \"quotes\": quotes_data\n",
        "}\n",
        "\n",
        "# --- Show output to the user ---\n",
        "print(\"âœ… Parsed live HTML into structured JSON (first page):\\n\")\n",
        "print(json.dumps(result, indent=2, ensure_ascii=False))\n",
        "\n",
        "# Also show a friendly table view of the first few rows\n",
        "print(\"\\nğŸ” Preview table (first 5 rows):\")\n",
        "df = pd.DataFrame(quotes_data)\n",
        "display(df.head(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aT459f-hg47n",
        "outputId": "7e90da29-644f-4be3-da06-76d609ad21c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Parsed live HTML into structured JSON (first page):\n",
            "\n",
            "{\n",
            "  \"source_url\": \"https://quotes.toscrape.com/\",\n",
            "  \"title\": \"Quotes to Scrape\",\n",
            "  \"count\": 10,\n",
            "  \"next_page\": \"https://quotes.toscrape.com/page/2/\",\n",
            "  \"quotes\": [\n",
            "    {\n",
            "      \"quote\": \"â€œThe world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.â€\",\n",
            "      \"author\": \"Albert Einstein\",\n",
            "      \"tags\": [\n",
            "        \"change\",\n",
            "        \"deep-thoughts\",\n",
            "        \"thinking\",\n",
            "        \"world\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"quote\": \"â€œIt is our choices, Harry, that show what we truly are, far more than our abilities.â€\",\n",
            "      \"author\": \"J.K. Rowling\",\n",
            "      \"tags\": [\n",
            "        \"abilities\",\n",
            "        \"choices\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"quote\": \"â€œThere are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.â€\",\n",
            "      \"author\": \"Albert Einstein\",\n",
            "      \"tags\": [\n",
            "        \"inspirational\",\n",
            "        \"life\",\n",
            "        \"live\",\n",
            "        \"miracle\",\n",
            "        \"miracles\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"quote\": \"â€œThe person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.â€\",\n",
            "      \"author\": \"Jane Austen\",\n",
            "      \"tags\": [\n",
            "        \"aliteracy\",\n",
            "        \"books\",\n",
            "        \"classic\",\n",
            "        \"humor\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"quote\": \"â€œImperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.â€\",\n",
            "      \"author\": \"Marilyn Monroe\",\n",
            "      \"tags\": [\n",
            "        \"be-yourself\",\n",
            "        \"inspirational\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"quote\": \"â€œTry not to become a man of success. Rather become a man of value.â€\",\n",
            "      \"author\": \"Albert Einstein\",\n",
            "      \"tags\": [\n",
            "        \"adulthood\",\n",
            "        \"success\",\n",
            "        \"value\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"quote\": \"â€œIt is better to be hated for what you are than to be loved for what you are not.â€\",\n",
            "      \"author\": \"AndrÃ© Gide\",\n",
            "      \"tags\": [\n",
            "        \"life\",\n",
            "        \"love\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"quote\": \"â€œI have not failed. I've just found 10,000 ways that won't work.â€\",\n",
            "      \"author\": \"Thomas A. Edison\",\n",
            "      \"tags\": [\n",
            "        \"edison\",\n",
            "        \"failure\",\n",
            "        \"inspirational\",\n",
            "        \"paraphrased\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"quote\": \"â€œA woman is like a tea bag; you never know how strong it is until it's in hot water.â€\",\n",
            "      \"author\": \"Eleanor Roosevelt\",\n",
            "      \"tags\": [\n",
            "        \"misattributed-eleanor-roosevelt\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"quote\": \"â€œA day without sunshine is like, you know, night.â€\",\n",
            "      \"author\": \"Steve Martin\",\n",
            "      \"tags\": [\n",
            "        \"humor\",\n",
            "        \"obvious\",\n",
            "        \"simile\"\n",
            "      ]\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "ğŸ” Preview table (first 5 rows):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                               quote           author  \\\n",
              "0  â€œThe world as we have created it is a process ...  Albert Einstein   \n",
              "1  â€œIt is our choices, Harry, that show what we t...     J.K. Rowling   \n",
              "2  â€œThere are only two ways to live your life. On...  Albert Einstein   \n",
              "3  â€œThe person, be it gentleman or lady, who has ...      Jane Austen   \n",
              "4  â€œImperfection is beauty, madness is genius and...   Marilyn Monroe   \n",
              "\n",
              "                                             tags  \n",
              "0        [change, deep-thoughts, thinking, world]  \n",
              "1                            [abilities, choices]  \n",
              "2  [inspirational, life, live, miracle, miracles]  \n",
              "3              [aliteracy, books, classic, humor]  \n",
              "4                    [be-yourself, inspirational]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c140011a-cc73-46e7-a289-844d78f254f6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quote</th>\n",
              "      <th>author</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>â€œThe world as we have created it is a process ...</td>\n",
              "      <td>Albert Einstein</td>\n",
              "      <td>[change, deep-thoughts, thinking, world]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>â€œIt is our choices, Harry, that show what we t...</td>\n",
              "      <td>J.K. Rowling</td>\n",
              "      <td>[abilities, choices]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>â€œThere are only two ways to live your life. On...</td>\n",
              "      <td>Albert Einstein</td>\n",
              "      <td>[inspirational, life, live, miracle, miracles]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>â€œThe person, be it gentleman or lady, who has ...</td>\n",
              "      <td>Jane Austen</td>\n",
              "      <td>[aliteracy, books, classic, humor]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>â€œImperfection is beauty, madness is genius and...</td>\n",
              "      <td>Marilyn Monroe</td>\n",
              "      <td>[be-yourself, inspirational]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c140011a-cc73-46e7-a289-844d78f254f6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c140011a-cc73-46e7-a289-844d78f254f6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c140011a-cc73-46e7-a289-844d78f254f6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2ee25293-ca23-4c41-b9eb-63d651ebfa62\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2ee25293-ca23-4c41-b9eb-63d651ebfa62')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2ee25293-ca23-4c41-b9eb-63d651ebfa62 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"quote\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u201cIt is our choices, Harry, that show what we truly are, far more than our abilities.\\u201d\",\n          \"\\u201cImperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.\\u201d\",\n          \"\\u201cThere are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.\\u201d\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"J.K. Rowling\",\n          \"Marilyn Monroe\",\n          \"Albert Einstein\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tags\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PDF Parsing**\n",
        "\n",
        "Use PDF parsing libraries to extract text, images, and other data from PDF documents. PDF parsing libraries like PyPDF, PDFMiner, and LlamaParse can handle complex layouts and structures. They also support extracting data based on specific patterns and rules."
      ],
      "metadata": {
        "id": "NoVJB4UBhYhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Real-PDF parsing demo (requests + pdfminer.six) â€” JSON + links table\n",
        "# Safe to rerun in Colab.\n",
        "!pip -q install pdfminer.six requests pandas\n",
        "\n",
        "import io, json, re\n",
        "import requests\n",
        "import pandas as pd\n",
        "from pdfminer.high_level import extract_text, extract_pages\n",
        "from pdfminer.pdfparser import PDFParser\n",
        "from pdfminer.pdfdocument import PDFDocument\n",
        "\n",
        "# A stable, text-based public PDF (swap this URL as you like)\n",
        "PDF_URL = \"https://arxiv.org/pdf/1706.03762.pdf\"  # \"Attention Is All You Need\"\n",
        "\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 \"\n",
        "                  \"(KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\",\n",
        "    \"Accept\": \"application/pdf,*/*;q=0.9\"\n",
        "}\n",
        "\n",
        "def fetch_pdf(url):\n",
        "    r = requests.get(url, headers=HEADERS, timeout=60)\n",
        "    r.raise_for_status()\n",
        "    return r.content, r.url\n",
        "\n",
        "def decode_meta(info_list):\n",
        "    \"\"\"pdfminer returns metadata as a list of dicts with byte keys/values.\"\"\"\n",
        "    if not info_list:\n",
        "        return {}\n",
        "    meta = {}\n",
        "    for k, v in info_list[0].items():\n",
        "        kd = k.decode('utf-8', 'ignore') if isinstance(k, (bytes, bytearray)) else str(k)\n",
        "        vd = v.decode('utf-8', 'ignore') if isinstance(v, (bytes, bytearray)) else str(v)\n",
        "        meta[kd.strip('/')] = vd\n",
        "    return meta\n",
        "\n",
        "def extract_urls(text):\n",
        "    # Simple URL regex that works well for demos\n",
        "    return re.findall(r\"https?://[^\\s)>\\]}]+\", text)\n",
        "\n",
        "# --- Fetch PDF bytes ---\n",
        "pdf_bytes, final_url = fetch_pdf(PDF_URL)\n",
        "\n",
        "# --- Page count (iterate pages once) ---\n",
        "page_count = sum(1 for _ in extract_pages(io.BytesIO(pdf_bytes)))\n",
        "\n",
        "# --- Metadata via low-level parser ---\n",
        "parser = PDFParser(io.BytesIO(pdf_bytes))\n",
        "doc = PDFDocument(parser)\n",
        "meta = decode_meta(getattr(doc, \"info\", None))\n",
        "\n",
        "# --- Extract text from first few pages quickly ---\n",
        "PAGES_TO_SCAN = min(page_count, 5) if page_count else 0\n",
        "page_indices = list(range(PAGES_TO_SCAN))\n",
        "\n",
        "scanned_text = extract_text(io.BytesIO(pdf_bytes), page_numbers=page_indices) if PAGES_TO_SCAN else \"\"\n",
        "first_page_preview = extract_text(io.BytesIO(pdf_bytes), page_numbers=[0])[:1200].strip() if page_count else \"\"\n",
        "\n",
        "# --- URLs (found in text) ---\n",
        "urls = sorted(set(extract_urls(scanned_text)))[:200]\n",
        "\n",
        "# --- Build structured JSON result ---\n",
        "word_count = len(re.findall(r\"\\w+\", scanned_text))\n",
        "result = {\n",
        "    \"source_url\": final_url,\n",
        "    \"pdf_meta\": {\n",
        "        \"title\": meta.get(\"Title\"),\n",
        "        \"author\": meta.get(\"Author\"),\n",
        "        \"pages\": page_count,\n",
        "        \"producer\": meta.get(\"Producer\"),\n",
        "    },\n",
        "    \"extracted\": {\n",
        "        \"scanned_pages\": PAGES_TO_SCAN,\n",
        "        \"num_words_in_scanned_pages\": word_count,\n",
        "        \"first_page_preview\": first_page_preview\n",
        "    },\n",
        "    \"links_found\": urls\n",
        "}\n",
        "\n",
        "# --- Show output to the user ---\n",
        "print(\"âœ… Parsed live PDF with pdfminer.six into structured JSON:\\n\")\n",
        "print(json.dumps(result, indent=2, ensure_ascii=False))\n",
        "\n",
        "# Also show a friendly table view of links (if any)\n",
        "if urls:\n",
        "    print(\"\\nğŸ” Links found (preview):\")\n",
        "    df = pd.DataFrame(urls, columns=[\"url\"])\n",
        "    display(df.head(10))\n",
        "else:\n",
        "    print(\"\\nğŸ” No links found on the scanned pages.\")\n",
        "\n",
        "# --- Tip: change PDF_URL above to parse a different public PDF.\n",
        "# For large PDFs, increase/decrease PAGES_TO_SCAN to control runtime.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpCs8q5DhiWm",
        "outputId": "ccf998a4-0b07-4f02-a92f-65085d33e678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Parsed live PDF with pdfminer.six into structured JSON:\n",
            "\n",
            "{\n",
            "  \"source_url\": \"https://arxiv.org/pdf/1706.03762\",\n",
            "  \"pdf_meta\": {\n",
            "    \"title\": \"\",\n",
            "    \"author\": \"\",\n",
            "    \"pages\": 15,\n",
            "    \"producer\": \"pdfTeX-1.40.25\"\n",
            "  },\n",
            "  \"extracted\": {\n",
            "    \"scanned_pages\": 5,\n",
            "    \"num_words_in_scanned_pages\": 2344,\n",
            "    \"first_page_preview\": \"3\\n2\\n0\\n2\\n\\ng\\nu\\nA\\n2\\n\\n]\\nL\\nC\\n.\\ns\\nc\\n[\\n\\n7\\nv\\n2\\n6\\n7\\n3\\n0\\n.\\n6\\n0\\n7\\n1\\n:\\nv\\ni\\nX\\nr\\na\\n\\nProvided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and figures in this paper solely for use in journalistic or\\nscholarly works.\\n\\nAttention Is All You Need\\n\\nAshish Vaswaniâˆ—\\nGoogle Brain\\navaswani@google.com\\n\\nNoam Shazeerâˆ—\\nGoogle Brain\\nnoam@google.com\\n\\nNiki Parmarâˆ—\\nGoogle Research\\nnikip@google.com\\n\\nJakob Uszkoreitâˆ—\\nGoogle Research\\nusz@google.com\\n\\nLlion Jonesâˆ—\\nGoogle Research\\nllion@google.com\\n\\nAidan N. Gomezâˆ— â€ \\nUniversity of Toronto\\naidan@cs.toronto.edu\\n\\nÅukasz Kaiserâˆ—\\nGoogle Brain\\nlukaszkaiser@google.com\\n\\nIllia Polosukhinâˆ— â€¡\\nillia.polosukhin@gmail.com\\n\\nAbstract\\n\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable a\"\n",
            "  },\n",
            "  \"links_found\": []\n",
            "}\n",
            "\n",
            "ğŸ” No links found on the scanned pages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OCR**\n",
        "\n",
        "Apply OCR techniques such as Tesseract, EasyOCR, and PaddleOCR to extract text from scanned PDFs or images. OCR can recognize text in images and extract it into a machine-readable format."
      ],
      "metadata": {
        "id": "O6EEUvqrimnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title OCR a live PDF (Tesseract + PyMuPDF) â€” JSON + table output\n",
        "# Installs (safe to rerun)\n",
        "!apt-get -y -qq install tesseract-ocr >/dev/null\n",
        "# For Arabic OCR too, uncomment the next line and set LANGS=\"ara+eng\" below:\n",
        "# !apt-get -y -qq install tesseract-ocr-ara >/dev/null\n",
        "!pip -q install pytesseract pymupdf pillow requests pandas\n",
        "\n",
        "import io, json\n",
        "import requests, fitz, pytesseract, pandas as pd\n",
        "from pytesseract import Output\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "# ----- Settings -----\n",
        "PDF_URL = \"https://www.irs.gov/pub/irs-pdf/fw9.pdf\"  # public, small and stable\n",
        "LANGS = \"eng\"                  # set to \"ara+eng\" if you installed Arabic above\n",
        "PAGES_TO_OCR = 2               # keep small for demo; increase as needed\n",
        "DPI = 300                      # higher DPI -> better OCR, slower runtime\n",
        "CONF_THRESHOLD = 60            # only keep words with confidence >= 60\n",
        "\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 \"\n",
        "                  \"(KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\",\n",
        "    \"Accept\": \"application/pdf,*/*;q=0.9\"\n",
        "}\n",
        "\n",
        "def fetch_pdf(url):\n",
        "    r = requests.get(url, headers=HEADERS, timeout=60)\n",
        "    r.raise_for_status()\n",
        "    return r.content, r.url\n",
        "\n",
        "def ocr_page(image, langs=LANGS):\n",
        "    # Per-word OCR (for boxes + confidence)\n",
        "    data = pytesseract.image_to_data(image, lang=langs, output_type=Output.DICT, config=\"--oem 3 --psm 6\")\n",
        "    words = []\n",
        "    n = len(data[\"text\"])\n",
        "    for i in range(n):\n",
        "        txt = (data[\"text\"][i] or \"\").strip()\n",
        "        try:\n",
        "            conf = float(data[\"conf\"][i])\n",
        "        except Exception:\n",
        "            conf = -1.0\n",
        "        if txt and conf >= CONF_THRESHOLD:\n",
        "            words.append({\n",
        "                \"text\": txt,\n",
        "                \"conf\": conf,\n",
        "                \"bbox\": [int(data[\"left\"][i]), int(data[\"top\"][i]), int(data[\"width\"][i]), int(data[\"height\"][i])]\n",
        "            })\n",
        "    # Full-page text (easier to read)\n",
        "    full_text = pytesseract.image_to_string(image, lang=langs, config=\"--oem 3 --psm 6\")\n",
        "    return words, full_text\n",
        "\n",
        "# --- Fetch PDF and open ---\n",
        "pdf_bytes, final_url = fetch_pdf(PDF_URL)\n",
        "doc = fitz.open(stream=pdf_bytes, filetype=\"pdf\")\n",
        "page_count = doc.page_count\n",
        "pages_to_scan = min(page_count, PAGES_TO_OCR)\n",
        "\n",
        "# --- OCR pages ---\n",
        "pages_out = []\n",
        "table_rows = []\n",
        "for i in range(pages_to_scan):\n",
        "    page = doc[i]\n",
        "    pix = page.get_pixmap(dpi=DPI, alpha=False)  # rasterize to image\n",
        "    img = Image.open(io.BytesIO(pix.tobytes(\"png\")))\n",
        "\n",
        "    words, full_text = ocr_page(img, langs=LANGS)\n",
        "    pages_out.append({\n",
        "        \"page_index\": i,\n",
        "        \"word_count_kept\": len(words),\n",
        "        \"text_preview\": full_text[:800].strip(),\n",
        "        \"words\": words[:150]  # cap for display\n",
        "    })\n",
        "    for w in words[:300]:  # cap for display\n",
        "        table_rows.append({\n",
        "            \"page\": i,\n",
        "            \"text\": w[\"text\"],\n",
        "            \"conf\": w[\"conf\"],\n",
        "            \"x\": w[\"bbox\"][0],\n",
        "            \"y\": w[\"bbox\"][1],\n",
        "            \"w\": w[\"bbox\"][2],\n",
        "            \"h\": w[\"bbox\"][3],\n",
        "        })\n",
        "\n",
        "# --- Build and show JSON result ---\n",
        "result = {\n",
        "    \"source_url\": final_url,\n",
        "    \"pages_total\": page_count,\n",
        "    \"pages_scanned\": pages_to_scan,\n",
        "    \"dpi\": DPI,\n",
        "    \"lang\": LANGS,\n",
        "    \"min_conf_kept\": CONF_THRESHOLD,\n",
        "    \"pages\": pages_out\n",
        "}\n",
        "\n",
        "print(\"âœ… OCRâ€™d live PDF into structured JSON:\\n\")\n",
        "print(json.dumps(result, indent=2, ensure_ascii=False))\n",
        "\n",
        "# --- Preview table of extracted words ---\n",
        "print(\"\\nğŸ” Preview of extracted words (first rows):\")\n",
        "df = pd.DataFrame(table_rows)\n",
        "display(df.head(20) if not df.empty else \"No words passed the confidence threshold.\")\n",
        "\n",
        "# --- Tips ---\n",
        "# 1) To switch PDFs, change PDF_URL above.\n",
        "# 2) For Arabic or mixed Arabic/English, install tesseract-ocr-ara (apt line above)\n",
        "#    and set LANGS = \"ara+eng\".\n",
        "# 3) Increase PAGES_TO_OCR or DPI for better recall (slower).\n",
        "# 4) To save outputs, you can write JSON to a file in /content and download it.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V8tTtCZfizEZ",
        "outputId": "109bf4ba-764d-4322-a7a6-740d02be0a08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… OCRâ€™d live PDF into structured JSON:\n",
            "\n",
            "{\n",
            "  \"source_url\": \"https://www.irs.gov/pub/irs-pdf/fw9.pdf\",\n",
            "  \"pages_total\": 6,\n",
            "  \"pages_scanned\": 2,\n",
            "  \"dpi\": 300,\n",
            "  \"lang\": \"eng\",\n",
            "  \"min_conf_kept\": 60,\n",
            "  \"pages\": [\n",
            "    {\n",
            "      \"page_index\": 0,\n",
            "      \"word_count_kept\": 922,\n",
            "      \"text_preview\": \"Form W-9 wo Request for Taxpayer _ . Give form to the\\n(Rev. March 2024) Identification Number and Certification requester. Do not\\nDepart t of the Ti . . . : .\\nInternal Revenue Service Go to www.irs.gov/FormW/9 for instructions and the latest information. send to the IRS.\\nBefore you begin. For guidance related to the purpose of Form W-9, see Purpose of Form, below.\\n1. Name of entity/individual. An entry is required. (For a sole proprietor or disregarded entity, enter the ownerâ€™s name on line 1, and enter the business/disregarded\\nentityâ€™s name on line 2.)\\n2 Business name/disregarded entity name, if different from above.\\nÂ° 3a Check the appropriate box for federal tax classification of the entity/individual whose name is entered on line 1. Check 4 Exemptions (codes apply only to\\n> only one of\",\n",
            "      \"words\": [\n",
            "        {\n",
            "          \"text\": \"Form\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            152,\n",
            "            200,\n",
            "            64,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"W-9\",\n",
            "          \"conf\": 91.0,\n",
            "          \"bbox\": [\n",
            "            234,\n",
            "            146,\n",
            "            158,\n",
            "            88\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Request\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1001,\n",
            "            159,\n",
            "            204,\n",
            "            78\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"for\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1231,\n",
            "            162,\n",
            "            65,\n",
            "            42\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Taxpayer\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            1317,\n",
            "            159,\n",
            "            235,\n",
            "            74\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \".\",\n",
            "          \"conf\": 64.0,\n",
            "          \"bbox\": [\n",
            "            1708,\n",
            "            224,\n",
            "            9,\n",
            "            9\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Give\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2070,\n",
            "            191,\n",
            "            77,\n",
            "            28\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"form\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2159,\n",
            "            191,\n",
            "            81,\n",
            "            28\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"to\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2253,\n",
            "            193,\n",
            "            35,\n",
            "            26\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"the\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2300,\n",
            "            191,\n",
            "            55,\n",
            "            28\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"(Rev.\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            151,\n",
            "            240,\n",
            "            63,\n",
            "            27\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"March\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            226,\n",
            "            240,\n",
            "            79,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2024)\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            316,\n",
            "            240,\n",
            "            70,\n",
            "            27\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Identification\",\n",
            "          \"conf\": 87.0,\n",
            "          \"bbox\": [\n",
            "            771,\n",
            "            224,\n",
            "            339,\n",
            "            42\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Number\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1134,\n",
            "            225,\n",
            "            196,\n",
            "            41\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"and\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1350,\n",
            "            225,\n",
            "            90,\n",
            "            41\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Certification\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1462,\n",
            "            224,\n",
            "            319,\n",
            "            42\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"requester.\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2071,\n",
            "            238,\n",
            "            179,\n",
            "            32\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Do\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2265,\n",
            "            236,\n",
            "            46,\n",
            "            28\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"not\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2325,\n",
            "            238,\n",
            "            56,\n",
            "            26\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Depart\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            152,\n",
            "            281,\n",
            "            83,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"t\",\n",
            "          \"conf\": 63.0,\n",
            "          \"bbox\": [\n",
            "            291,\n",
            "            282,\n",
            "            8,\n",
            "            20\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"of\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            305,\n",
            "            277,\n",
            "            27,\n",
            "            36\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"the\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            340,\n",
            "            281,\n",
            "            22,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \".\",\n",
            "          \"conf\": 61.0,\n",
            "          \"bbox\": [\n",
            "            1220,\n",
            "            300,\n",
            "            5,\n",
            "            4\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Internal\",\n",
            "          \"conf\": 87.0,\n",
            "          \"bbox\": [\n",
            "            152,\n",
            "            283,\n",
            "            85,\n",
            "            59\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Revenue\",\n",
            "          \"conf\": 86.0,\n",
            "          \"bbox\": [\n",
            "            246,\n",
            "            283,\n",
            "            114,\n",
            "            59\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Go\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            718,\n",
            "            300,\n",
            "            43,\n",
            "            25\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"to\",\n",
            "          \"conf\": 93.0,\n",
            "          \"bbox\": [\n",
            "            772,\n",
            "            302,\n",
            "            31,\n",
            "            22\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"for\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1164,\n",
            "            300,\n",
            "            45,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"instructions\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1220,\n",
            "            302,\n",
            "            185,\n",
            "            22\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"and\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1417,\n",
            "            300,\n",
            "            56,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"the\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1484,\n",
            "            300,\n",
            "            50,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"latest\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            1546,\n",
            "            300,\n",
            "            86,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"information.\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            1643,\n",
            "            300,\n",
            "            188,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"send\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2070,\n",
            "            281,\n",
            "            84,\n",
            "            28\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"to\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2167,\n",
            "            283,\n",
            "            34,\n",
            "            26\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"the\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            2213,\n",
            "            281,\n",
            "            56,\n",
            "            28\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"IRS.\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            2283,\n",
            "            281,\n",
            "            68,\n",
            "            28\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Before\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            152,\n",
            "            362,\n",
            "            103,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"you\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            266,\n",
            "            368,\n",
            "            55,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"begin.\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            334,\n",
            "            362,\n",
            "            94,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"For\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            442,\n",
            "            362,\n",
            "            46,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"guidance\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            499,\n",
            "            362,\n",
            "            135,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"related\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            646,\n",
            "            362,\n",
            "            98,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"to\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            756,\n",
            "            364,\n",
            "            28,\n",
            "            22\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"the\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            795,\n",
            "            362,\n",
            "            46,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"purpose\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            853,\n",
            "            368,\n",
            "            120,\n",
            "            25\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"of\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            984,\n",
            "            362,\n",
            "            28,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Form\",\n",
            "          \"conf\": 91.0,\n",
            "          \"bbox\": [\n",
            "            1024,\n",
            "            362,\n",
            "            73,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"W-9,\",\n",
            "          \"conf\": 91.0,\n",
            "          \"bbox\": [\n",
            "            1109,\n",
            "            362,\n",
            "            68,\n",
            "            29\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"see\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1190,\n",
            "            368,\n",
            "            51,\n",
            "            18\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Purpose\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            1251,\n",
            "            362,\n",
            "            123,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"of\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            1385,\n",
            "            362,\n",
            "            31,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Form,\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1423,\n",
            "            362,\n",
            "            84,\n",
            "            29\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"below.\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1521,\n",
            "            362,\n",
            "            94,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Name\",\n",
            "          \"conf\": 74.0,\n",
            "          \"bbox\": [\n",
            "            308,\n",
            "            412,\n",
            "            74,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"of\",\n",
            "          \"conf\": 91.0,\n",
            "          \"bbox\": [\n",
            "            392,\n",
            "            412,\n",
            "            24,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"entity/individual.\",\n",
            "          \"conf\": 91.0,\n",
            "          \"bbox\": [\n",
            "            425,\n",
            "            412,\n",
            "            209,\n",
            "            27\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"An\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            644,\n",
            "            412,\n",
            "            34,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"entry\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            689,\n",
            "            413,\n",
            "            64,\n",
            "            26\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"is\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            763,\n",
            "            412,\n",
            "            19,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"required.\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            792,\n",
            "            412,\n",
            "            112,\n",
            "            27\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"(For\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            916,\n",
            "            412,\n",
            "            49,\n",
            "            27\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"a\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            975,\n",
            "            418,\n",
            "            14,\n",
            "            15\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"sole\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            999,\n",
            "            412,\n",
            "            51,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"proprietor\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1061,\n",
            "            412,\n",
            "            126,\n",
            "            27\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"or\",\n",
            "          \"conf\": 97.0,\n",
            "          \"bbox\": [\n",
            "            1197,\n",
            "            418,\n",
            "            25,\n",
            "            15\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"disregarded\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1231,\n",
            "            412,\n",
            "            153,\n",
            "            27\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"entity,\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1396,\n",
            "            412,\n",
            "            75,\n",
            "            27\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"enter\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1483,\n",
            "            413,\n",
            "            65,\n",
            "            20\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"the\",\n",
            "          \"conf\": 93.0,\n",
            "          \"bbox\": [\n",
            "            1557,\n",
            "            412,\n",
            "            40,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"ownerâ€™s\",\n",
            "          \"conf\": 92.0,\n",
            "          \"bbox\": [\n",
            "            1607,\n",
            "            412,\n",
            "            101,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"name\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1719,\n",
            "            418,\n",
            "            69,\n",
            "            15\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"on\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            1799,\n",
            "            418,\n",
            "            29,\n",
            "            15\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"line\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            1840,\n",
            "            412,\n",
            "            42,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"1,\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1894,\n",
            "            412,\n",
            "            19,\n",
            "            25\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"and\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1925,\n",
            "            412,\n",
            "            46,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"enter\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1982,\n",
            "            413,\n",
            "            66,\n",
            "            20\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"the\",\n",
            "          \"conf\": 93.0,\n",
            "          \"bbox\": [\n",
            "            2056,\n",
            "            412,\n",
            "            40,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"business/disregarded\",\n",
            "          \"conf\": 91.0,\n",
            "          \"bbox\": [\n",
            "            2107,\n",
            "            412,\n",
            "            277,\n",
            "            27\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"entityâ€™s\",\n",
            "          \"conf\": 92.0,\n",
            "          \"bbox\": [\n",
            "            308,\n",
            "            447,\n",
            "            92,\n",
            "            27\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"name\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            411,\n",
            "            453,\n",
            "            69,\n",
            "            15\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"on\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            491,\n",
            "            453,\n",
            "            29,\n",
            "            15\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"line\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            532,\n",
            "            447,\n",
            "            42,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2.)\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            584,\n",
            "            447,\n",
            "            30,\n",
            "            27\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2\",\n",
            "          \"conf\": 61.0,\n",
            "          \"bbox\": [\n",
            "            257,\n",
            "            562,\n",
            "            15,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Business\",\n",
            "          \"conf\": 93.0,\n",
            "          \"bbox\": [\n",
            "            308,\n",
            "            562,\n",
            "            115,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"name/disregarded\",\n",
            "          \"conf\": 92.0,\n",
            "          \"bbox\": [\n",
            "            433,\n",
            "            562,\n",
            "            235,\n",
            "            27\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"entity\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            679,\n",
            "            562,\n",
            "            70,\n",
            "            27\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"name,\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            759,\n",
            "            568,\n",
            "            77,\n",
            "            19\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"if\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            848,\n",
            "            562,\n",
            "            13,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"different\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            871,\n",
            "            562,\n",
            "            105,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"from\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            985,\n",
            "            562,\n",
            "            58,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"above.\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1054,\n",
            "            562,\n",
            "            85,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"3a\",\n",
            "          \"conf\": 72.0,\n",
            "          \"bbox\": [\n",
            "            257,\n",
            "            662,\n",
            "            32,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Check\",\n",
            "          \"conf\": 72.0,\n",
            "          \"bbox\": [\n",
            "            307,\n",
            "            662,\n",
            "            82,\n",
            "            22\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"the\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            398,\n",
            "            662,\n",
            "            40,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"appropriate\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            448,\n",
            "            662,\n",
            "            149,\n",
            "            27\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"box\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            607,\n",
            "            662,\n",
            "            47,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"for\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            663,\n",
            "            662,\n",
            "            35,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"federal\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            706,\n",
            "            662,\n",
            "            88,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"tax\",\n",
            "          \"conf\": 97.0,\n",
            "          \"bbox\": [\n",
            "            804,\n",
            "            663,\n",
            "            39,\n",
            "            20\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"classification\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            853,\n",
            "            662,\n",
            "            165,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"of\",\n",
            "          \"conf\": 97.0,\n",
            "          \"bbox\": [\n",
            "            1029,\n",
            "            662,\n",
            "            25,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"the\",\n",
            "          \"conf\": 93.0,\n",
            "          \"bbox\": [\n",
            "            1062,\n",
            "            662,\n",
            "            40,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"entity/individual\",\n",
            "          \"conf\": 92.0,\n",
            "          \"bbox\": [\n",
            "            1112,\n",
            "            662,\n",
            "            201,\n",
            "            27\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"whose\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1324,\n",
            "            662,\n",
            "            83,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"name\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1418,\n",
            "            668,\n",
            "            70,\n",
            "            15\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"is\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            1499,\n",
            "            662,\n",
            "            18,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"entered\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1527,\n",
            "            662,\n",
            "            96,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"on\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1635,\n",
            "            668,\n",
            "            30,\n",
            "            15\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"line\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            1676,\n",
            "            662,\n",
            "            43,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"1.\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1730,\n",
            "            662,\n",
            "            20,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Check\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1761,\n",
            "            662,\n",
            "            82,\n",
            "            22\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"4\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1907,\n",
            "            667,\n",
            "            15,\n",
            "            20\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Exemptions\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            1941,\n",
            "            666,\n",
            "            151,\n",
            "            27\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"(codes\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2102,\n",
            "            666,\n",
            "            86,\n",
            "            27\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"apply\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2198,\n",
            "            666,\n",
            "            70,\n",
            "            27\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"only\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2277,\n",
            "            666,\n",
            "            53,\n",
            "            27\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"to\",\n",
            "          \"conf\": 97.0,\n",
            "          \"bbox\": [\n",
            "            2339,\n",
            "            667,\n",
            "            24,\n",
            "            20\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"only\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            308,\n",
            "            697,\n",
            "            52,\n",
            "            27\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"one\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            370,\n",
            "            703,\n",
            "            50,\n",
            "            15\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"of\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            430,\n",
            "            697,\n",
            "            24,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"the\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            462,\n",
            "            697,\n",
            "            40,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"following\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            512,\n",
            "            697,\n",
            "            114,\n",
            "            27\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"seven\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            637,\n",
            "            703,\n",
            "            74,\n",
            "            15\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"boxes.\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            723,\n",
            "            697,\n",
            "            83,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"certain\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1941,\n",
            "            701,\n",
            "            86,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"entities,\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2038,\n",
            "            701,\n",
            "            98,\n",
            "            25\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"not\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2148,\n",
            "            702,\n",
            "            40,\n",
            "            20\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"individuals;\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2198,\n",
            "            701,\n",
            "            142,\n",
            "            25\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"instructi\",\n",
            "          \"conf\": 92.0,\n",
            "          \"bbox\": [\n",
            "            1996,\n",
            "            736,\n",
            "            100,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"3):\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2269,\n",
            "            736,\n",
            "            28,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"5\",\n",
            "          \"conf\": 62.0,\n",
            "          \"bbox\": [\n",
            "            200,\n",
            "            768,\n",
            "            18,\n",
            "            34\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Individual/sole\",\n",
            "          \"conf\": 92.0,\n",
            "          \"bbox\": [\n",
            "            363,\n",
            "            758,\n",
            "            184,\n",
            "            22\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"proprietor\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            558,\n",
            "            758,\n",
            "            127,\n",
            "            27\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"C\",\n",
            "          \"conf\": 93.0,\n",
            "          \"bbox\": [\n",
            "            808,\n",
            "            758,\n",
            "            18,\n",
            "            22\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"corporation\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            837,\n",
            "            758,\n",
            "            147,\n",
            "            27\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"S\",\n",
            "          \"conf\": 92.0,\n",
            "          \"bbox\": [\n",
            "            1108,\n",
            "            758,\n",
            "            16,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"corporation\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1135,\n",
            "            758,\n",
            "            147,\n",
            "            27\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Partnership\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1409,\n",
            "            754,\n",
            "            146,\n",
            "            36\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Trust/estate\",\n",
            "          \"conf\": 91.0,\n",
            "          \"bbox\": [\n",
            "            1667,\n",
            "            754,\n",
            "            165,\n",
            "            36\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"See\",\n",
            "          \"conf\": 80.0,\n",
            "          \"bbox\": [\n",
            "            1941,\n",
            "            742,\n",
            "            44,\n",
            "            15\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"instructions\",\n",
            "          \"conf\": 91.0,\n",
            "          \"bbox\": [\n",
            "            1996,\n",
            "            742,\n",
            "            148,\n",
            "            15\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"on\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            2155,\n",
            "            742,\n",
            "            29,\n",
            "            15\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"page\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2196,\n",
            "            742,\n",
            "            63,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"3)\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            2284,\n",
            "            736,\n",
            "            6,\n",
            "            27\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Ã©\",\n",
            "          \"conf\": 72.0,\n",
            "          \"bbox\": [\n",
            "            160,\n",
            "            825,\n",
            "            18,\n",
            "            25\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"LLC.\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            362,\n",
            "            814,\n",
            "            57,\n",
            "            22\n",
            "          ]\n",
            "        }\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"page_index\": 1,\n",
            "      \"word_count_kept\": 1313,\n",
            "      \"text_preview\": \"Form W-9 (Rev. 3-2024) Page 2\\nmust obtain your correct taxpayer identification number (TIN), which Foreign person. If you are a foreign person or the U.S. branch of a\\nmay be your social security number (SSN), individual taxpayer foreign bank that has elected to be treated as a U.S. person (under\\nidentification number (ITIN), adoption taxpayer identification number Regulations section 1.1441-1(b)(2)(iv) or other applicable section for\\n(ATIN), or employer identification number (EIN), to report on an chapter 3 or 4 purposes), do not use Form W-9. Instead, use the\\ninformation return the amount paid to you, or other amount reportable appropriate Form W-8 or Form 8233 (see Pub. 515). If you are a\\non an information return. Examples of information returns include, but qualified foreign pension fun\",\n",
            "      \"words\": [\n",
            "        {\n",
            "          \"text\": \"Form\",\n",
            "          \"conf\": 92.0,\n",
            "          \"bbox\": [\n",
            "            152,\n",
            "            160,\n",
            "            64,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"W-9\",\n",
            "          \"conf\": 91.0,\n",
            "          \"bbox\": [\n",
            "            227,\n",
            "            160,\n",
            "            52,\n",
            "            21\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"(Rev.\",\n",
            "          \"conf\": 93.0,\n",
            "          \"bbox\": [\n",
            "            290,\n",
            "            160,\n",
            "            62,\n",
            "            27\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"3-2024)\",\n",
            "          \"conf\": 93.0,\n",
            "          \"bbox\": [\n",
            "            364,\n",
            "            160,\n",
            "            98,\n",
            "            27\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Page\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2304,\n",
            "            163,\n",
            "            64,\n",
            "            27\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"2\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2378,\n",
            "            154,\n",
            "            21,\n",
            "            30\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"must\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            152,\n",
            "            243,\n",
            "            71,\n",
            "            22\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"obtain\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            235,\n",
            "            241,\n",
            "            89,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"your\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            337,\n",
            "            247,\n",
            "            64,\n",
            "            25\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"correct\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            412,\n",
            "            243,\n",
            "            103,\n",
            "            22\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"taxpayer\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            526,\n",
            "            243,\n",
            "            129,\n",
            "            29\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"identification\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            666,\n",
            "            241,\n",
            "            186,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"number\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            865,\n",
            "            241,\n",
            "            112,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"(TIN),\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            988,\n",
            "            241,\n",
            "            74,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"which\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1075,\n",
            "            241,\n",
            "            85,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Foreign\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1322,\n",
            "            241,\n",
            "            117,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"person.\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1452,\n",
            "            247,\n",
            "            116,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"If\",\n",
            "          \"conf\": 81.0,\n",
            "          \"bbox\": [\n",
            "            1582,\n",
            "            241,\n",
            "            16,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"you\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1608,\n",
            "            247,\n",
            "            51,\n",
            "            25\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"are\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1672,\n",
            "            247,\n",
            "            45,\n",
            "            18\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"a\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            1728,\n",
            "            247,\n",
            "            16,\n",
            "            18\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"foreign\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1754,\n",
            "            241,\n",
            "            101,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"person\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1869,\n",
            "            247,\n",
            "            98,\n",
            "            25\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"or\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1980,\n",
            "            247,\n",
            "            29,\n",
            "            18\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"the\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2018,\n",
            "            241,\n",
            "            46,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"U.S.\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            2077,\n",
            "            241,\n",
            "            59,\n",
            "            25\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"branch\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            2150,\n",
            "            241,\n",
            "            99,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"of\",\n",
            "          \"conf\": 94.0,\n",
            "          \"bbox\": [\n",
            "            2262,\n",
            "            241,\n",
            "            28,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"a\",\n",
            "          \"conf\": 94.0,\n",
            "          \"bbox\": [\n",
            "            2300,\n",
            "            247,\n",
            "            16,\n",
            "            18\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"may\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            152,\n",
            "            285,\n",
            "            61,\n",
            "            25\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"be\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            225,\n",
            "            279,\n",
            "            34,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"your\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            270,\n",
            "            285,\n",
            "            65,\n",
            "            25\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"social\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            345,\n",
            "            279,\n",
            "            83,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"security\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            441,\n",
            "            279,\n",
            "            115,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"number\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            568,\n",
            "            279,\n",
            "            112,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"(SSN),\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            691,\n",
            "            279,\n",
            "            89,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"individual\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            794,\n",
            "            279,\n",
            "            137,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"taxpayer\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            942,\n",
            "            281,\n",
            "            129,\n",
            "            29\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"foreign\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1320,\n",
            "            279,\n",
            "            101,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"bank\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1435,\n",
            "            279,\n",
            "            71,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"that\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1515,\n",
            "            279,\n",
            "            57,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"has\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1584,\n",
            "            279,\n",
            "            50,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"elected\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1645,\n",
            "            279,\n",
            "            106,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"to\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1763,\n",
            "            281,\n",
            "            28,\n",
            "            22\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"be\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            1804,\n",
            "            279,\n",
            "            35,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"treated\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            1849,\n",
            "            279,\n",
            "            103,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"as\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            1965,\n",
            "            285,\n",
            "            32,\n",
            "            18\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"a\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2008,\n",
            "            285,\n",
            "            16,\n",
            "            18\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"U.S.\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2037,\n",
            "            279,\n",
            "            59,\n",
            "            25\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"person\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2110,\n",
            "            285,\n",
            "            99,\n",
            "            25\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"(under\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2222,\n",
            "            279,\n",
            "            93,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"identification\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            152,\n",
            "            316,\n",
            "            186,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"number\",\n",
            "          \"conf\": 93.0,\n",
            "          \"bbox\": [\n",
            "            352,\n",
            "            316,\n",
            "            112,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"(ITIN),\",\n",
            "          \"conf\": 91.0,\n",
            "          \"bbox\": [\n",
            "            475,\n",
            "            316,\n",
            "            82,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"adoption\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            570,\n",
            "            316,\n",
            "            129,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"taxpayer\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            711,\n",
            "            318,\n",
            "            129,\n",
            "            29\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"identification\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            851,\n",
            "            316,\n",
            "            186,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"number\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1051,\n",
            "            316,\n",
            "            112,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Regulations\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            1323,\n",
            "            316,\n",
            "            172,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"section\",\n",
            "          \"conf\": 93.0,\n",
            "          \"bbox\": [\n",
            "            1506,\n",
            "            316,\n",
            "            105,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"or\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1881,\n",
            "            322,\n",
            "            29,\n",
            "            18\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"other\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1920,\n",
            "            316,\n",
            "            76,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"applicable\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2007,\n",
            "            316,\n",
            "            151,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"section\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2169,\n",
            "            316,\n",
            "            104,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"for\",\n",
            "          \"conf\": 97.0,\n",
            "          \"bbox\": [\n",
            "            2285,\n",
            "            316,\n",
            "            40,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"(ATIN),\",\n",
            "          \"conf\": 92.0,\n",
            "          \"bbox\": [\n",
            "            152,\n",
            "            354,\n",
            "            95,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"or\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            260,\n",
            "            360,\n",
            "            30,\n",
            "            18\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"employer\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            300,\n",
            "            354,\n",
            "            137,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"identification\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            449,\n",
            "            354,\n",
            "            185,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"number\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            648,\n",
            "            354,\n",
            "            112,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"(EIN),\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            771,\n",
            "            354,\n",
            "            75,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"to\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            858,\n",
            "            356,\n",
            "            28,\n",
            "            22\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"report\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            899,\n",
            "            356,\n",
            "            87,\n",
            "            29\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"on\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            997,\n",
            "            360,\n",
            "            34,\n",
            "            18\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"an\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1044,\n",
            "            360,\n",
            "            33,\n",
            "            18\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"chapter\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1321,\n",
            "            354,\n",
            "            113,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"3\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1444,\n",
            "            354,\n",
            "            16,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"or\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1472,\n",
            "            360,\n",
            "            29,\n",
            "            18\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"4\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1511,\n",
            "            354,\n",
            "            16,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"purposes),\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            1540,\n",
            "            354,\n",
            "            153,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"do\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1706,\n",
            "            354,\n",
            "            36,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"not\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1755,\n",
            "            356,\n",
            "            45,\n",
            "            22\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"use\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            1813,\n",
            "            360,\n",
            "            50,\n",
            "            18\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Form\",\n",
            "          \"conf\": 93.0,\n",
            "          \"bbox\": [\n",
            "            1875,\n",
            "            354,\n",
            "            73,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"W-9.\",\n",
            "          \"conf\": 82.0,\n",
            "          \"bbox\": [\n",
            "            1960,\n",
            "            354,\n",
            "            69,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Instead,\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2043,\n",
            "            354,\n",
            "            114,\n",
            "            29\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"use\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2171,\n",
            "            360,\n",
            "            50,\n",
            "            18\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"the\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2232,\n",
            "            354,\n",
            "            46,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"information\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            152,\n",
            "            391,\n",
            "            164,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"return\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            329,\n",
            "            393,\n",
            "            84,\n",
            "            22\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"the\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            424,\n",
            "            391,\n",
            "            46,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"amount\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            482,\n",
            "            393,\n",
            "            111,\n",
            "            22\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"paid\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            605,\n",
            "            391,\n",
            "            60,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"to\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            677,\n",
            "            393,\n",
            "            28,\n",
            "            22\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"you,\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            716,\n",
            "            397,\n",
            "            61,\n",
            "            25\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"or\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            790,\n",
            "            397,\n",
            "            29,\n",
            "            18\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"other\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            829,\n",
            "            391,\n",
            "            76,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"amount\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            916,\n",
            "            393,\n",
            "            111,\n",
            "            22\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"reportable\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1038,\n",
            "            391,\n",
            "            151,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"appropriate\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            1321,\n",
            "            391,\n",
            "            171,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Form\",\n",
            "          \"conf\": 92.0,\n",
            "          \"bbox\": [\n",
            "            1504,\n",
            "            391,\n",
            "            73,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"W-8\",\n",
            "          \"conf\": 91.0,\n",
            "          \"bbox\": [\n",
            "            1589,\n",
            "            391,\n",
            "            61,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"or\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1661,\n",
            "            397,\n",
            "            30,\n",
            "            18\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Form\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1702,\n",
            "            391,\n",
            "            73,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"8233\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1788,\n",
            "            391,\n",
            "            72,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"(see\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1872,\n",
            "            391,\n",
            "            59,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Pub.\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1943,\n",
            "            391,\n",
            "            64,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"515).\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            2020,\n",
            "            391,\n",
            "            70,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"If\",\n",
            "          \"conf\": 93.0,\n",
            "          \"bbox\": [\n",
            "            2104,\n",
            "            391,\n",
            "            16,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"you\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            2130,\n",
            "            397,\n",
            "            52,\n",
            "            25\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"are\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2194,\n",
            "            397,\n",
            "            45,\n",
            "            18\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"a\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2251,\n",
            "            397,\n",
            "            16,\n",
            "            18\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"on\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            151,\n",
            "            435,\n",
            "            34,\n",
            "            18\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"an\",\n",
            "          \"conf\": 94.0,\n",
            "          \"bbox\": [\n",
            "            198,\n",
            "            435,\n",
            "            33,\n",
            "            18\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"information\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            245,\n",
            "            429,\n",
            "            163,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"return.\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            422,\n",
            "            431,\n",
            "            92,\n",
            "            22\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Examples\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            529,\n",
            "            429,\n",
            "            142,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"of\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            682,\n",
            "            429,\n",
            "            28,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"information\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            722,\n",
            "            429,\n",
            "            163,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"returns\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            898,\n",
            "            431,\n",
            "            102,\n",
            "            22\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"include,\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1012,\n",
            "            429,\n",
            "            112,\n",
            "            29\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"but\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1138,\n",
            "            429,\n",
            "            46,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"qualified\",\n",
            "          \"conf\": 95.0,\n",
            "          \"bbox\": [\n",
            "            1321,\n",
            "            429,\n",
            "            123,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"foreign\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1455,\n",
            "            429,\n",
            "            101,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"pension\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1570,\n",
            "            429,\n",
            "            113,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"fund\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1695,\n",
            "            429,\n",
            "            64,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"under\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1773,\n",
            "            429,\n",
            "            84,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Regulations\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1869,\n",
            "            429,\n",
            "            172,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"section\",\n",
            "          \"conf\": 93.0,\n",
            "          \"bbox\": [\n",
            "            2052,\n",
            "            429,\n",
            "            105,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"1.897(I)-1(d),\",\n",
            "          \"conf\": 64.0,\n",
            "          \"bbox\": [\n",
            "            2171,\n",
            "            429,\n",
            "            181,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"or\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2365,\n",
            "            435,\n",
            "            29,\n",
            "            18\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"are\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            151,\n",
            "            472,\n",
            "            45,\n",
            "            18\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"not\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            208,\n",
            "            468,\n",
            "            46,\n",
            "            22\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"limited\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            266,\n",
            "            466,\n",
            "            94,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"to,\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            372,\n",
            "            468,\n",
            "            36,\n",
            "            27\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"the\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            420,\n",
            "            466,\n",
            "            46,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"following.\",\n",
            "          \"conf\": 92.0,\n",
            "          \"bbox\": [\n",
            "            476,\n",
            "            466,\n",
            "            140,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"a\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1321,\n",
            "            472,\n",
            "            16,\n",
            "            18\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"partnership\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1349,\n",
            "            466,\n",
            "            166,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"that\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1526,\n",
            "            466,\n",
            "            56,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"is\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1595,\n",
            "            466,\n",
            "            20,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"wholly\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1626,\n",
            "            466,\n",
            "            94,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"owned\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1731,\n",
            "            466,\n",
            "            97,\n",
            "            24\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"by\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1841,\n",
            "            466,\n",
            "            34,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"qualified\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            1886,\n",
            "            466,\n",
            "            123,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"foreign\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2020,\n",
            "            466,\n",
            "            101,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"pension\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2135,\n",
            "            466,\n",
            "            113,\n",
            "            31\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"funds,\",\n",
            "          \"conf\": 96.0,\n",
            "          \"bbox\": [\n",
            "            2260,\n",
            "            466,\n",
            "            90,\n",
            "            29\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"*\",\n",
            "          \"conf\": 75.0,\n",
            "          \"bbox\": [\n",
            "            152,\n",
            "            522,\n",
            "            12,\n",
            "            12\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Form\",\n",
            "          \"conf\": 93.0,\n",
            "          \"bbox\": [\n",
            "            179,\n",
            "            516,\n",
            "            73,\n",
            "            24\n",
            "          ]\n",
            "        }\n",
            "      ]\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "ğŸ” Preview of extracted words (first rows):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    page            text  conf     x    y    w   h\n",
              "0      0            Form  96.0   152  200   64  21\n",
              "1      0             W-9  91.0   234  146  158  88\n",
              "2      0         Request  96.0  1001  159  204  78\n",
              "3      0             for  96.0  1231  162   65  42\n",
              "4      0        Taxpayer  95.0  1317  159  235  74\n",
              "5      0               .  64.0  1708  224    9   9\n",
              "6      0            Give  96.0  2070  191   77  28\n",
              "7      0            form  96.0  2159  191   81  28\n",
              "8      0              to  96.0  2253  193   35  26\n",
              "9      0             the  96.0  2300  191   55  28\n",
              "10     0           (Rev.  96.0   151  240   63  27\n",
              "11     0           March  96.0   226  240   79  21\n",
              "12     0           2024)  96.0   316  240   70  27\n",
              "13     0  Identification  87.0   771  224  339  42\n",
              "14     0          Number  96.0  1134  225  196  41\n",
              "15     0             and  96.0  1350  225   90  41\n",
              "16     0   Certification  96.0  1462  224  319  42\n",
              "17     0      requester.  96.0  2071  238  179  32\n",
              "18     0              Do  96.0  2265  236   46  28\n",
              "19     0             not  96.0  2325  238   56  26"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-922650fd-f989-4d03-a428-20dd9b4c7ed2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page</th>\n",
              "      <th>text</th>\n",
              "      <th>conf</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>w</th>\n",
              "      <th>h</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Form</td>\n",
              "      <td>96.0</td>\n",
              "      <td>152</td>\n",
              "      <td>200</td>\n",
              "      <td>64</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>W-9</td>\n",
              "      <td>91.0</td>\n",
              "      <td>234</td>\n",
              "      <td>146</td>\n",
              "      <td>158</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Request</td>\n",
              "      <td>96.0</td>\n",
              "      <td>1001</td>\n",
              "      <td>159</td>\n",
              "      <td>204</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>for</td>\n",
              "      <td>96.0</td>\n",
              "      <td>1231</td>\n",
              "      <td>162</td>\n",
              "      <td>65</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Taxpayer</td>\n",
              "      <td>95.0</td>\n",
              "      <td>1317</td>\n",
              "      <td>159</td>\n",
              "      <td>235</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>.</td>\n",
              "      <td>64.0</td>\n",
              "      <td>1708</td>\n",
              "      <td>224</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>Give</td>\n",
              "      <td>96.0</td>\n",
              "      <td>2070</td>\n",
              "      <td>191</td>\n",
              "      <td>77</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>form</td>\n",
              "      <td>96.0</td>\n",
              "      <td>2159</td>\n",
              "      <td>191</td>\n",
              "      <td>81</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>to</td>\n",
              "      <td>96.0</td>\n",
              "      <td>2253</td>\n",
              "      <td>193</td>\n",
              "      <td>35</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>the</td>\n",
              "      <td>96.0</td>\n",
              "      <td>2300</td>\n",
              "      <td>191</td>\n",
              "      <td>55</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>(Rev.</td>\n",
              "      <td>96.0</td>\n",
              "      <td>151</td>\n",
              "      <td>240</td>\n",
              "      <td>63</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>March</td>\n",
              "      <td>96.0</td>\n",
              "      <td>226</td>\n",
              "      <td>240</td>\n",
              "      <td>79</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>2024)</td>\n",
              "      <td>96.0</td>\n",
              "      <td>316</td>\n",
              "      <td>240</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>Identification</td>\n",
              "      <td>87.0</td>\n",
              "      <td>771</td>\n",
              "      <td>224</td>\n",
              "      <td>339</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>Number</td>\n",
              "      <td>96.0</td>\n",
              "      <td>1134</td>\n",
              "      <td>225</td>\n",
              "      <td>196</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>and</td>\n",
              "      <td>96.0</td>\n",
              "      <td>1350</td>\n",
              "      <td>225</td>\n",
              "      <td>90</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>Certification</td>\n",
              "      <td>96.0</td>\n",
              "      <td>1462</td>\n",
              "      <td>224</td>\n",
              "      <td>319</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>requester.</td>\n",
              "      <td>96.0</td>\n",
              "      <td>2071</td>\n",
              "      <td>238</td>\n",
              "      <td>179</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>Do</td>\n",
              "      <td>96.0</td>\n",
              "      <td>2265</td>\n",
              "      <td>236</td>\n",
              "      <td>46</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>not</td>\n",
              "      <td>96.0</td>\n",
              "      <td>2325</td>\n",
              "      <td>238</td>\n",
              "      <td>56</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-922650fd-f989-4d03-a428-20dd9b4c7ed2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-922650fd-f989-4d03-a428-20dd9b4c7ed2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-922650fd-f989-4d03-a428-20dd9b4c7ed2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f890a10a-e9f2-4680-8c1f-c218a4cddf5c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f890a10a-e9f2-4680-8c1f-c218a4cddf5c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f890a10a-e9f2-4680-8c1f-c218a4cddf5c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"# 4) To save outputs, you can write JSON to a file in /content and download it\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"page\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Form\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"conf\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.32892610787807,\n        \"min\": 64.0,\n        \"max\": 96.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          91.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 804,\n        \"min\": 151,\n        \"max\": 2325,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          152\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31,\n        \"min\": 146,\n        \"max\": 240,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          191\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"w\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 94,\n        \"min\": 9,\n        \"max\": 339,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          64\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"h\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20,\n        \"min\": 9,\n        \"max\": 88,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Extraction**\n",
        "\n",
        "Use data extraction techniques to extract specific data from HTML and PDF documents based on particular patterns, rules, or templates"
      ],
      "metadata": {
        "id": "HaD11Khfk5Ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title OCR + Data Extraction from a real invoice PDF â€” JSON + table output\n",
        "# Install deps (safe to rerun)\n",
        "!apt-get -y -qq install tesseract-ocr >/dev/null\n",
        "# For Arabic OCR too, uncomment and set LANGS=\"ara+eng\" below:\n",
        "# !apt-get -y -qq install tesseract-ocr-ara >/dev/null\n",
        "!pip -q install pytesseract pymupdf pillow requests pandas\n",
        "\n",
        "import io, re, json, statistics\n",
        "import requests, fitz, pytesseract, pandas as pd\n",
        "from pytesseract import Output\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "# --- Settings ---\n",
        "PDF_URL = \"https://slicedinvoices.com/pdf/wordpress-pdf-invoice-plugin-sample.pdf\"\n",
        "LANGS = \"eng\"       # set to \"ara+eng\" if you installed Arabic\n",
        "DPI = 300           # higher DPI -> better OCR\n",
        "CONF_MIN = 50       # keep words with conf >= threshold for confidence estimates\n",
        "\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 \"\n",
        "                  \"(KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\",\n",
        "    \"Accept\": \"application/pdf,*/*;q=0.9\"\n",
        "}\n",
        "\n",
        "# --- Helpers ---\n",
        "def fetch_pdf(url):\n",
        "    r = requests.get(url, headers=HEADERS, timeout=60)\n",
        "    r.raise_for_status()\n",
        "    return r.content, r.url\n",
        "\n",
        "def ocr_page(img, langs=LANGS):\n",
        "    # light pre-processing improves OCR\n",
        "    gray = ImageOps.grayscale(img)\n",
        "    gray = ImageOps.autocontrast(gray)\n",
        "    # words with boxes + conf\n",
        "    data = pytesseract.image_to_data(gray, lang=langs, output_type=Output.DICT, config=\"--oem 3 --psm 6\")\n",
        "    # full text for regex extraction\n",
        "    text = pytesseract.image_to_string(gray, lang=langs, config=\"--oem 3 --psm 6\")\n",
        "    return data, text\n",
        "\n",
        "def find_field(pattern, text, flags=re.IGNORECASE):\n",
        "    m = re.search(pattern, text, flags)\n",
        "    return m.group(1).strip() if m else None\n",
        "\n",
        "def block_between(text, start_label, end_label, max_chars=300):\n",
        "    pattern = rf\"{re.escape(start_label)}\\s*(.+?)\\s*{re.escape(end_label)}\"\n",
        "    m = re.search(pattern, text, re.IGNORECASE | re.DOTALL)\n",
        "    if m:\n",
        "        return re.sub(r\"\\s+\\n\", \"\\n\", m.group(1).strip())[:max_chars]\n",
        "    return None\n",
        "\n",
        "def estimate_conf_for_value(value, ocr_words, ocr_confs):\n",
        "    # Approximate confidence: average conf of tokens present in OCR word list\n",
        "    if not value:\n",
        "        return None\n",
        "    tokens = re.findall(r\"[A-Za-z0-9]+(?:\\.\\d+)?\", value)\n",
        "    confs = []\n",
        "    ow = [w.lower() for w in ocr_words]\n",
        "    for t in tokens:\n",
        "        t_low = t.lower()\n",
        "        # collect all occurrences to be robust\n",
        "        matches = [ocr_confs[i] for i, w in enumerate(ow) if w == t_low and ocr_confs[i] >= 0]\n",
        "        confs.extend(matches)\n",
        "    return round(statistics.mean(confs), 1) if confs else None\n",
        "\n",
        "# --- Fetch & rasterize first page ---\n",
        "pdf_bytes, final_url = fetch_pdf(PDF_URL)\n",
        "doc = fitz.open(stream=pdf_bytes, filetype=\"pdf\")\n",
        "page = doc[0]\n",
        "pix = page.get_pixmap(dpi=DPI, alpha=False)\n",
        "img = Image.open(io.BytesIO(pix.tobytes(\"png\")))\n",
        "\n",
        "# --- OCR ---\n",
        "data, full_text = ocr_page(img, langs=LANGS)\n",
        "\n",
        "# Collect OCR words + confs for confidence estimates\n",
        "ocr_words = []\n",
        "ocr_confs = []\n",
        "for t, c in zip(data[\"text\"], data[\"conf\"]):\n",
        "    txt = (t or \"\").strip()\n",
        "    try:\n",
        "        conf = float(c)\n",
        "    except Exception:\n",
        "        conf = -1.0\n",
        "    if txt:\n",
        "        ocr_words.append(txt)\n",
        "        ocr_confs.append(conf)\n",
        "\n",
        "# --- Regex-based extraction rules (tuned for the sample invoice) ---\n",
        "fields = {}\n",
        "fields[\"invoice_number\"] = find_field(r\"Invoice\\s+Number\\s*([A-Za-z0-9-]+)\", full_text)\n",
        "fields[\"order_number\"]   = find_field(r\"Order\\s+Number\\s*([A-Za-z0-9-]+)\", full_text)\n",
        "fields[\"invoice_date\"]   = find_field(r\"Invoice\\s+Date\\s*([A-Za-z]+\\s+\\d{1,2},\\s*\\d{4})\", full_text)\n",
        "fields[\"due_date\"]       = find_field(r\"Due\\s+Date\\s*([A-Za-z]+\\s+\\d{1,2},\\s*\\d{4})\", full_text)\n",
        "fields[\"total_due\"]      = find_field(r\"Total\\s+Due\\s*\\$?([0-9,]+\\.\\d{2})\", full_text) or \\\n",
        "                           find_field(r\"\\bTotal\\s*\\$?([0-9,]+\\.\\d{2})\", full_text)\n",
        "# Emails (grab first two as from/to emails)\n",
        "emails = re.findall(r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\", full_text)\n",
        "fields[\"emails\"] = emails[:2] if emails else []\n",
        "\n",
        "# Blocks (rough cut) between markers\n",
        "fields[\"from_block\"] = block_between(full_text, \"From:\", \"Invoice Number\") \\\n",
        "    or block_between(full_text, \"From:\", \"Invoice Date\")\n",
        "fields[\"to_block\"]   = block_between(full_text, \"To:\",   \"Invoice Number\") \\\n",
        "    or block_between(full_text, \"To:\",   \"Invoice Date\")\n",
        "\n",
        "# --- Confidence estimates per field (approximate) ---\n",
        "conf = {}\n",
        "for k, v in fields.items():\n",
        "    if isinstance(v, str):\n",
        "        conf[k] = estimate_conf_for_value(v, ocr_words, ocr_confs)\n",
        "    elif isinstance(v, list) and v:\n",
        "        conf[k] = estimate_conf_for_value(\" \".join(v), ocr_words, ocr_confs)\n",
        "    else:\n",
        "        conf[k] = None\n",
        "\n",
        "# --- Build result JSON ---\n",
        "result = {\n",
        "    \"source_url\": final_url,\n",
        "    \"pages_total\": doc.page_count,\n",
        "    \"dpi\": DPI,\n",
        "    \"lang\": LANGS,\n",
        "    \"extracted\": fields,\n",
        "    \"confidence_estimates\": conf,\n",
        "    \"preview_text\": full_text[:800].strip()\n",
        "}\n",
        "\n",
        "print(\"âœ… OCR + data extraction result:\\n\")\n",
        "print(json.dumps(result, indent=2, ensure_ascii=False))\n",
        "\n",
        "# --- Show a friendly table preview ---\n",
        "kv_rows = [{\"field\": k, \"value\": (\", \".join(v) if isinstance(v, list) else v), \"approx_conf\": conf[k]} for k, v in fields.items()]\n",
        "df = pd.DataFrame(kv_rows)\n",
        "print(\"\\nğŸ” Extracted fields (preview):\")\n",
        "display(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 910
        },
        "id": "cRuyPS5Xk4pm",
        "outputId": "d51b97ee-dbae-4527-edd6-30a71523297d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… OCR + data extraction result:\n",
            "\n",
            "{\n",
            "  \"source_url\": \"https://slicedinvoices.com/pdf/wordpress-pdf-invoice-plugin-sample.pdf\",\n",
            "  \"pages_total\": 1,\n",
            "  \"dpi\": 300,\n",
            "  \"lang\": \"eng\",\n",
            "  \"extracted\": {\n",
            "    \"invoice_number\": null,\n",
            "    \"order_number\": \"12345\",\n",
            "    \"invoice_date\": null,\n",
            "    \"due_date\": null,\n",
            "    \"total_due\": \"85.00\",\n",
            "    \"emails\": [\n",
            "      \"test@test.com\",\n",
            "      \"admin@slicedinvoices.com\"\n",
            "    ],\n",
            "    \"from_block\": null,\n",
            "    \"to_block\": null\n",
            "  },\n",
            "  \"confidence_estimates\": {\n",
            "    \"invoice_number\": null,\n",
            "    \"order_number\": 96.0,\n",
            "    \"invoice_date\": null,\n",
            "    \"due_date\": null,\n",
            "    \"total_due\": null,\n",
            "    \"emails\": 91.0,\n",
            "    \"from_block\": null,\n",
            "    \"to_block\": null\n",
            "  },\n",
            "  \"preview_text\": \"Â© icednvoices\\n\\nFrom:\\n\\nDEMO - Sliced Invoices Order Number 12345\\n\\nSuite 54-1204 January 25, 2016\\n\\n123 Somewhere Street January 31, 2016\\n\\nadmin @slicedinvoices.com otal nue .\\n\\nTo:\\n\\nTest Business\\n\\n123 Somewhere St\\n\\nMelbourne, VIC 3000\\n\\ntest@test.com\\n\\nWeb Design $85.00 0.00% $85.00\\nThis is a sample description...\\n\\nSub Total $85.00\\n$8.50\\n$93.50\\n\\nANZ Bank\\n\\nACC # 1234 1234\\n\\nBSB # 4321 432\\n\\nPayment is due within 30 days from date of invoice. Late payment is subject to fees of 5% per month.\\nThanks for choosing DEMO - Sliced Invoices | admin@slicedinvoices.com\\n\\nPage 1/1\"\n",
            "}\n",
            "\n",
            "ğŸ” Extracted fields (preview):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "            field                                    value  approx_conf\n",
              "0  invoice_number                                     None          NaN\n",
              "1    order_number                                    12345         96.0\n",
              "2    invoice_date                                     None          NaN\n",
              "3        due_date                                     None          NaN\n",
              "4       total_due                                    85.00          NaN\n",
              "5          emails  test@test.com, admin@slicedinvoices.com         91.0\n",
              "6      from_block                                     None          NaN\n",
              "7        to_block                                     None          NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-93b38dd0-507e-4fdb-981a-14bffb5e5285\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>field</th>\n",
              "      <th>value</th>\n",
              "      <th>approx_conf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>invoice_number</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>order_number</td>\n",
              "      <td>12345</td>\n",
              "      <td>96.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>invoice_date</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>due_date</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>total_due</td>\n",
              "      <td>85.00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>emails</td>\n",
              "      <td>test@test.com, admin@slicedinvoices.com</td>\n",
              "      <td>91.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>from_block</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>to_block</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93b38dd0-507e-4fdb-981a-14bffb5e5285')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-93b38dd0-507e-4fdb-981a-14bffb5e5285 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-93b38dd0-507e-4fdb-981a-14bffb5e5285');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-89e81c97-ddbf-4eee-b1c2-c66b53c4ecce\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-89e81c97-ddbf-4eee-b1c2-c66b53c4ecce')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-89e81c97-ddbf-4eee-b1c2-c66b53c4ecce button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_c722a30b-b24a-46c2-b12b-10d812393c8e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c722a30b-b24a-46c2-b12b-10d812393c8e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"field\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"order_number\",\n          \"emails\",\n          \"invoice_number\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"value\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"12345\",\n          \"85.00\",\n          \"test@test.com, admin@slicedinvoices.com\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"approx_conf\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.5355339059327378,\n        \"min\": 91.0,\n        \"max\": 96.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          91.0,\n          96.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Common Crawl**\n",
        "\n",
        "A massive dataset of raw web data extracted from billions of web pages, widely used for training LLMs like GPT-3 and LLaMA"
      ],
      "metadata": {
        "id": "FYncozmmk4ek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Common Crawl mini-sampler (WET) â†’ DataFrame + JSON\n",
        "# It downloads the list of WET files for a crawl, picks one WET.gz, streams only the first N text records,\n",
        "# shows them in a pandas DataFrame, and saves a JSON snapshot to /content/cc_subset.json.\n",
        "\n",
        "# â€”â€”â€” Setup â€”â€”â€”\n",
        "!pip -q install requests warcio pandas\n",
        "\n",
        "import gzip, io, json, random, itertools\n",
        "from typing import List, Dict\n",
        "import requests\n",
        "import pandas as pd\n",
        "from warcio.archiveiterator import ArchiveIterator\n",
        "from IPython.display import display\n",
        "\n",
        "# â€”â€”â€” Parameters (editable in Colab UI) â€”â€”â€”\n",
        "CRAWL = \"CC-MAIN-2024-22\"  #@param {type:\"string\"}\n",
        "DOCS_TO_SHOW = 20          #@param {type:\"slider\", min:5, max:100, step:5}\n",
        "KEYWORD_FILTER = \"\"        #@param {type:\"string\"}\n",
        "RANDOMIZE_WET_FILE = True  #@param {type:\"boolean\"}\n",
        "\n",
        "USER_AGENT = \"ColabDemo/1.0 (contact: your_email@example.com)\"\n",
        "\n",
        "session = requests.Session()\n",
        "session.headers.update({\"User-Agent\": USER_AGENT})\n",
        "\n",
        "# â€”â€”â€” 1) Get the list of WET files for this crawl â€”â€”â€”\n",
        "wet_list_url = f\"https://data.commoncrawl.org/crawl-data/{CRAWL}/wet.paths.gz\"\n",
        "r = session.get(wet_list_url, timeout=60)\n",
        "r.raise_for_status()\n",
        "wet_paths = gzip.decompress(r.content).decode(\"utf-8\").strip().splitlines()\n",
        "assert wet_paths, \"No WET paths found for this crawl.\"\n",
        "\n",
        "# Pick a WET file (random or first for determinism)\n",
        "wet_path = random.choice(wet_paths) if RANDOMIZE_WET_FILE else wet_paths[0]\n",
        "wet_url = f\"https://data.commoncrawl.org/{wet_path}\"\n",
        "print(f\"Using WET file:\\n{wet_url}\\n\")\n",
        "\n",
        "# â€”â€”â€” 2) Stream the WET.gz and extract the first N conversion records (plain text) â€”â€”â€”\n",
        "resp = session.get(wet_url, stream=True, timeout=120)\n",
        "resp.raise_for_status()\n",
        "# ensure streaming decompression\n",
        "resp.raw.decode_content = True\n",
        "gz = gzip.GzipFile(fileobj=resp.raw)\n",
        "\n",
        "rows: List[Dict] = []\n",
        "seen = 0\n",
        "keyword = KEYWORD_FILTER.strip().lower()\n",
        "\n",
        "for record in ArchiveIterator(gz):\n",
        "    # WET files store text in 'conversion' records\n",
        "    if record.rec_type != \"conversion\":\n",
        "        continue\n",
        "\n",
        "    url = record.rec_headers.get_header(\"WARC-Target-URI\") or \"\"\n",
        "    payload = record.content_stream().read()\n",
        "    text = payload.decode(\"utf-8\", errors=\"replace\")\n",
        "\n",
        "    if keyword and (keyword not in text.lower()) and (keyword not in url.lower()):\n",
        "        continue  # simple keyword filter\n",
        "\n",
        "    rows.append({\n",
        "        \"url\": url,\n",
        "        \"chars\": len(text),\n",
        "        \"snippet\": text[:300].replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
        "    })\n",
        "    seen += 1\n",
        "    if seen >= DOCS_TO_SHOW:\n",
        "        break\n",
        "\n",
        "# â€”â€”â€” 3) Display & save â€”â€”â€”\n",
        "if not rows:\n",
        "    print(\"No records matched the filter. Try clearing KEYWORD_FILTER or increasing DOCS_TO_SHOW.\")\n",
        "else:\n",
        "    df = pd.DataFrame(rows)\n",
        "    display(df)\n",
        "\n",
        "    out_path = \"/content/cc_subset.json\"\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(rows, f, ensure_ascii=False, indent=2)\n",
        "    print(f\"\\nSaved {len(rows)} records to {out_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "BMlJBbOclt1w",
        "outputId": "d7c2de41-de19-42f5-f1d5-912ff548a5e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using WET file:\n",
            "https://data.commoncrawl.org/crawl-data/CC-MAIN-2024-22/segments/1715971059418.31/wet/CC-MAIN-20240530021529-20240530051529-00110.warc.wet.gz\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                  url  chars  \\\n",
              "0           http://024zhendongshixiao.com/chanpin.asp    541   \n",
              "1                            http://111.6.83.33:8099/   1781   \n",
              "2                             http://1149.jp/menseki/     74   \n",
              "3            http://11radio.com/voddetail/428789.html   1650   \n",
              "4                         http://120zxk.com/gnzy.html   1905   \n",
              "5              http://13.36.34.64/lhistoire-en-video/   4558   \n",
              "6                       http://17xx.top/97447755.html    708   \n",
              "7   http://2.beradm.z8.ru/index.php?id=2393&start=740   6637   \n",
              "8   http://2024n.tokiwa-home.jp/2017/06/28/%E3%83%...   2743   \n",
              "9   http://215072.homepagemodules.de/t508317f11776...   7484   \n",
              "10                   http://216.83.47.238/?ref=1F9EEA   5443   \n",
              "11  http://2ch.omorovie.com/2019/01/11/%E3%80%90%E...     74   \n",
              "12  http://2chlena.com/brunetki/106-na-paru-s-drug...   1612   \n",
              "13  http://2fwww.fountainmagazine.com/all-issues/1...  18079   \n",
              "14               http://3-gin.net/d-mituhide-top.html   1841   \n",
              "15  http://335974.ym98g.com/?PUT=a_show&AID=160129...   5431   \n",
              "16  http://335by.com/index.phtml?PUT=gift_send&AID...    217   \n",
              "17  http://356.schoollibrary.edu.pe.ca/cgi-bin/koh...   2214   \n",
              "18  http://356.schoollibrary.edu.pe.ca/cgi-bin/koh...   2348   \n",
              "19  http://356.schoollibrary.edu.pe.ca/cgi-bin/koh...   2360   \n",
              "\n",
              "                                              snippet  \n",
              "0   æŒ¯åŠ¨æ—¶æ•ˆ ï¼Œæ²ˆé˜³æŒ¯åŠ¨æ—¶æ•ˆï¼Œ æŒ¯åŠ¨æ—¶æ•ˆè®¾å¤‡ï¼Œæ²ˆé˜³è¾½æ²³æŒ¯åŠ¨æœºæ¢°å‚æ˜¯ä¸“ä¸šç”Ÿäº§\"æŒ¯åŠ¨æ—¶æ•ˆè®¾å¤‡\"çš„å…¬å¸...  \n",
              "1   ä¿¡ç”¨æ½¢å· ä¿¡ç”¨æ½¢å·æ¬¢è¿æ‚¨ï¼ åå°ç™»å½• | æ— éšœç¢ APPä¸‹è½½ | åå°ç™»å½• æ¬¢è¿æ‚¨ï¼šæå¸…æ»¨ï¼...  \n",
              "2   One moment, please... Please wait while your r...  \n",
              "3   ã€Šå†²ç”°ææ¢¨å“ªéƒ¨æœ€å¥½çœ‹ã€‹ è‰²YEYEé¦™è•‰å‡¹å‡¸ä¸€åŒºäºŒåŒº-6699å«©è‰ä¹…ä¹…ä¹…ç²¾å“å½±é™¢ä¹…ä¹…ä¹…ä¹…æ— ç å›½...  \n",
              "4   å›½äº§ç²¾å“æ— ç ç‚¹å‡»è¿›å…¥å…è´¹,äºšæ´²av æ—¥éŸ©ç²¾å“é«˜æ¸…ç‹¼äººè‰² æœç´¢ è§‚çœ‹å†å² æ’­æ”¾å†å² é¦–é¡µ Â· ...  \n",
              "5   MEDIATHEQUE VIDEO - WEBTUBE.fr - RUTUBE.fr Ski...  \n",
              "6   17xx.top - é¦–é¡µ lnrbt.com wukanglu.com green-hn....  \n",
              "7   ĞĞ´Ğ¼Ğ¸Ğ½Ğ¸ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾ÑĞµĞ»ĞºĞ° Ğ‘ĞµÑ€ĞµĞ·Ğ¾Ğ²ĞºĞ° | Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ´...  \n",
              "8   ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸ãƒªãƒ‹ãƒ¥ãƒ¼ã‚¢ãƒ«ã®ãŠçŸ¥ã‚‰ã› - æ ªå¼ä¼šç¤¾ãƒˆã‚­ãƒ¯ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¸ã‚¹ã‚­ãƒƒãƒ— ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³...  \n",
              "9   RE: Synchronsprecher als SÃ¤nger - 44 Sie sind ...  \n",
              "10  Bolasenja Situs Bandar judi Bola & Mix Parlay ...  \n",
              "11  One moment, please... Please wait while your r...  \n",
              "12  ĞĞ° Ğ¿Ğ°Ñ€Ñƒ Ñ Ğ´Ñ€ÑƒĞ³Ğ¾Ğ¼ Ñ‚Ñ€Ğ°Ñ…Ğ½ÑƒĞ»Ğ¸ Ğ¶ĞµĞ½Ñƒ Â» Ğ”Ğ²Ğ¾Ğ¹Ğ½Ğ¾Ğµ Ğ¸ Ğ¢Ñ€Ğ¾...  \n",
              "13  Reflections on The Existence and Unity of The ...  \n",
              "14  D-æ˜æ™ºåå…µè¡›å…‰ç§€ è¬å¤šããƒ«ãƒ¼ãƒ„ã«è¿«ã‚‹ â€‹è¿‘æ±Ÿå¤šè³€å‡ºèº«èª¬! ã¤ãªãä¸‰éŠ€è”µ Home A-ä¸‰éŠ€...  \n",
              "15  hougongå¤å¨ƒå¾Œå®®è¦–è¨Š å›é¦–é  é»æ•¸è£œçµ¦ç«™ æœƒå“¡å°ˆå€ åŠ å…¥æœƒå“¡ ä½¿ç”¨èªªæ˜ ä»˜æ¬¾æ–¹å¼ å•é¡Œ...  \n",
              "16  å°æ¹¾uuèŠå¤©å®¤ å»ºè®®å°†æœ¬ç«™ åŠ å…¥æ”¶è—ï¼Œæ–¹ä¾¿æ—¥åæ‰¾å¯» å›é¦–é¡µ å…è´¹ä¸“åŒº ç‚¹æ•°å……å€¼ä¸­å¿ƒ ä¼šå‘˜ç™»å…¥...  \n",
              "17  PEI School Library System Catalog â€º Results of...  \n",
              "18  PEI School Library System Catalog â€º Results of...  \n",
              "19  PEI School Library System Catalog â€º Results of...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cff3d04d-0cd5-45e2-a582-e0193085333b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>chars</th>\n",
              "      <th>snippet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>http://024zhendongshixiao.com/chanpin.asp</td>\n",
              "      <td>541</td>\n",
              "      <td>æŒ¯åŠ¨æ—¶æ•ˆ ï¼Œæ²ˆé˜³æŒ¯åŠ¨æ—¶æ•ˆï¼Œ æŒ¯åŠ¨æ—¶æ•ˆè®¾å¤‡ï¼Œæ²ˆé˜³è¾½æ²³æŒ¯åŠ¨æœºæ¢°å‚æ˜¯ä¸“ä¸šç”Ÿäº§\"æŒ¯åŠ¨æ—¶æ•ˆè®¾å¤‡\"çš„å…¬å¸...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>http://111.6.83.33:8099/</td>\n",
              "      <td>1781</td>\n",
              "      <td>ä¿¡ç”¨æ½¢å· ä¿¡ç”¨æ½¢å·æ¬¢è¿æ‚¨ï¼ åå°ç™»å½• | æ— éšœç¢ APPä¸‹è½½ | åå°ç™»å½• æ¬¢è¿æ‚¨ï¼šæå¸…æ»¨ï¼...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>http://1149.jp/menseki/</td>\n",
              "      <td>74</td>\n",
              "      <td>One moment, please... Please wait while your r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>http://11radio.com/voddetail/428789.html</td>\n",
              "      <td>1650</td>\n",
              "      <td>ã€Šå†²ç”°ææ¢¨å“ªéƒ¨æœ€å¥½çœ‹ã€‹ è‰²YEYEé¦™è•‰å‡¹å‡¸ä¸€åŒºäºŒåŒº-6699å«©è‰ä¹…ä¹…ä¹…ç²¾å“å½±é™¢ä¹…ä¹…ä¹…ä¹…æ— ç å›½...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>http://120zxk.com/gnzy.html</td>\n",
              "      <td>1905</td>\n",
              "      <td>å›½äº§ç²¾å“æ— ç ç‚¹å‡»è¿›å…¥å…è´¹,äºšæ´²av æ—¥éŸ©ç²¾å“é«˜æ¸…ç‹¼äººè‰² æœç´¢ è§‚çœ‹å†å² æ’­æ”¾å†å² é¦–é¡µ Â· ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>http://13.36.34.64/lhistoire-en-video/</td>\n",
              "      <td>4558</td>\n",
              "      <td>MEDIATHEQUE VIDEO - WEBTUBE.fr - RUTUBE.fr Ski...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>http://17xx.top/97447755.html</td>\n",
              "      <td>708</td>\n",
              "      <td>17xx.top - é¦–é¡µ lnrbt.com wukanglu.com green-hn....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>http://2.beradm.z8.ru/index.php?id=2393&amp;start=740</td>\n",
              "      <td>6637</td>\n",
              "      <td>ĞĞ´Ğ¼Ğ¸Ğ½Ğ¸ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾ÑĞµĞ»ĞºĞ° Ğ‘ĞµÑ€ĞµĞ·Ğ¾Ğ²ĞºĞ° | Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ´...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>http://2024n.tokiwa-home.jp/2017/06/28/%E3%83%...</td>\n",
              "      <td>2743</td>\n",
              "      <td>ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸ãƒªãƒ‹ãƒ¥ãƒ¼ã‚¢ãƒ«ã®ãŠçŸ¥ã‚‰ã› - æ ªå¼ä¼šç¤¾ãƒˆã‚­ãƒ¯ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¸ã‚¹ã‚­ãƒƒãƒ— ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>http://215072.homepagemodules.de/t508317f11776...</td>\n",
              "      <td>7484</td>\n",
              "      <td>RE: Synchronsprecher als SÃ¤nger - 44 Sie sind ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>http://216.83.47.238/?ref=1F9EEA</td>\n",
              "      <td>5443</td>\n",
              "      <td>Bolasenja Situs Bandar judi Bola &amp; Mix Parlay ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>http://2ch.omorovie.com/2019/01/11/%E3%80%90%E...</td>\n",
              "      <td>74</td>\n",
              "      <td>One moment, please... Please wait while your r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>http://2chlena.com/brunetki/106-na-paru-s-drug...</td>\n",
              "      <td>1612</td>\n",
              "      <td>ĞĞ° Ğ¿Ğ°Ñ€Ñƒ Ñ Ğ´Ñ€ÑƒĞ³Ğ¾Ğ¼ Ñ‚Ñ€Ğ°Ñ…Ğ½ÑƒĞ»Ğ¸ Ğ¶ĞµĞ½Ñƒ Â» Ğ”Ğ²Ğ¾Ğ¹Ğ½Ğ¾Ğµ Ğ¸ Ğ¢Ñ€Ğ¾...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>http://2fwww.fountainmagazine.com/all-issues/1...</td>\n",
              "      <td>18079</td>\n",
              "      <td>Reflections on The Existence and Unity of The ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>http://3-gin.net/d-mituhide-top.html</td>\n",
              "      <td>1841</td>\n",
              "      <td>D-æ˜æ™ºåå…µè¡›å…‰ç§€ è¬å¤šããƒ«ãƒ¼ãƒ„ã«è¿«ã‚‹ â€‹è¿‘æ±Ÿå¤šè³€å‡ºèº«èª¬! ã¤ãªãä¸‰éŠ€è”µ Home A-ä¸‰éŠ€...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>http://335974.ym98g.com/?PUT=a_show&amp;AID=160129...</td>\n",
              "      <td>5431</td>\n",
              "      <td>hougongå¤å¨ƒå¾Œå®®è¦–è¨Š å›é¦–é  é»æ•¸è£œçµ¦ç«™ æœƒå“¡å°ˆå€ åŠ å…¥æœƒå“¡ ä½¿ç”¨èªªæ˜ ä»˜æ¬¾æ–¹å¼ å•é¡Œ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>http://335by.com/index.phtml?PUT=gift_send&amp;AID...</td>\n",
              "      <td>217</td>\n",
              "      <td>å°æ¹¾uuèŠå¤©å®¤ å»ºè®®å°†æœ¬ç«™ åŠ å…¥æ”¶è—ï¼Œæ–¹ä¾¿æ—¥åæ‰¾å¯» å›é¦–é¡µ å…è´¹ä¸“åŒº ç‚¹æ•°å……å€¼ä¸­å¿ƒ ä¼šå‘˜ç™»å…¥...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>http://356.schoollibrary.edu.pe.ca/cgi-bin/koh...</td>\n",
              "      <td>2214</td>\n",
              "      <td>PEI School Library System Catalog â€º Results of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>http://356.schoollibrary.edu.pe.ca/cgi-bin/koh...</td>\n",
              "      <td>2348</td>\n",
              "      <td>PEI School Library System Catalog â€º Results of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>http://356.schoollibrary.edu.pe.ca/cgi-bin/koh...</td>\n",
              "      <td>2360</td>\n",
              "      <td>PEI School Library System Catalog â€º Results of...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cff3d04d-0cd5-45e2-a582-e0193085333b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cff3d04d-0cd5-45e2-a582-e0193085333b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cff3d04d-0cd5-45e2-a582-e0193085333b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bb32a227-fc47-4992-aebc-09c8fd4cf5ae\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bb32a227-fc47-4992-aebc-09c8fd4cf5ae')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bb32a227-fc47-4992-aebc-09c8fd4cf5ae button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_49e99b2c-e59c-4bc9-b416-ab1e2e5afb76\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_49e99b2c-e59c-4bc9-b416-ab1e2e5afb76 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"http://024zhendongshixiao.com/chanpin.asp\",\n          \"http://356.schoollibrary.edu.pe.ca/cgi-bin/koha/opac-search.pl?q=su:Painters%20%20and%20su:United%20States%20%20and%20su:Biography&limit=branch:356&limit=branch:356&limit=branch:356&limit=branch:356&limit=branch:356&limit=branch:356&limit=branch:356&limit=branch:356&limit=branch:356&limit=branch:356&limit=branch:356&limit=branch:356&limit=branch:356&limit=branch:356&limit=branch:356&limit=su-to:Artists.&limit=su-to:Artists.&limit=au:Venezia,%20Mike.&limit=au:Venezia,%20Mike.&limit=su-to:Painting,%20American.&limit=su-to:Painting,%20American.&limit=su-to:Painters&limit=se:Getting%20to%20know%20the%20world's%20greatest%20artists&limit=su-to:Painting,%20American.&limit=su-to:Artists.&limit=su-to:Painters&limit=su-to:Painting,%20American.&limit=su-to:Artists.&limit=su-to:Artists.&sort_by=relevance_asc&limit=se:Getting%20to%20know%20the%20world's%20greatest%20artists\",\n          \"http://335974.ym98g.com/?PUT=a_show&AID=160129&FID=335974&R2=&CHANNEL=\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chars\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4087,\n        \"min\": 74,\n        \"max\": 18079,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          541,\n          4558,\n          1612\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"snippet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"\\u632f\\u52a8\\u65f6\\u6548 \\uff0c\\u6c88\\u9633\\u632f\\u52a8\\u65f6\\u6548\\uff0c \\u632f\\u52a8\\u65f6\\u6548\\u8bbe\\u5907\\uff0c\\u6c88\\u9633\\u8fbd\\u6cb3\\u632f\\u52a8\\u673a\\u68b0\\u5382\\u662f\\u4e13\\u4e1a\\u751f\\u4ea7\\\"\\u632f\\u52a8\\u65f6\\u6548\\u8bbe\\u5907\\\"\\u7684\\u516c\\u53f8\\uff01 \\u8bbe\\u4e3a\\u9996\\u9875 \\u52a0\\u5165\\u6536\\u85cf \\u8054\\u7cfb\\u6211\\u4eec 24\\u5c0f\\u65f6\\u670d\\u52a1\\u70ed\\u7ebf\\uff1a13504076972 \\u4ea7\\u54c1\\u5bfc\\u822a \\u667a\\u80fd\\u6db2\\u6676\\u632f\\u52a8\\u65f6\\u6548\\u88c5\\u7f6e \\u591a\\u529f\\u80fd\\u578b\\u632f\\u52a8\\u65f6\\u6548\\u88c5\\u7f6e \\u9ad8\\u7aef\\u5168\\u81ea\\u52a8\\u632f\\u52a8\\u65f6\\u6548\\u88c5\\u7f6e \\u667a\\u80fd\\u6570\\u7801\\u578b\\u632f\\u52a8\\u65f6\\u6548\\u88c5\\u7f6e \\u795e\\u5dde\\u8d85\\u80fd\\u578b\\u632f\\u52a8\\u65f6\\u6548\\u88c5\\u7f6e \\u8d85\\u7ea7\\u578b\\u632f\\u52a8\\u65f6\\u6548\\u88c5\\u7f6e \\u8054\\u7cfb\\u6211\\u4eec \\u6c88\\u9633\\u5e02\\u8fbd\\u6cb3\\u632f\\u52a8\\u673a\\u68b0\\u5382 \\u670d\\u52a1\\u70ed\\u7ebf\\uff1a13504076972 \\u7535 \\u8bdd\\uff1a024-24126545 \\u4f20 \\u771f\\uff1a\\u603b\\u673a\\u8f6c801 \\u624b \\u673a\\uff1a13066637772 \\u516c\\u53f8\\u5730\\u5740\\uff1a \\u6c88\\u9633\\u6c88\\u6cb3\\u533a\\u4f1a\\u6b66\\u885720\\u53f7 \\u4ea7\\u54c1\\u4e2d\\u5fc3 \\u9996\\u9875 > \\u4ea7\\u54c1\\u4e2d\\u5fc3 \\u632f\\u52a8\\u65f6\\u6548 ASR2010-7\\u771f\\u5f69\\u667a\\u80fd\\u632f\\u52a8\\u65f6\\u6548\\u88c5\\u7f6e ASR2010-\",\n          \"\\u4fe1\\u7528\\u6f62\\u5ddd \\u4fe1\\u7528\\u6f62\\u5ddd\\u6b22\\u8fce\\u60a8\\uff01 \\u540e\\u53f0\\u767b\\u5f55 | \\u65e0\\u969c\\u788d APP\\u4e0b\\u8f7d | \\u540e\\u53f0\\u767b\\u5f55 \\u6b22\\u8fce\\u60a8\\uff1a\\u674e\\u5e05\\u6ee8\\uff01\\u4e2a\\u4eba\\u4e2d\\u5fc3 | \\u9000\\u51fa \\u5b89\\u5353\\u5ba2\\u6237\\u7aef IOS\\u5ba2\\u6237\\u7aef \\u4f7f\\u7528\\u63d0\\u793a\\uff1a \\u7528\\u624b\\u673a\\u4e0a\\u7684\\u4e8c\\u7ef4\\u7801\\u626b\\u63cf\\u8f6f\\u4ef6\\u62cd\\u6444\\u5bf9\\u5e94\\u56fe\\u6807\\u53f3\\u4fa7\\u4e8c\\u7ef4\\u7801\\u4e0b\\u8f7d \\u5168\\u56fd\\u4e00\\u4f53\\u5316\\u4fe1\\u606f\\u67e5\\u8be2 \\u884c\\u653f\\u8bb8\\u53ef\\u4e0e\\u884c\\u653f\\u5904\\u7f5a \\u7ad9\\u5185\\u67e5\\u8be2 \\u9996 \\u9875 \\u4fe1\\u7528\\u52a8\\u6001 \\u653f\\u7b56\\u6cd5\\u89c4 \\u4fe1\\u606f\\u516c\\u793a \\u4fe1\\u7528\\u670d\\u52a1 \\u8054\\u5408\\u5956\\u60e9 \\u5178\\u578b\\u6848\\u4f8b \\u4e13\\u9879\\u6cbb\\u7406 \\u4fe1\\u7528\\u627f\\u8bfa \\u5931\\u4fe1\\u5b88\\u4fe1\\u540d\\u5355 \\u6f62\\u5ddd\\u53bf\\u4f4f\\u623f\\u548c\\u57ce\\u4e61\\u5efa\\u8bbe\\u5c40\\u5173\\u4e8e\\u6f62\\u5ddd\\u53bf2024\\u5e74\\u5f1f\\u4e09\\u6279\\u5efa\\u7b51\\u2026 \\u6f62\\u5ddd\\u53bf\\u6559\\u4f53\\u5c40\\u53ec\\u5f00\\u793e\\u4f1a\\u4fe1\\u7528\\u4f53\\u7cfb\\u5efa\\u8bbe\\u5ba3\\u4f20\\u5de5\\u4f5c\\u57f9\\u8bad\\u4f1a \\u5ba3\\u4f20\\u5165\\u4f01\\u4e1a\\uff0c\\u6253\\u901a\\u4fe1\\u7528\\u4f53\\u7cfb\\u653f\\u7b56\\u5ba3\\u4f20\\u843d\\u5b9e\\u201c\\u6700\\u540e\\u4e00\\u516c\\u91cc\\u201d \\u5173\\u4e8e\\u6cb3\\u5357\\u7701\\u8499\\u7396\\u5efa\\u7b51\\u5de5\\u7a0b\\u6709\\u9650\\u516c\\u53f8\\u3001\\u6cb3\\u5357\\u697c\\u4e91\\u5efa\\u7b51\\u5de5\\u7a0b\\u2026 \\u5173\\u4e8e\\u516c\\u5e03 2024\\u5e74\\u7b2c\\u4e8c\\u6279\\u5efa\\u7b51\\u4e1a\\u4f01\\u4e1a\\u8d44\",\n          \"\\u30db\\u30fc\\u30e0\\u30da\\u30fc\\u30b8\\u30ea\\u30cb\\u30e5\\u30fc\\u30a2\\u30eb\\u306e\\u304a\\u77e5\\u3089\\u305b - \\u682a\\u5f0f\\u4f1a\\u793e\\u30c8\\u30ad\\u30ef \\u30b3\\u30f3\\u30c6\\u30f3\\u30c4\\u3078\\u30b9\\u30ad\\u30c3\\u30d7 \\u30ca\\u30d3\\u30b2\\u30fc\\u30b7\\u30e7\\u30f3\\u306b\\u79fb\\u52d5 \\u30c8\\u30ad\\u30ef\\u306e\\u5bb6\\u3065\\u304f\\u308a \\u5168\\u9928\\u51b7\\u6696\\u623f\\u7a7a\\u8abf\\u30b7\\u30b9\\u30c6\\u30e0 \\u4e2d\\uff12\\u968e\\u306e\\u3042\\u308b\\u5bb6 \\u4e0d\\u52d5\\u7523\\u60c5\\u5831 \\u8c4a\\u91ce\\u753a\\u8c4a\\u91ce \\u4f0a\\u8c46\\u6bdb\\u5206\\u8b72\\u5730A\\u533a\\u753b\\u300093.1\\u576a(307.86\\u33a1) \\u8c4a\\u91ce\\u753a\\u8c4a\\u91ce \\u4f0a\\u8c46\\u6bdb\\u5206\\u8b72\\u5730C\\u533a\\u753b\\u300052.5\\u576a(173.55\\u33a1) \\u8c4a\\u91ce\\u753a\\u8c4a\\u91ce \\u4f0a\\u8c46\\u6bdb\\u5206\\u8b72\\u5730E\\u533a\\u753b\\u300077.2\\u576a(255.35\\u33a1) \\u8c4a\\u91ce\\u753a\\u8c4a\\u91ce \\u4f0a\\u8c46\\u6bdb\\u5206\\u8b72\\u5730F\\u533a\\u753b\\u300087.2\\u576a(288.45\\u33a1) \\u8c4a\\u91ce\\u753a\\u8c4a\\u91ce \\u4f0a\\u8c46\\u6bdb\\u5206\\u8b72\\u5730G\\u533a\\u753b\\u300099.4\\u576a(328.61\\u33a1) \\u5c55\\u793a\\u5834\\uff08\\u3068\\u304d\\u308f\\u5bb6\\uff09 \\u69d8\\u3005\\u306a\\u4f4f\\u307e\\u3044\\u4e8b\\u696d \\u4f1a\\u793e\\u6982\\u8981 \\u30b9\\u30bf\\u30c3\\u30d5\\u7d39\\u4ecb \\u3054\\u4e88\\u7d04\\u30fb\\u304a\\u554f\\u5408\\u305b \\u65b0\\u7740\\u60c5\\u5831 HOME \\u65b0\\u7740\\u60c5\\u5831 \\u30d6\\u30ed\\u30b0 \\u30db\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved 20 records to /content/cc_subset.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**C4 (Colossal Clean Crawled Corpus)**\n",
        "\n",
        "A 750 GB English corpus derived from Common Crawl, used to train models like MPT-7B and T5."
      ],
      "metadata": {
        "id": "zFfLgNZbmHQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title C4 (Colossal Clean Crawled Corpus) mini-sampler â†’ DataFrame + JSON\n",
        "# Streams from the Hugging Face \"allenai/c4\" dataset, samples N documents (optionally filtered by a keyword),\n",
        "# displays them in a pandas DataFrame, and saves to /content/c4_subset.json.\n",
        "\n",
        "# â€”â€”â€” Setup â€”â€”â€”\n",
        "!pip -q install datasets pandas\n",
        "\n",
        "import json, random\n",
        "from typing import List, Dict\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from datasets import load_dataset\n",
        "\n",
        "# â€”â€”â€” Parameters (editable in Colab UI) â€”â€”â€”\n",
        "C4_CONFIG = \"en\"           #@param [\"en\",\"en.noclean\",\"realnewslike\",\"multilingual\"]\n",
        "SPLIT = \"train\"            #@param [\"train\",\"validation\"]\n",
        "SAMPLES = 20               #@param {type:\"slider\", min:5, max:200, step:5}\n",
        "KEYWORD_FILTER = \"\"        #@param {type:\"string\"}\n",
        "MAX_RECORDS_TO_SCAN = 5000 #@param {type:\"integer\"}\n",
        "RANDOM_SEED = 42           #@param {type:\"integer\"}\n",
        "\n",
        "random.seed(RANDOM_SEED)\n",
        "kw = KEYWORD_FILTER.strip().lower()\n",
        "\n",
        "# â€”â€”â€” 1) Open C4 in streaming mode (no full download) â€”â€”â€”\n",
        "# Notes:\n",
        "# - \"allenai/c4\" is the canonical HF dataset ID.\n",
        "# - 'multilingual' contains 100+ languages; 'en.noclean' is the unfiltered English subset.\n",
        "ds = load_dataset(\"allenai/c4\", C4_CONFIG, split=SPLIT, streaming=True)\n",
        "\n",
        "# â€”â€”â€” 2) Reservoir-sample up to SAMPLES matching records â€”â€”â€”\n",
        "# Works well with streaming (single pass, bounded memory).\n",
        "sample: List[Dict] = []\n",
        "accepted = 0\n",
        "scanned = 0\n",
        "\n",
        "def keep_example(ex):\n",
        "    if not kw:\n",
        "        return True\n",
        "    t = ex.get(\"text\",\"\").lower()\n",
        "    u = ex.get(\"url\",\"\").lower()\n",
        "    return (kw in t) or (kw in u)\n",
        "\n",
        "for ex in ds:\n",
        "    scanned += 1\n",
        "    if keep_example(ex):\n",
        "        accepted += 1\n",
        "        if len(sample) < SAMPLES:\n",
        "            sample.append(ex)\n",
        "        else:\n",
        "            j = random.randint(0, accepted - 1)\n",
        "            if j < SAMPLES:\n",
        "                sample[j] = ex\n",
        "    if scanned >= MAX_RECORDS_TO_SCAN or len(sample) >= SAMPLES:\n",
        "        break\n",
        "\n",
        "# â€”â€”â€” 3) Display & save â€”â€”â€”\n",
        "if not sample:\n",
        "    print(\"No matches found. Try clearing KEYWORD_FILTER or increasing MAX_RECORDS_TO_SCAN.\")\n",
        "else:\n",
        "    rows = []\n",
        "    for ex in sample:\n",
        "        text = ex.get(\"text\",\"\")\n",
        "        url = ex.get(\"url\",\"\")\n",
        "        rows.append({\n",
        "            \"url\": url,\n",
        "            \"chars\": len(text),\n",
        "            \"snippet\": text[:300].replace(\"\\n\",\" \").replace(\"\\r\",\" \")\n",
        "        })\n",
        "    df = pd.DataFrame(rows)\n",
        "    display(df)\n",
        "\n",
        "    out_path = \"/content/c4_subset.json\"\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(rows, f, ensure_ascii=False, indent=2)\n",
        "    print(f\"\\nSaved {len(rows)} records to {out_path}\")\n",
        "    print(f\"Config: {C4_CONFIG} | Split: {SPLIT} | Scanned: {scanned} records\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792,
          "referenced_widgets": [
            "c1d8560caf29499d95c231260446c6a7",
            "fded41de14594b27a9ef347dc2806e87",
            "6096e648e5aa4be5877ca6f725b83fdf",
            "5cdcd576f7d143eea7c8d40ff62c734c",
            "a589e8d2e01f4f78bbc90aa5c2e47fa0",
            "f15c8476671541f783b33c70ad590b1d",
            "7835114338194d2997d87c7454bd5ab7",
            "3bc4c280441c407b969aeabe5c2b25fb",
            "39ada13d4a534367b0cb281616ccb230",
            "62bf96bde7ec420fa8f495e9f2c9166a",
            "48577a070c1443bc8f1ff774209dd1f4",
            "13fb1304be794ccbb80c0d6fa8c8dfc4",
            "086c040f37f54827bce61d67084fb252",
            "2f9e9aa9811a4cefa081e3375e40c5d2",
            "005fd6769dce49658390d205e9ff2099",
            "71863a22488442e49bf039f68e42ec5b",
            "e05526b085fa4bf19d316d500be84335",
            "7f098778e12a47da99f903cf6408a74d",
            "07f78f2090a54fa48321116e90536be1",
            "0c304d1c0589482185b2b9c6bf22dc84",
            "cba60ab719154c28948fd318c9c64d95",
            "38bc0986e2834d22901d1c8cc53dd473"
          ]
        },
        "id": "ZbZF5dSOmRdF",
        "outputId": "41828104-0773-494e-fb6f-51d612503e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/1024 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1d8560caf29499d95c231260446c6a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/1024 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13fb1304be794ccbb80c0d6fa8c8dfc4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                  url  chars  \\\n",
              "0   https://klyq.com/beginners-bbq-class-taking-pl...    747   \n",
              "1   https://forums.macrumors.com/threads/restore-f...   1628   \n",
              "2   https://awishcometrue.com/Catalogs/Clearance/T...    183   \n",
              "3   https://www.blackhatworld.com/seo/how-many-bac...    957   \n",
              "4               http://bond.dpsk12.org/category/news/   1013   \n",
              "5   https://tatkalforsure.com/trains-between-stati...    375   \n",
              "6     https://karaokegal.livejournal.com/1773485.html    213   \n",
              "7   http://www.iammeek.com/2018/06/the-rich-get-ri...    574   \n",
              "8   https://www.webcontacts.com.au/Biomedics-conta...    572   \n",
              "9   https://www.ibj.com/articles/53814-sysco-termi...   2116   \n",
              "10  http://layarbioskop21.info/search/peace-breake...    260   \n",
              "11  http://trivisionglobal.com/members-dashboard/t...   1414   \n",
              "12   http://www.colby.edu/directory/profile/dwfindla/   1171   \n",
              "13  https://community.homestead.com/homestead/topi...    398   \n",
              "14  http://hotel-east-bourne-resort-and-spa-shimla...    223   \n",
              "15        https://kitchenbyte.com/best-bakeware-sets/  11080   \n",
              "16  https://conversation.which.co.uk/technology/do...   4218   \n",
              "17  https://www.archiscene.net/tower/four-frankfur...   2164   \n",
              "18  http://www.dgupost.com/news/articleView.html?i...   1649   \n",
              "19  http://new.minerals.net/gemstone/quartz_gemsto...   7522   \n",
              "\n",
              "                                              snippet  \n",
              "0   Beginners BBQ Class Taking Place in Missoula! ...  \n",
              "1   Discussion in 'Mac OS X Lion (10.7)' started b...  \n",
              "2   Foil plaid lycra and spandex shortall with met...  \n",
              "3   How many backlinks per day for new site? Discu...  \n",
              "4   The Denver Board of Education opened the 2017-...  \n",
              "5   BANGALORE CY JUNCTION SBC to GONDIA JUNCTION G...  \n",
              "6   I thought I was going to finish the 3rd season...  \n",
              "7   The rich get richer and the poor get poorer eh...  \n",
              "8   Biomedics 1 Day Extra are daily replacement di...  \n",
              "9   Sysco Corp. has terminated its planned $3.5 bi...  \n",
              "10  Pencarian FILM Untuk \"Peace Breaker 2017\" yuk ...  \n",
              "11  Below you'll find some great videos that will ...  \n",
              "12  \"Unemployment, Relative Price Dispersion and t...  \n",
              "13  I have existing web site brittlloyd.org. I ope...  \n",
              "14  Embrace world class facilities at East Bourne ...  \n",
              "15  \"Bake me a pie or go away,\" I've literally had...  \n",
              "16  Are film trailers spoiling movies? In April we...  \n",
              "17  UNStudio has joined forces with HPP Architects...  \n",
              "18  â–²Students are shouting several slogans to guar...  \n",
              "19  Quartz is one of the most common and varied mi...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71b06618-4c22-418a-896a-055f67ab8cd9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>chars</th>\n",
              "      <th>snippet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://klyq.com/beginners-bbq-class-taking-pl...</td>\n",
              "      <td>747</td>\n",
              "      <td>Beginners BBQ Class Taking Place in Missoula! ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://forums.macrumors.com/threads/restore-f...</td>\n",
              "      <td>1628</td>\n",
              "      <td>Discussion in 'Mac OS X Lion (10.7)' started b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://awishcometrue.com/Catalogs/Clearance/T...</td>\n",
              "      <td>183</td>\n",
              "      <td>Foil plaid lycra and spandex shortall with met...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://www.blackhatworld.com/seo/how-many-bac...</td>\n",
              "      <td>957</td>\n",
              "      <td>How many backlinks per day for new site? Discu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>http://bond.dpsk12.org/category/news/</td>\n",
              "      <td>1013</td>\n",
              "      <td>The Denver Board of Education opened the 2017-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>https://tatkalforsure.com/trains-between-stati...</td>\n",
              "      <td>375</td>\n",
              "      <td>BANGALORE CY JUNCTION SBC to GONDIA JUNCTION G...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>https://karaokegal.livejournal.com/1773485.html</td>\n",
              "      <td>213</td>\n",
              "      <td>I thought I was going to finish the 3rd season...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>http://www.iammeek.com/2018/06/the-rich-get-ri...</td>\n",
              "      <td>574</td>\n",
              "      <td>The rich get richer and the poor get poorer eh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>https://www.webcontacts.com.au/Biomedics-conta...</td>\n",
              "      <td>572</td>\n",
              "      <td>Biomedics 1 Day Extra are daily replacement di...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>https://www.ibj.com/articles/53814-sysco-termi...</td>\n",
              "      <td>2116</td>\n",
              "      <td>Sysco Corp. has terminated its planned $3.5 bi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>http://layarbioskop21.info/search/peace-breake...</td>\n",
              "      <td>260</td>\n",
              "      <td>Pencarian FILM Untuk \"Peace Breaker 2017\" yuk ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>http://trivisionglobal.com/members-dashboard/t...</td>\n",
              "      <td>1414</td>\n",
              "      <td>Below you'll find some great videos that will ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>http://www.colby.edu/directory/profile/dwfindla/</td>\n",
              "      <td>1171</td>\n",
              "      <td>\"Unemployment, Relative Price Dispersion and t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>https://community.homestead.com/homestead/topi...</td>\n",
              "      <td>398</td>\n",
              "      <td>I have existing web site brittlloyd.org. I ope...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>http://hotel-east-bourne-resort-and-spa-shimla...</td>\n",
              "      <td>223</td>\n",
              "      <td>Embrace world class facilities at East Bourne ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>https://kitchenbyte.com/best-bakeware-sets/</td>\n",
              "      <td>11080</td>\n",
              "      <td>\"Bake me a pie or go away,\" I've literally had...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>https://conversation.which.co.uk/technology/do...</td>\n",
              "      <td>4218</td>\n",
              "      <td>Are film trailers spoiling movies? In April we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>https://www.archiscene.net/tower/four-frankfur...</td>\n",
              "      <td>2164</td>\n",
              "      <td>UNStudio has joined forces with HPP Architects...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>http://www.dgupost.com/news/articleView.html?i...</td>\n",
              "      <td>1649</td>\n",
              "      <td>â–²Students are shouting several slogans to guar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>http://new.minerals.net/gemstone/quartz_gemsto...</td>\n",
              "      <td>7522</td>\n",
              "      <td>Quartz is one of the most common and varied mi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71b06618-4c22-418a-896a-055f67ab8cd9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-71b06618-4c22-418a-896a-055f67ab8cd9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-71b06618-4c22-418a-896a-055f67ab8cd9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ea132553-30d0-4e2d-99c7-6533e750ca28\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ea132553-30d0-4e2d-99c7-6533e750ca28')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ea132553-30d0-4e2d-99c7-6533e750ca28 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_6b1aff2e-b61e-46d4-96ec-defaa6d6d031\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6b1aff2e-b61e-46d4-96ec-defaa6d6d031 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"https://klyq.com/beginners-bbq-class-taking-place-in-missoula/\",\n          \"https://www.archiscene.net/tower/four-frankfurt-unstudio/\",\n          \"https://kitchenbyte.com/best-bakeware-sets/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chars\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2759,\n        \"min\": 183,\n        \"max\": 11080,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          747,\n          2164,\n          11080\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"snippet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Beginners BBQ Class Taking Place in Missoula! Do you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class fo\",\n          \"UNStudio has joined forces with HPP Architects to create a consortium (UNS + HPP) to carry out the next phases of their winning project at the architectural design competition for FOUR Frankfurt. Take a look at the complete story after the jump. From the architects: The centrally located 16,000 squa\",\n          \"\\\"Bake me a pie or go away,\\\" I've literally had my son say that to me a few times. So, what was I to do except fulfilling his demand? Baking (not only pies), is a cooking method where tools DO actually make the man, which means that it is very hard or nearly impossible to do it successfully without p\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved 20 records to /content/c4_subset.json\n",
            "Config: en | Split: train | Scanned: 20 records\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RefinedWeb**\n",
        "\n",
        "A massive corpus of deduplicated and filtered tokens from Common Crawl, developed to train the Falcon-40B model."
      ],
      "metadata": {
        "id": "FQNTXalTmcjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title RefinedWeb mini-sampler â†’ DataFrame + JSON\n",
        "# Streams from Hugging Face \"tiiuae/falcon-refinedweb\", samples N docs (with optional keyword filter),\n",
        "# displays them in a pandas DataFrame, and saves to /content/refinedweb_subset.json.\n",
        "\n",
        "# â€”â€”â€” Setup â€”â€”â€”\n",
        "!pip -q install datasets pandas\n",
        "\n",
        "import json, random\n",
        "from typing import List, Dict\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from datasets import load_dataset\n",
        "\n",
        "# â€”â€”â€” Parameters (editable in Colab UI) â€”â€”â€”\n",
        "SAMPLES = 20                #@param {type:\"slider\", min:5, max:200, step:5}\n",
        "KEYWORD_FILTER = \"\"         #@param {type:\"string\"}\n",
        "MAX_RECORDS_TO_SCAN = 5000  #@param {type:\"integer\"}\n",
        "RANDOM_SEED = 42            #@param {type:\"integer\"}\n",
        "\n",
        "random.seed(RANDOM_SEED)\n",
        "kw = KEYWORD_FILTER.strip().lower()\n",
        "\n",
        "# â€”â€”â€” 1) Open RefinedWeb in streaming mode (no full download) â€”â€”â€”\n",
        "ds = load_dataset(\"tiiuae/falcon-refinedweb\", split=\"train\", streaming=True)\n",
        "\n",
        "# â€”â€”â€” 2) Reservoir-sample up to SAMPLES matching records â€”â€”â€”\n",
        "def keep_example(ex):\n",
        "    if not kw:\n",
        "        return True\n",
        "    t = (ex.get(\"content\") or \"\").lower()\n",
        "    u = (ex.get(\"url\") or \"\").lower()\n",
        "    return (kw in t) or (kw in u)\n",
        "\n",
        "sample: List[Dict] = []\n",
        "accepted = 0\n",
        "scanned = 0\n",
        "\n",
        "for ex in ds:\n",
        "    scanned += 1\n",
        "    if keep_example(ex):\n",
        "        accepted += 1\n",
        "        if len(sample) < SAMPLES:\n",
        "            sample.append(ex)\n",
        "        else:\n",
        "            j = random.randint(0, accepted - 1)\n",
        "            if j < SAMPLES:\n",
        "                sample[j] = ex\n",
        "    if scanned >= MAX_RECORDS_TO_SCAN or len(sample) >= SAMPLES:\n",
        "        break\n",
        "\n",
        "# â€”â€”â€” 3) Display & save â€”â€”â€”\n",
        "if not sample:\n",
        "    print(\"No matches found. Try clearing KEYWORD_FILTER or increasing MAX_RECORDS_TO_SCAN.\")\n",
        "else:\n",
        "    rows = []\n",
        "    for ex in sample:\n",
        "        content = ex.get(\"content\") or \"\"\n",
        "        rows.append({\n",
        "            \"url\": ex.get(\"url\") or \"\",\n",
        "            \"timestamp\": str(ex.get(\"timestamp\") or \"\"),\n",
        "            \"dump\": ex.get(\"dump\") or \"\",\n",
        "            \"segment\": ex.get(\"segment\") or \"\",\n",
        "            \"images_found\": len(ex.get(\"image_urls\") or []),\n",
        "            \"chars\": len(content),\n",
        "            \"snippet\": content[:300].replace(\"\\n\",\" \").replace(\"\\r\",\" \")\n",
        "        })\n",
        "    df = pd.DataFrame(rows)\n",
        "    display(df)\n",
        "\n",
        "    out_path = \"/content/refinedweb_subset.json\"\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(rows, f, ensure_ascii=False, indent=2)\n",
        "    print(f\"\\nSaved {len(rows)} records to {out_path}\")\n",
        "    print(f\"Scanned: {scanned} | Accepted: {accepted} | Keyword: {KEYWORD_FILTER!r}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760,
          "referenced_widgets": [
            "97158974b3f044cf873a6f09f81cd16b",
            "3711aa05bc414cd29fb62bb460d8f011",
            "dd545e189b7d46d98f501c685cbd009f",
            "f7af9f5dbfc74e49a44352b9848d9ecb",
            "a8963db493ff4879abc9f1bc2798ce59",
            "2af7ba6c06f64bd8ac8c08e230d7dc13",
            "a504bd060a3d490d843ac70c0757cc89",
            "91a2ad4fc7954d06a4e72549e81d093a",
            "d0541fbe7ca04f6a8324c0b012a0eb4c",
            "57f8b006f30a44feaa89acf7e99608d5",
            "5f44afbefc0342eda04ba563303e12bd"
          ]
        },
        "id": "uSpyFfTamgkJ",
        "outputId": "1ca03b7a-6dc3-4b99-aeee-a682d0c698f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/5534 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97158974b3f044cf873a6f09f81cd16b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                  url            timestamp  \\\n",
              "0   http://100parts.wordpress.com/2012/08/04/astra...  2013-05-18 10:42:00   \n",
              "1   http://100percentwinnersblog.com/watch-survivo...  2013-05-18 11:02:03   \n",
              "2   http://101squadron.com/blog/2007/05/pesky-pecu...  2013-05-18 10:21:35   \n",
              "3              http://1037theloon.com/tags/scorpions/  2013-05-18 10:21:51   \n",
              "4     http://1063thebuzz.com/category/reviews/page/7/  2013-05-18 10:31:09   \n",
              "5   http://1069therock.com/billy-gibbons-co-oh-wel...  2013-05-18 10:32:50   \n",
              "6   http://1075zoofm.com/silent-hill-revelation-3d...  2013-05-18 10:40:29   \n",
              "7   http://1079ishot.com/taylor-swift-justin-biebe...  2013-05-18 10:31:04   \n",
              "8                  http://1940.iwm.org.uk/?page_id=13  2013-05-18 10:54:03   \n",
              "9   http://1heckofaguy.com/2011/10/16/leonard-cohe...  2013-05-18 10:13:18   \n",
              "10        http://1md.be/works/alpro-soya-stay-curious  2013-05-18 11:01:55   \n",
              "11                  http://1sorrowmadeyou.tumblr.com/  2013-05-18 10:21:03   \n",
              "12  http://2010.nyc.wordcamp.org/2010/09/07/call-f...  2013-05-18 10:41:52   \n",
              "13      http://2012planetx.info/archives/date/2011/05  2013-05-18 10:21:37   \n",
              "14  http://247wallst.com/2013/01/07/todays-market-...  2013-05-18 10:54:15   \n",
              "15  http://2languages2worlds.wordpress.com/tag/fre...  2013-05-18 10:12:07   \n",
              "16  http://30daysofautism.wordpress.com/tag/advocacy/  2013-05-18 10:22:15   \n",
              "17  http://365days2play.com/category/3-2-shopping-...  2013-05-18 10:12:38   \n",
              "18  http://3sistersvillage.com/blog/2011/11/9/post...  2013-05-18 10:41:26   \n",
              "19  http://4closurefraud.org/2010/10/25/sandusky-w...  2013-05-18 10:21:14   \n",
              "\n",
              "               dump        segment  images_found  chars  \\\n",
              "0   CC-MAIN-2013-20  1368696382261             0    514   \n",
              "1   CC-MAIN-2013-20  1368696382261             0  10583   \n",
              "2   CC-MAIN-2013-20  1368696382261             5    195   \n",
              "3   CC-MAIN-2013-20  1368696382261             0    501   \n",
              "4   CC-MAIN-2013-20  1368696382261            13    201   \n",
              "5   CC-MAIN-2013-20  1368696382261             3    905   \n",
              "6   CC-MAIN-2013-20  1368696382261             1   3967   \n",
              "7   CC-MAIN-2013-20  1368696382261             1   1603   \n",
              "8   CC-MAIN-2013-20  1368696382261             0   1992   \n",
              "9   CC-MAIN-2013-20  1368696382261             0   3294   \n",
              "10  CC-MAIN-2013-20  1368696382261             3    440   \n",
              "11  CC-MAIN-2013-20  1368696382261             0    409   \n",
              "12  CC-MAIN-2013-20  1368696382261             0    873   \n",
              "13  CC-MAIN-2013-20  1368696382261             0   1184   \n",
              "14  CC-MAIN-2013-20  1368696382261             0   1315   \n",
              "15  CC-MAIN-2013-20  1368696382261             0     24   \n",
              "16  CC-MAIN-2013-20  1368696382261             0   1253   \n",
              "17  CC-MAIN-2013-20  1368696382261             0   1956   \n",
              "18  CC-MAIN-2013-20  1368696382261             7   1721   \n",
              "19  CC-MAIN-2013-20  1368696382261             0   6633   \n",
              "\n",
              "                                              snippet  \n",
              "0   these birches can be found in many places in E...  \n",
              "1   Watch Survivor Redemption Island Season 22 Epi...  \n",
              "2   Pesky? this was a high school project for a pr...  \n",
              "3   metalkingdom.net [ 80â€²s @ 8 Feature Video â€“ Bi...  \n",
              "4   Splice Review Black Ops Escalation Map Pack [V...  \n",
              "5   Billy Gibbons & Co., â€˜Oh Wellâ€™ â€“ Song Review J...  \n",
              "6   â€˜Silent Hill: Revelation 3Dâ€™ Review As far as ...  \n",
              "7   Taylor Swift, Justin Bieber, Lady Gaga + More ...  \n",
              "8   All branches of the Imperial War Museum are co...  \n",
              "9   Yep â€“ Itâ€™s Another Do I Have To Dance All Nigh...  \n",
              "10  Stay Curious Alpro We created the 'interactive...  \n",
              "11  I got off the plane, grabbed my bags, I saw sh...  \n",
              "12  Call for Speakers! This is it! Finally weâ€™re t...  \n",
              "13  Wednesday, June 1, 2011 5 PM PST / 8 PM EST Ch...  \n",
              "14  The stock market is down Monday, with the Dow ...  \n",
              "15                           Posts Tagged frequency Â»  \n",
              "16  Autism Positivity Autism Positivity - Increasi...  \n",
              "17  Iâ€™ve never seen Meatworks full before in the n...  \n",
              "18  Postcards from a Global Trekker: Cape Town, So...  \n",
              "19  Rhonda D. McLaughlin vs Bank of America â€“ Sand...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-626c7e6e-4950-4762-b43d-94f94ccedd2f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>dump</th>\n",
              "      <th>segment</th>\n",
              "      <th>images_found</th>\n",
              "      <th>chars</th>\n",
              "      <th>snippet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>http://100parts.wordpress.com/2012/08/04/astra...</td>\n",
              "      <td>2013-05-18 10:42:00</td>\n",
              "      <td>CC-MAIN-2013-20</td>\n",
              "      <td>1368696382261</td>\n",
              "      <td>0</td>\n",
              "      <td>514</td>\n",
              "      <td>these birches can be found in many places in E...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>http://100percentwinnersblog.com/watch-survivo...</td>\n",
              "      <td>2013-05-18 11:02:03</td>\n",
              "      <td>CC-MAIN-2013-20</td>\n",
              "      <td>1368696382261</td>\n",
              "      <td>0</td>\n",
              "      <td>10583</td>\n",
              "      <td>Watch Survivor Redemption Island Season 22 Epi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>http://101squadron.com/blog/2007/05/pesky-pecu...</td>\n",
              "      <td>2013-05-18 10:21:35</td>\n",
              "      <td>CC-MAIN-2013-20</td>\n",
              "      <td>1368696382261</td>\n",
              "      <td>5</td>\n",
              "      <td>195</td>\n",
              "      <td>Pesky? this was a high school project for a pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>http://1037theloon.com/tags/scorpions/</td>\n",
              "      <td>2013-05-18 10:21:51</td>\n",
              "      <td>CC-MAIN-2013-20</td>\n",
              "      <td>1368696382261</td>\n",
              "      <td>0</td>\n",
              "      <td>501</td>\n",
              "      <td>metalkingdom.net [ 80â€²s @ 8 Feature Video â€“ Bi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>http://1063thebuzz.com/category/reviews/page/7/</td>\n",
              "      <td>2013-05-18 10:31:09</td>\n",
              "      <td>CC-MAIN-2013-20</td>\n",
              "      <td>1368696382261</td>\n",
              "      <td>13</td>\n",
              "      <td>201</td>\n",
              "      <td>Splice Review Black Ops Escalation Map Pack [V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>http://1069therock.com/billy-gibbons-co-oh-wel...</td>\n",
              "      <td>2013-05-18 10:32:50</td>\n",
              "      <td>CC-MAIN-2013-20</td>\n",
              "      <td>1368696382261</td>\n",
              "      <td>3</td>\n",
              "      <td>905</td>\n",
              "      <td>Billy Gibbons &amp; Co., â€˜Oh Wellâ€™ â€“ Song Review J...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>http://1075zoofm.com/silent-hill-revelation-3d...</td>\n",
              "      <td>2013-05-18 10:40:29</td>\n",
              "      <td>CC-MAIN-2013-20</td>\n",
              "      <td>1368696382261</td>\n",
              "      <td>1</td>\n",
              "      <td>3967</td>\n",
              "      <td>â€˜Silent Hill: Revelation 3Dâ€™ Review As far as ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>http://1079ishot.com/taylor-swift-justin-biebe...</td>\n",
              "      <td>2013-05-18 10:31:04</td>\n",
              "      <td>CC-MAIN-2013-20</td>\n",
              "      <td>1368696382261</td>\n",
              "      <td>1</td>\n",
              "      <td>1603</td>\n",
              "      <td>Taylor Swift, Justin Bieber, Lady Gaga + More ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>http://1940.iwm.org.uk/?page_id=13</td>\n",
              "      <td>2013-05-18 10:54:03</td>\n",
              "      <td>CC-MAIN-2013-20</td>\n",
              "      <td>1368696382261</td>\n",
              "      <td>0</td>\n",
              "      <td>1992</td>\n",
              "      <td>All branches of the Imperial War Museum are co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>http://1heckofaguy.com/2011/10/16/leonard-cohe...</td>\n",
              "      <td>2013-05-18 10:13:18</td>\n",
              "      <td>CC-MAIN-2013-20</td>\n",
              "      <td>1368696382261</td>\n",
              "      <td>0</td>\n",
              "      <td>3294</td>\n",
              "      <td>Yep â€“ Itâ€™s Another Do I Have To Dance All Nigh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>http://1md.be/works/alpro-soya-stay-curious</td>\n",
              "      <td>2013-05-18 11:01:55</td>\n",
              "      <td>CC-MAIN-2013-20</td>\n",
              "      <td>1368696382261</td>\n",
              "      <td>3</td>\n",
              "      <td>440</td>\n",
              "      <td>Stay Curious Alpro We created the 'interactive...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>http://1sorrowmadeyou.tumblr.com/</td>\n",
              "      <td>2013-05-18 10:21:03</td>\n",
              "      <td>CC-MAIN-2013-20</td>\n",
              "      <td>1368696382261</td>\n",
              "      <td>0</td>\n",
              "      <td>409</td>\n",
              "      <td>I got off the plane, grabbed my bags, I saw sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>http://2010.nyc.wordcamp.org/2010/09/07/call-f...</td>\n",
              "      <td>2013-05-18 10:41:52</td>\n",
              "      <td>CC-MAIN-2013-20</td>\n",
              "      <td>1368696382261</td>\n",
              "      <td>0</td>\n",
              "      <td>873</td>\n",
              "      <td>Call for Speakers! This is it! Finally weâ€™re t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>http://2012planetx.info/archives/date/2011/05</td>\n",
              "      <td>2013-05-18 10:21:37</td>\n",
              "      <td>CC-MAIN-2013-20</td>\n",
              "      <td>1368696382261</td>\n",
              "      <td>0</td>\n",
              "      <td>1184</td>\n",
              "      <td>Wednesday, June 1, 2011 5 PM PST / 8 PM EST Ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>http://247wallst.com/2013/01/07/todays-market-...</td>\n",
              "      <td>2013-05-18 10:54:15</td>\n",
              "      <td>CC-MAIN-2013-20</td>\n",
              "      <td>1368696382261</td>\n",
              "      <td>0</td>\n",
              "      <td>1315</td>\n",
              "      <td>The stock market is down Monday, with the Dow ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>http://2languages2worlds.wordpress.com/tag/fre...</td>\n",
              "      <td>2013-05-18 10:12:07</td>\n",
              "      <td>CC-MAIN-2013-20</td>\n",
              "      <td>1368696382261</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>Posts Tagged frequency Â»</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>http://30daysofautism.wordpress.com/tag/advocacy/</td>\n",
              "      <td>2013-05-18 10:22:15</td>\n",
              "      <td>CC-MAIN-2013-20</td>\n",
              "      <td>1368696382261</td>\n",
              "      <td>0</td>\n",
              "      <td>1253</td>\n",
              "      <td>Autism Positivity Autism Positivity - Increasi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>http://365days2play.com/category/3-2-shopping-...</td>\n",
              "      <td>2013-05-18 10:12:38</td>\n",
              "      <td>CC-MAIN-2013-20</td>\n",
              "      <td>1368696382261</td>\n",
              "      <td>0</td>\n",
              "      <td>1956</td>\n",
              "      <td>Iâ€™ve never seen Meatworks full before in the n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>http://3sistersvillage.com/blog/2011/11/9/post...</td>\n",
              "      <td>2013-05-18 10:41:26</td>\n",
              "      <td>CC-MAIN-2013-20</td>\n",
              "      <td>1368696382261</td>\n",
              "      <td>7</td>\n",
              "      <td>1721</td>\n",
              "      <td>Postcards from a Global Trekker: Cape Town, So...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>http://4closurefraud.org/2010/10/25/sandusky-w...</td>\n",
              "      <td>2013-05-18 10:21:14</td>\n",
              "      <td>CC-MAIN-2013-20</td>\n",
              "      <td>1368696382261</td>\n",
              "      <td>0</td>\n",
              "      <td>6633</td>\n",
              "      <td>Rhonda D. McLaughlin vs Bank of America â€“ Sand...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-626c7e6e-4950-4762-b43d-94f94ccedd2f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-626c7e6e-4950-4762-b43d-94f94ccedd2f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-626c7e6e-4950-4762-b43d-94f94ccedd2f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4c92a205-d0a0-472c-8819-f78a72b6b7e5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4c92a205-d0a0-472c-8819-f78a72b6b7e5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4c92a205-d0a0-472c-8819-f78a72b6b7e5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_dc36d713-efd3-4204-b8ba-d96374878e06\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_dc36d713-efd3-4204-b8ba-d96374878e06 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"http://100parts.wordpress.com/2012/08/04/astray-baden-baden-day-31/\",\n          \"http://365days2play.com/category/3-2-shopping-centres/orchard-ion-mall/\",\n          \"http://2languages2worlds.wordpress.com/tag/frequency/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"2013-05-18 10:42:00\",\n          \"2013-05-18 10:12:38\",\n          \"2013-05-18 10:12:07\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dump\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"CC-MAIN-2013-20\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"segment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"1368696382261\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"images_found\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 13,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chars\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2563,\n        \"min\": 24,\n        \"max\": 10583,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          514\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"snippet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"these birches can be found in many places in Europe - the photos is from a short trip to Baden-Baden in 2007. the clouds in the background are the messengers of the storm Kyrill. here are some more moments of the trip: Baden-Baden. - \\u201cast/ray\\u201d is a bilingual wordplay: \\u201cast\\u201d means \\u201ctwig\\u201d in German. a\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved 20 records to /content/refinedweb_subset.json\n",
            "Scanned: 20 | Accepted: 20 | Keyword: ''\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BookCorpus**\n",
        "\n",
        "A 985-million-word dataset of 11,000 unpublished books, used to train LLMs like RoBERTA and XLNET."
      ],
      "metadata": {
        "id": "cO50C9qcm6hd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title BookCorpusOpen mini-sampler â†’ DataFrame + JSON\n",
        "# Streams from Hugging Face BookCorpusOpen, samples N docs (optional keyword filter),\n",
        "# displays them in a pandas DataFrame, and saves to /content/bookcorpus_subset.json.\n",
        "\n",
        "# â€”â€”â€” Setup â€”â€”â€”\n",
        "!pip -q install datasets pandas\n",
        "\n",
        "import json, random\n",
        "from typing import List, Dict\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from datasets import load_dataset\n",
        "\n",
        "# â€”â€”â€” Parameters (editable in Colab UI) â€”â€”â€”\n",
        "DATASET_ID = \"lucadiliello/bookcorpusopen\"  #@param [\"lucadiliello/bookcorpusopen\",\"bookcorpusopen\"]\n",
        "SPLIT = \"train\"                              #@param [\"train\"]\n",
        "SAMPLES = 20                                 #@param {type:\"slider\", min:5, max:200, step:5}\n",
        "KEYWORD_FILTER = \"\"                          #@param {type:\"string\"}\n",
        "MAX_RECORDS_TO_SCAN = 5000                   #@param {type:\"integer\"}\n",
        "RANDOM_SEED = 42                             #@param {type:\"integer\"}\n",
        "\n",
        "random.seed(RANDOM_SEED)\n",
        "kw = KEYWORD_FILTER.strip().lower()\n",
        "\n",
        "# â€”â€”â€” 1) Open BookCorpusOpen in streaming mode (no full download) â€”â€”â€”\n",
        "ds = load_dataset(DATASET_ID, split=SPLIT, streaming=True)\n",
        "\n",
        "# â€”â€”â€” 2) Reservoir-sample up to SAMPLES matching records â€”â€”â€”\n",
        "def keep_example(ex):\n",
        "    if not kw:\n",
        "        return True\n",
        "    t = (ex.get(\"text\") or \"\").lower()\n",
        "    ti = (ex.get(\"title\") or \"\").lower()\n",
        "    return (kw in t) or (kw in ti)\n",
        "\n",
        "sample: List[Dict] = []\n",
        "accepted = 0\n",
        "scanned = 0\n",
        "\n",
        "for ex in ds:\n",
        "    scanned += 1\n",
        "    if keep_example(ex):\n",
        "        accepted += 1\n",
        "        if len(sample) < SAMPLES:\n",
        "            sample.append(ex)\n",
        "        else:\n",
        "            j = random.randint(0, accepted - 1)\n",
        "            if j < SAMPLES:\n",
        "                sample[j] = ex\n",
        "    if scanned >= MAX_RECORDS_TO_SCAN or len(sample) >= SAMPLES:\n",
        "        break\n",
        "\n",
        "# â€”â€”â€” 3) Display & save â€”â€”â€”\n",
        "if not sample:\n",
        "    print(\"No matches found. Try clearing KEYWORD_FILTER or increasing MAX_RECORDS_TO_SCAN.\")\n",
        "else:\n",
        "    rows = []\n",
        "    for ex in sample:\n",
        "        text = ex.get(\"text\") or \"\"\n",
        "        rows.append({\n",
        "            \"title\": ex.get(\"title\") or \"\",\n",
        "            \"chars\": len(text),\n",
        "            \"snippet\": text[:300].replace(\"\\n\",\" \").replace(\"\\r\",\" \")\n",
        "        })\n",
        "    df = pd.DataFrame(rows)\n",
        "    display(df)\n",
        "\n",
        "    out_path = \"/content/bookcorpus_subset.json\"\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(rows, f, ensure_ascii=False, indent=2)\n",
        "    print(f\"\\nSaved {len(rows)} records to {out_path}\")\n",
        "    print(f\"Dataset: {DATASET_ID} | Scanned: {scanned} | Accepted: {accepted} | Keyword: {KEYWORD_FILTER!r}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "id": "U1fYagZMm9LC",
        "outputId": "746ac71a-4fe6-43ab-9d00-939686fd0e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                title    chars  \\\n",
              "0             1-2-this-is-only-the-beginning.epub.txt  1136214   \n",
              "1        1-god-poems-on-god-creator-volume-1.epub.txt   202815   \n",
              "2        1-god-poems-on-god-creator-volume-2.epub.txt   194829   \n",
              "3        1-god-poems-on-god-creator-volume-3.epub.txt   193786   \n",
              "4        1-god-poems-on-god-creator-volume-4.epub.txt   311230   \n",
              "5      1-lollapalooza-witness-no-consequence.epub.txt   146543   \n",
              "6   1-shades-of-gray-noir-city-shrouded-by-darknes...   572541   \n",
              "7   1-shades-of-gray-noir-city-shrouded-by-darknes...   572541   \n",
              "8                            10-more-stories.epub.txt   123049   \n",
              "9   10-of-the-best-stories-from-kenji-miyazawa-and...   173262   \n",
              "10  10-reasons-why-the-rapture-must-be-left-behind...   121451   \n",
              "11                10-tales-of-classic-horror.epub.txt   760693   \n",
              "12                       10-ways-to-fk-santa.epub.txt   170418   \n",
              "13               100-alphanumeric-crosswords.epub.txt   458901   \n",
              "14            100-incredible-happiness-hacks.epub.txt   177027   \n",
              "15               100-number-count-crosswords.epub.txt    65280   \n",
              "16                   100-seconds-to-midnight.epub.txt   820186   \n",
              "17            100-ways-to-kill-your-business.epub.txt   214901   \n",
              "18                 1000-lines-magic-sequence.epub.txt   219645   \n",
              "19                  1000-yards-john-milton-1.epub.txt   118744   \n",
              "\n",
              "                                              snippet  \n",
              "0     1 + 2  This Is Only The Beginning  Kristie L...  \n",
              "1     ## 1 God â€“ Poems on God , Creator â€“ volume 1...  \n",
              "2     ## 1 God â€“ Poems on God , Creator â€“ volume 2...  \n",
              "3     ## 1 God â€“ Poems on God , Creator â€“ volume 3...  \n",
              "4     ## 1 God â€“ Poems on God , Creator â€“ volume 4...  \n",
              "5     1-Lollapalooza Witness,  No Consequence  By ...  \n",
              "6     Shades Of Gray  #1  Noir, City Shrouded By D...  \n",
              "7     Shades Of Gray  #1  Noir, City Shrouded By D...  \n",
              "8     10 More Stories  by Floyd Looney  Copyright ...  \n",
              "9     ### 10 of the Best Stories from Kenji Miyaza...  \n",
              "10    # 10 Reasons Why the Rapture Must be Left Be...  \n",
              "11    10 Classic Tales of Horror  Edited by Lance ...  \n",
              "12   10 Ways To F**K Santa  By Erica Storm  Copyri...  \n",
              "13    Gregory Zorzos  100 Alphanumeric Crosswords ...  \n",
              "14    100  Incredible  Happiness  Hacks  _  __Megh...  \n",
              "15    Gregory Zorzos  100  Number Count Crosswords...  \n",
              "16   100  SECONDS  to  MIDNIGHT  # A Clan Story  #...  \n",
              "17    100 Ways To  Kill Your Business  Sandra Wise...  \n",
              "18    Gregory Zorzos  1,000 lines Magic sequence  ...  \n",
              "19    * * *  ## One Thousand Yards  A John Milton ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-586935b2-5987-4b31-9ab4-8163ab0abe75\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>chars</th>\n",
              "      <th>snippet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1-2-this-is-only-the-beginning.epub.txt</td>\n",
              "      <td>1136214</td>\n",
              "      <td>1 + 2  This Is Only The Beginning  Kristie L...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1-god-poems-on-god-creator-volume-1.epub.txt</td>\n",
              "      <td>202815</td>\n",
              "      <td>## 1 God â€“ Poems on God , Creator â€“ volume 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1-god-poems-on-god-creator-volume-2.epub.txt</td>\n",
              "      <td>194829</td>\n",
              "      <td>## 1 God â€“ Poems on God , Creator â€“ volume 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1-god-poems-on-god-creator-volume-3.epub.txt</td>\n",
              "      <td>193786</td>\n",
              "      <td>## 1 God â€“ Poems on God , Creator â€“ volume 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1-god-poems-on-god-creator-volume-4.epub.txt</td>\n",
              "      <td>311230</td>\n",
              "      <td>## 1 God â€“ Poems on God , Creator â€“ volume 4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1-lollapalooza-witness-no-consequence.epub.txt</td>\n",
              "      <td>146543</td>\n",
              "      <td>1-Lollapalooza Witness,  No Consequence  By ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1-shades-of-gray-noir-city-shrouded-by-darknes...</td>\n",
              "      <td>572541</td>\n",
              "      <td>Shades Of Gray  #1  Noir, City Shrouded By D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1-shades-of-gray-noir-city-shrouded-by-darknes...</td>\n",
              "      <td>572541</td>\n",
              "      <td>Shades Of Gray  #1  Noir, City Shrouded By D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10-more-stories.epub.txt</td>\n",
              "      <td>123049</td>\n",
              "      <td>10 More Stories  by Floyd Looney  Copyright ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10-of-the-best-stories-from-kenji-miyazawa-and...</td>\n",
              "      <td>173262</td>\n",
              "      <td>### 10 of the Best Stories from Kenji Miyaza...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10-reasons-why-the-rapture-must-be-left-behind...</td>\n",
              "      <td>121451</td>\n",
              "      <td># 10 Reasons Why the Rapture Must be Left Be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>10-tales-of-classic-horror.epub.txt</td>\n",
              "      <td>760693</td>\n",
              "      <td>10 Classic Tales of Horror  Edited by Lance ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>10-ways-to-fk-santa.epub.txt</td>\n",
              "      <td>170418</td>\n",
              "      <td>10 Ways To F**K Santa  By Erica Storm  Copyri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>100-alphanumeric-crosswords.epub.txt</td>\n",
              "      <td>458901</td>\n",
              "      <td>Gregory Zorzos  100 Alphanumeric Crosswords ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>100-incredible-happiness-hacks.epub.txt</td>\n",
              "      <td>177027</td>\n",
              "      <td>100  Incredible  Happiness  Hacks  _  __Megh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>100-number-count-crosswords.epub.txt</td>\n",
              "      <td>65280</td>\n",
              "      <td>Gregory Zorzos  100  Number Count Crosswords...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>100-seconds-to-midnight.epub.txt</td>\n",
              "      <td>820186</td>\n",
              "      <td>100  SECONDS  to  MIDNIGHT  # A Clan Story  #...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>100-ways-to-kill-your-business.epub.txt</td>\n",
              "      <td>214901</td>\n",
              "      <td>100 Ways To  Kill Your Business  Sandra Wise...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1000-lines-magic-sequence.epub.txt</td>\n",
              "      <td>219645</td>\n",
              "      <td>Gregory Zorzos  1,000 lines Magic sequence  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1000-yards-john-milton-1.epub.txt</td>\n",
              "      <td>118744</td>\n",
              "      <td>* * *  ## One Thousand Yards  A John Milton ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-586935b2-5987-4b31-9ab4-8163ab0abe75')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-586935b2-5987-4b31-9ab4-8163ab0abe75 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-586935b2-5987-4b31-9ab4-8163ab0abe75');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a5ec2e84-1466-4332-ae28-d353fe7392b2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a5ec2e84-1466-4332-ae28-d353fe7392b2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a5ec2e84-1466-4332-ae28-d353fe7392b2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_38e96e3b-d443-4f7b-9f70-67479c6d11a2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_38e96e3b-d443-4f7b-9f70-67479c6d11a2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"1-2-this-is-only-the-beginning.epub.txt\",\n          \"100-ways-to-kill-your-business.epub.txt\",\n          \"100-number-count-crosswords.epub.txt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chars\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 289803,\n        \"min\": 65280,\n        \"max\": 1136214,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          1136214,\n          146543,\n          170418\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"snippet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"  1 + 2  This Is Only The Beginning  Kristie Lynn Higgins  Text Copyright \\u00a9 2018  Cover art created by Kristie Lynn Higgins\\u00a9 2017  Smashwords Ebook Edition  02212018  The Triumph of Death created by Pieter Bruegel the Elder  www.KristieLynnHiggins.com  No part of this book may be reproduced or trans\",\n          \"  1-Lollapalooza Witness,  No Consequence  By Zaphnath Paaneah Copyright 2013  Published by Zaphnath Paaneah (ZP) at Smashwords  Prologue:  Hello. Through God's grace, Zaphnath Paaneah (God lives and speaks) is this Lollapalooza Witness, me. (Matthew10:20) \\\"For it is not ye that speak, but the Spiri\",\n          \" 10 Ways To F**K Santa  By Erica Storm  Copyright 2017 by Erica Storm Copyright  Copyright (C) 2017 by Erica Storm  All rights reserved. No part of this book may be used or reproduced in any manner whatsoever without written permission, except in the case of brief quotations embodied in critical art\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved 20 records to /content/bookcorpus_subset.json\n",
            "Dataset: lucadiliello/bookcorpusopen | Scanned: 20 | Accepted: 20 | Keyword: ''\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Pile**\n",
        "\n",
        "An 800 GB corpus curated from 22 diverse datasets, primarily from academic or professional sources, used to train models like GPT-Neo and LLaMA."
      ],
      "metadata": {
        "id": "-ZvMgyR6oDAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title The Pile (mirror) mini-sampler â†’ DataFrame + JSON\n",
        "# Streams from Hugging Face \"monology/pile-uncopyrighted-parquet\" (or JSON mirror),\n",
        "# samples N docs (optional keyword + subset filter), displays a DataFrame, and saves JSON.\n",
        "\n",
        "# â€”â€”â€” Setup â€”â€”â€”\n",
        "!pip -q install datasets pandas pyarrow\n",
        "\n",
        "import json, ast, random\n",
        "from typing import List, Dict, Any\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from datasets import load_dataset\n",
        "\n",
        "# â€”â€”â€” Parameters (editable) â€”â€”â€”\n",
        "DATASET_ID = \"monology/pile-uncopyrighted-parquet\"  #@param [\"monology/pile-uncopyrighted-parquet\",\"monology/pile-uncopyrighted\"]\n",
        "SPLIT = \"train\"                                     #@param [\"train\"]\n",
        "SAMPLES = 20                                        #@param {type:\"slider\", min:5, max:200, step:5}\n",
        "KEYWORD_FILTER = \"\"                                  #@param {type:\"string\"}  # match in text (or URL in some subsets)\n",
        "SUBSET_FILTER = \"\"                                   #@param {type:\"string\"}  # match meta['pile_set_name'] (e.g., \"arXiv\", \"Pile-CC\")\n",
        "MAX_RECORDS_TO_SCAN = 5000                           #@param {type:\"integer\"}\n",
        "RANDOM_SEED = 42                                     #@param {type:\"integer\"}\n",
        "\n",
        "random.seed(RANDOM_SEED)\n",
        "kw = KEYWORD_FILTER.strip().lower()\n",
        "sub_kw = SUBSET_FILTER.strip().lower()\n",
        "\n",
        "def parse_meta(m: Any) -> Dict[str, Any]:\n",
        "    if isinstance(m, dict):\n",
        "        return m\n",
        "    if isinstance(m, str) and m.strip():\n",
        "        s = m.strip()\n",
        "        for loader in (json.loads, ast.literal_eval):\n",
        "            try:\n",
        "                obj = loader(s)\n",
        "                return obj if isinstance(obj, dict) else {}\n",
        "            except Exception:\n",
        "                continue\n",
        "    return {}\n",
        "\n",
        "def keep_example(ex) -> bool:\n",
        "    text = (ex.get(\"text\") or \"\")\n",
        "    meta = parse_meta(ex.get(\"meta\"))\n",
        "    if kw and kw not in text.lower():\n",
        "        # Some subsets may include extra fields like 'url' inside meta\n",
        "        if kw not in str(meta.get(\"url\", \"\")).lower():\n",
        "            return False\n",
        "    if sub_kw:\n",
        "        name = str(meta.get(\"pile_set_name\") or \"\").lower()\n",
        "        if sub_kw not in name:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "# â€”â€”â€” 1) Open the mirror in streaming mode â€”â€”â€”\n",
        "ds = load_dataset(DATASET_ID, split=SPLIT, streaming=True)\n",
        "\n",
        "# â€”â€”â€” 2) Reservoir-sample up to SAMPLES records â€”â€”â€”\n",
        "sample: List[Dict[str, Any]] = []\n",
        "accepted = 0\n",
        "scanned = 0\n",
        "\n",
        "for ex in ds:\n",
        "    scanned += 1\n",
        "    if keep_example(ex):\n",
        "        accepted += 1\n",
        "        if len(sample) < SAMPLES:\n",
        "            sample.append(ex)\n",
        "        else:\n",
        "            j = random.randint(0, accepted - 1)\n",
        "            if j < SAMPLES:\n",
        "                sample[j] = ex\n",
        "    if scanned >= MAX_RECORDS_TO_SCAN or len(sample) >= SAMPLES:\n",
        "        break\n",
        "\n",
        "# â€”â€”â€” 3) Display & save â€”â€”â€”\n",
        "if not sample:\n",
        "    print(\"No matches found. Try clearing filters or increasing MAX_RECORDS_TO_SCAN.\")\n",
        "else:\n",
        "    rows = []\n",
        "    for ex in sample:\n",
        "        text = ex.get(\"text\") or \"\"\n",
        "        meta = parse_meta(ex.get(\"meta\"))\n",
        "        rows.append({\n",
        "            \"pile_set_name\": meta.get(\"pile_set_name\") or \"\",\n",
        "            \"chars\": len(text),\n",
        "            \"snippet\": text[:300].replace(\"\\n\",\" \").replace(\"\\r\",\" \")\n",
        "        })\n",
        "    df = pd.DataFrame(rows)\n",
        "    display(df)\n",
        "\n",
        "    out_path = \"/content/pile_subset.json\"\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(rows, f, ensure_ascii=False, indent=2)\n",
        "    print(f\"\\nSaved {len(rows)} records to {out_path}\")\n",
        "    print(f\"Dataset: {DATASET_ID} | Scanned: {scanned} | Accepted: {accepted} | \"\n",
        "          f\"Keyword: {KEYWORD_FILTER!r} | Subset filter: {SUBSET_FILTER!r}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792,
          "referenced_widgets": [
            "8df26a76897e4022b9e349b785a4322d",
            "1745c49e5b1944f49e07c8c35e5d66b7",
            "f7ac2027d92c4a98beea06fa209655f6",
            "dfb07871e2744bcdad28e63af9d89bff",
            "903ae7d1e9b34d35b8065bb00f4e00c0",
            "aea40a6d4d10415d8357914ed9a58f1f",
            "c8728bf9bcff4d19ab4a88b8562ac044",
            "132b29bf79414e41923c960bf3662a25",
            "0d3ed473cf2346fba9e01fd649703d70",
            "fea6eb8ebb7b4c96b797b58cc650e2d7",
            "f6e2b186bb1f439c85004a16eb901e33",
            "aaf768174b424842a3d16ca3c9eae341",
            "0c707bb92a2f4747b710623a426af7ca",
            "302d06021cc54ca2ae1ac3871726ea74",
            "ce036b0f3e474cff95170892dc2f661b",
            "b14ab1421e614d2fb0398a42de70df4f",
            "02d4ea534b0746519457e79e4b42329e",
            "4091cd2731af4537ad943dd35cc282eb",
            "9894a04390514980b807a6dfcfb9849c",
            "bad518bdf95d43fb92fbf3d6a1c310bc",
            "137e4357dba34720b6c79d8754192e8b",
            "3adab6899acb499da33a5d14eb6f1b72"
          ]
        },
        "id": "VWyFecwnoQQc",
        "outputId": "cbc74b2b-3eb8-436d-bc24-d8d334a35820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/1987 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8df26a76897e4022b9e349b785a4322d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/1987 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aaf768174b424842a3d16ca3c9eae341"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        pile_set_name  chars  \\\n",
              "0             Pile-CC  13274   \n",
              "1              Github   4278   \n",
              "2             Pile-CC    384   \n",
              "3             Pile-CC   1754   \n",
              "4       StackExchange   2016   \n",
              "5             Pile-CC   4468   \n",
              "6       StackExchange    709   \n",
              "7             Pile-CC   1075   \n",
              "8       StackExchange   1107   \n",
              "9      Wikipedia (en)   2665   \n",
              "10             Github    179   \n",
              "11   PubMed Abstracts   1798   \n",
              "12      StackExchange   2341   \n",
              "13            Pile-CC    666   \n",
              "14   PubMed Abstracts    848   \n",
              "15  USPTO Backgrounds   1711   \n",
              "16            Pile-CC   8376   \n",
              "17   PubMed Abstracts    543   \n",
              "18   PubMed Abstracts   1580   \n",
              "19            Pile-CC  19844   \n",
              "\n",
              "                                              snippet  \n",
              "0   It is done, and submitted. You can play â€œSurvi...  \n",
              "1   <?xml version=\"1.0\" encoding=\"UTF-8\"?>  <segme...  \n",
              "2   Topic: reinvent midnight madness  Amazon annou...  \n",
              "3   About Grand Slam Fishing Charters  As a family...  \n",
              "4   Q:  Why was Mundungus banned from the Hog's He...  \n",
              "5   Working Women, Special Provision and the Debat...  \n",
              "6   Q:  Using M-Test to show you can differentiate...  \n",
              "7   Jeanette Sawyer Cohen, PhD, clinical assistant...  \n",
              "8   Q:  What's the simplest way to pass a file as ...  \n",
              "9   Major League Baseball All-Century Team  In 199...  \n",
              "10  {   \"fpsLimit\": 60,   \"preset\": \"basic\",   \"ba...  \n",
              "11  PCI Alternative Using Sustained Exercise (PAUS...  \n",
              "12  Q:  Â¿PorquÃ© en este loop de JavaScript la impr...  \n",
              "13  Running  Stat  Dinner with people is always be...  \n",
              "14  TiO2 nanotubes for bone regeneration. Nanostru...  \n",
              "15  In general, absorbent articles should comforta...  \n",
              "16  jOOQ on The ORM Foundation?  I am the develope...  \n",
              "17  Standardised protocol for primate faecal analy...  \n",
              "18  Examination of factors affecting gait properti...  \n",
              "19  I've learned the nitrogen vacancies used in Me...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-095c3f8a-718c-426e-8bbc-c39a2d8232e2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pile_set_name</th>\n",
              "      <th>chars</th>\n",
              "      <th>snippet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Pile-CC</td>\n",
              "      <td>13274</td>\n",
              "      <td>It is done, and submitted. You can play â€œSurvi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Github</td>\n",
              "      <td>4278</td>\n",
              "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;  &lt;segme...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Pile-CC</td>\n",
              "      <td>384</td>\n",
              "      <td>Topic: reinvent midnight madness  Amazon annou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Pile-CC</td>\n",
              "      <td>1754</td>\n",
              "      <td>About Grand Slam Fishing Charters  As a family...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>StackExchange</td>\n",
              "      <td>2016</td>\n",
              "      <td>Q:  Why was Mundungus banned from the Hog's He...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Pile-CC</td>\n",
              "      <td>4468</td>\n",
              "      <td>Working Women, Special Provision and the Debat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>StackExchange</td>\n",
              "      <td>709</td>\n",
              "      <td>Q:  Using M-Test to show you can differentiate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Pile-CC</td>\n",
              "      <td>1075</td>\n",
              "      <td>Jeanette Sawyer Cohen, PhD, clinical assistant...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>StackExchange</td>\n",
              "      <td>1107</td>\n",
              "      <td>Q:  What's the simplest way to pass a file as ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Wikipedia (en)</td>\n",
              "      <td>2665</td>\n",
              "      <td>Major League Baseball All-Century Team  In 199...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Github</td>\n",
              "      <td>179</td>\n",
              "      <td>{   \"fpsLimit\": 60,   \"preset\": \"basic\",   \"ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>PubMed Abstracts</td>\n",
              "      <td>1798</td>\n",
              "      <td>PCI Alternative Using Sustained Exercise (PAUS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>StackExchange</td>\n",
              "      <td>2341</td>\n",
              "      <td>Q:  Â¿PorquÃ© en este loop de JavaScript la impr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Pile-CC</td>\n",
              "      <td>666</td>\n",
              "      <td>Running  Stat  Dinner with people is always be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>PubMed Abstracts</td>\n",
              "      <td>848</td>\n",
              "      <td>TiO2 nanotubes for bone regeneration. Nanostru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>USPTO Backgrounds</td>\n",
              "      <td>1711</td>\n",
              "      <td>In general, absorbent articles should comforta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Pile-CC</td>\n",
              "      <td>8376</td>\n",
              "      <td>jOOQ on The ORM Foundation?  I am the develope...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>PubMed Abstracts</td>\n",
              "      <td>543</td>\n",
              "      <td>Standardised protocol for primate faecal analy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>PubMed Abstracts</td>\n",
              "      <td>1580</td>\n",
              "      <td>Examination of factors affecting gait properti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Pile-CC</td>\n",
              "      <td>19844</td>\n",
              "      <td>I've learned the nitrogen vacancies used in Me...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-095c3f8a-718c-426e-8bbc-c39a2d8232e2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-095c3f8a-718c-426e-8bbc-c39a2d8232e2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-095c3f8a-718c-426e-8bbc-c39a2d8232e2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1e91c18e-106a-4339-abcc-8ce73754df40\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1e91c18e-106a-4339-abcc-8ce73754df40')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1e91c18e-106a-4339-abcc-8ce73754df40 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_94c6850c-342b-4216-bf76-7b56e83df029\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_94c6850c-342b-4216-bf76-7b56e83df029 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"pile_set_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Pile-CC\",\n          \"Github\",\n          \"USPTO Backgrounds\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chars\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4968,\n        \"min\": 179,\n        \"max\": 19844,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          13274,\n          543,\n          1711\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"snippet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"It is done, and submitted. You can play \\u201cSurvival of the Tastiest\\u201d on Android, and on the web. Playing on the web works, but you have to simulate multi-touch for table moving and that can be a bit confusing.  There\\u2019s a lot I\\u2019d like to talk about. I\\u2019ll go through every topic, insted of making the typ\",\n          \"Standardised protocol for primate faecal analysis. Macroscopic analysis of primate faeces as a way to study diet is well established, but lack of standardisation of methods may handicap comparative studies of the resulting data. Here we present a proven technique, including equipment and supplies, p\",\n          \"In general, absorbent articles should comfortably fit the body of a wearer. Most absorbent articles include an absorbent pad formed by an absorbent core contained in a wrap comprising a barrier tissue and/or a forming tissue. The subject invention discloses an absorbent article generally having exte\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved 20 records to /content/pile_subset.json\n",
            "Dataset: monology/pile-uncopyrighted-parquet | Scanned: 20 | Accepted: 20 | Keyword: '' | Subset filter: ''\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code sources**\n",
        "\n",
        "such as 'Starcoder Data', a programming-centric dataset built from 783 GB of code written in 86 programming languages, are used to train models like 'Salesforce' CodeGen and 'Starcoder'"
      ],
      "metadata": {
        "id": "ArHZfW8RphDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Token-free code corpus mini-sampler â†’ DataFrame + JSON\n",
        "# Streams a tiny sample from an open code dataset, shows it in a DataFrame, and saves JSON.\n",
        "\n",
        "!pip -q install datasets pandas\n",
        "\n",
        "import json, random\n",
        "from typing import Dict, Any, List\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from datasets import load_dataset\n",
        "\n",
        "# â€”â€”â€” Parameters â€”â€”â€”\n",
        "DATASET = \"code_search_net\"   #@param [\"code_search_net\", \"mbpp\", \"openai_humaneval\"]\n",
        "CSN_LANGUAGE = \"python\"       #@param [\"python\",\"java\",\"javascript\",\"ruby\",\"go\",\"php\"]\n",
        "SAMPLES = 20                  #@param {type:\"slider\", min:5, max:200, step:5}\n",
        "KEYWORD_FILTER = \"\"           #@param {type:\"string\"}\n",
        "MAX_RECORDS_TO_SCAN = 5000    #@param {type:\"integer\"}\n",
        "RANDOM_SEED = 42              #@param {type:\"integer\"}\n",
        "\n",
        "random.seed(RANDOM_SEED)\n",
        "kw = KEYWORD_FILTER.strip().lower()\n",
        "\n",
        "# â€”â€”â€” Load chosen dataset in streaming mode â€”â€”â€”\n",
        "def load_open_dataset(name: str):\n",
        "    if name == \"code_search_net\":\n",
        "        # HF hosts each language as a config\n",
        "        return load_dataset(\"code_search_net\", CSN_LANGUAGE, split=\"train\", streaming=True), f\"code_search_net/{CSN_LANGUAGE}\"\n",
        "    elif name == \"mbpp\":\n",
        "        # Try a popular public mirror first; fall back to the canonical id\n",
        "        try:\n",
        "            return load_dataset(\"Muennighoff/mbpp\", split=\"train\", streaming=True), \"mbpp\"\n",
        "        except Exception:\n",
        "            return load_dataset(\"mbpp\", split=\"train\", streaming=True), \"mbpp\"\n",
        "    else:  # openai_humaneval\n",
        "        return load_dataset(\"openai_humaneval\", split=\"test\", streaming=True), \"openai_humaneval\"\n",
        "\n",
        "ds, active_source = load_open_dataset(DATASET)\n",
        "\n",
        "# â€”â€”â€” Field mapping helpers â€”â€”â€”\n",
        "def extract_text(ex: Dict[str, Any]) -> str:\n",
        "    \"\"\"Return the code/text field depending on dataset schema.\"\"\"\n",
        "    if active_source.startswith(\"code_search_net/\"):\n",
        "        # CodeSearchNet stores code here:\n",
        "        return ex.get(\"func_code_string\") or \"\"\n",
        "    elif active_source == \"mbpp\":\n",
        "        # MBPP has a 'code' field with reference solutions\n",
        "        return ex.get(\"code\") or \"\"\n",
        "    else:  # openai_humaneval\n",
        "        # Prefer canonical solution; otherwise show the prompt\n",
        "        return ex.get(\"canonical_solution\") or ex.get(\"prompt\") or \"\"\n",
        "\n",
        "def keep_example(ex: Dict[str, Any]) -> bool:\n",
        "    if not kw: return True\n",
        "    hay = \" \".join([\n",
        "        extract_text(ex),\n",
        "        str(ex.get(\"docstring\") or ex.get(\"text\") or \"\"),\n",
        "        str(ex.get(\"repo\") or ex.get(\"path\") or \"\"),\n",
        "        str(ex.get(\"language\") or \"\"),\n",
        "    ]).lower()\n",
        "    return kw in hay\n",
        "\n",
        "def row_from_example(ex: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    code_text = extract_text(ex)\n",
        "    row = {\n",
        "        \"source\": active_source,\n",
        "        \"chars\": len(code_text),\n",
        "        \"snippet\": code_text[:300].replace(\"\\n\",\" \").replace(\"\\r\",\" \"),\n",
        "    }\n",
        "    # nice-to-have context columns per dataset\n",
        "    if active_source.startswith(\"code_search_net/\"):\n",
        "        row.update({\n",
        "            \"lang\": ex.get(\"language\") or active_source.split(\"/\")[-1],\n",
        "            \"repo\": ex.get(\"repo\") or \"\",\n",
        "            \"path\": ex.get(\"path\") or \"\",\n",
        "        })\n",
        "    elif active_source == \"mbpp\":\n",
        "        row.update({\"title\": ex.get(\"text\") or \"\", \"lang\": \"python\"})\n",
        "    else:  # humaneval\n",
        "        row.update({\"task_id\": ex.get(\"task_id\") or \"\", \"lang\": \"python\"})\n",
        "    return row\n",
        "\n",
        "# â€”â€”â€” Reservoir sample â€”â€”â€”\n",
        "sample: List[Dict[str, Any]] = []\n",
        "accepted = 0\n",
        "scanned = 0\n",
        "\n",
        "for ex in ds:\n",
        "    scanned += 1\n",
        "    if keep_example(ex):\n",
        "        accepted += 1\n",
        "        if len(sample) < SAMPLES:\n",
        "            sample.append(ex)\n",
        "        else:\n",
        "            j = random.randint(0, accepted - 1)\n",
        "            if j < SAMPLES:\n",
        "                sample[j] = ex\n",
        "    if scanned >= MAX_RECORDS_TO_SCAN or len(sample) >= SAMPLES:\n",
        "        break\n",
        "\n",
        "# â€”â€”â€” Display & save â€”â€”â€”\n",
        "if not sample:\n",
        "    print(\"No matches found. Try clearing KEYWORD_FILTER or increasing MAX_RECORDS_TO_SCAN.\")\n",
        "else:\n",
        "    rows = [row_from_example(ex) for ex in sample]\n",
        "    df = pd.DataFrame(rows)\n",
        "    display(df)\n",
        "\n",
        "    out_path = \"/content/code_subset.json\"\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(rows, f, ensure_ascii=False, indent=2)\n",
        "    print(f\"\\nSaved {len(rows)} records to {out_path}\")\n",
        "    print(f\"Dataset: {active_source} | Scanned: {scanned} | Accepted: {accepted} | Keyword: {KEYWORD_FILTER!r}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "mm80WvMSptCz",
        "outputId": "e679ed11-86ec-4a40-f4e2-93850a24749c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Dataset scripts are no longer supported, but found code_search_net.py",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1677644892.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"openai_humaneval\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreaming\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"openai_humaneval\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactive_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_open_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# â€”â€”â€” Field mapping helpers â€”â€”â€”\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1677644892.py\u001b[0m in \u001b[0;36mload_open_dataset\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"code_search_net\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# HF hosts each language as a config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"code_search_net\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCSN_LANGUAGE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreaming\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"code_search_net/{CSN_LANGUAGE}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mbpp\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Try a popular public mirror first; fall back to the canonical id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1390\u001b[0m         dataset_infos = DatasetInfosDict(\n\u001b[1;32m   1391\u001b[0m             {\n\u001b[0;32m-> 1392\u001b[0;31m                 \u001b[0mconfig_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDatasetInfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexported_dataset_infos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mconfig_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexported_dataset_infos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m             }\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m         \u001b[0mincrease_load_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, data_dir, data_files, cache_dir, **download_kwargs)\u001b[0m\n\u001b[1;32m   1029\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_files\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m             \u001b[0mpatterns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mmetadata_configs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"data_files\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata_configs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m             \u001b[0mpatterns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata_configs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data_files\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, data_dir, data_files, cache_dir, **download_kwargs)\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;31m# make the new module to be noticed by the import system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvalidate_caches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0mbuilder_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"base_path\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDatasetModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuilder_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportable_file_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimportable_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Dataset scripts are no longer supported, but found code_search_net.py"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multilingual datasets**\n",
        "\n",
        "such as ROOTS, a 1.6TB multilingual dataset curated from text sourced in 59 languages, are used to train the BLOOM language model."
      ],
      "metadata": {
        "id": "TtQSiteJuIiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Multilingual mini-sampler (ROOTS / mC4 / OSCAR) â†’ DataFrame + JSON\n",
        "# Streams a few docs from a multilingual corpus, displays them, and saves JSON.\n",
        "\n",
        "# â€”â€”â€” Setup â€”â€”â€”\n",
        "!pip -q install datasets pandas\n",
        "\n",
        "import os, json, random\n",
        "from typing import Dict, Any, List\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from datasets import load_dataset\n",
        "\n",
        "# â€”â€”â€” Choose a source â€”â€”â€”\n",
        "MODE = \"mC4\"  #@param [\"ROOTS\",\"mC4\",\"OSCAR\"]\n",
        "\n",
        "# ROOTS settings (requires accepting ROOTS conditions on HF and being authenticated)\n",
        "ROOTS_DATASET_ID = \"bigscience-data/roots_en_wikipedia\"  #@param {type:\"string\"}\n",
        "HF_TOKEN = \"\"  #@param {type:\"string\"}  # Optional; needed if ROOTS gate prompts for login\n",
        "\n",
        "# mC4 / OSCAR language\n",
        "LANG = \"en\"  #@param [\"en\",\"fr\",\"de\",\"es\",\"ar\",\"hi\",\"id\",\"vi\",\"zh\",\"ru\",\"it\",\"pt\",\"ja\",\"ko\",\"nl\",\"sv\",\"pl\",\"tr\",\"uk\",\"fa\"]\n",
        "\n",
        "# General sampling params\n",
        "SAMPLES = 20               #@param {type:\"slider\", min:5, max:200, step:5}\n",
        "KEYWORD_FILTER = \"\"        #@param {type:\"string\"}  # simple contains() filter on text/url/meta\n",
        "MAX_RECORDS_TO_SCAN = 5000 #@param {type:\"integer\"}\n",
        "RANDOM_SEED = 42           #@param {type:\"integer\"}\n",
        "\n",
        "random.seed(RANDOM_SEED)\n",
        "kw = KEYWORD_FILTER.strip().lower()\n",
        "token = (HF_TOKEN or os.environ.get(\"HF_TOKEN\") or \"\").strip()\n",
        "\n",
        "# â€”â€”â€” Load the chosen dataset in streaming mode â€”â€”â€”\n",
        "def load_roots():\n",
        "    # Always pass token if provided (many ROOTS subsets are gated behind an ethical charter)\n",
        "    try:\n",
        "        return load_dataset(ROOTS_DATASET_ID, split=\"train\", streaming=True, token=token)\n",
        "    except TypeError:\n",
        "        return load_dataset(ROOTS_DATASET_ID, split=\"train\", streaming=True, use_auth_token=token)\n",
        "\n",
        "def load_mc4():\n",
        "    # mC4 is multilingual Common Crawl; each language is a config like 'en', 'fr', etc.\n",
        "    return load_dataset(\"mc4\", LANG, split=\"train\", streaming=True)\n",
        "\n",
        "def load_oscar():\n",
        "    # OSCAR uses language configs like 'unshuffled_deduplicated_en'\n",
        "    return load_dataset(\"oscar\", f\"unshuffled_deduplicated_{LANG}\", split=\"train\", streaming=True)\n",
        "\n",
        "if MODE == \"ROOTS\":\n",
        "    source_name = f\"ROOTS {ROOTS_DATASET_ID}\"\n",
        "    try:\n",
        "        ds = load_roots()\n",
        "    except Exception as e:\n",
        "        print(\"âŒ Could not access ROOTS (likely gated). Tip: accept the BigScience conditions and use an HF token.\")\n",
        "        print(\"Falling back to mC4 instead.\\nDetails:\", e)\n",
        "        ds = load_mc4()\n",
        "        source_name = f\"mC4/{LANG}\"\n",
        "elif MODE == \"mC4\":\n",
        "    ds = load_mc4()\n",
        "    source_name = f\"mC4/{LANG}\"\n",
        "else:\n",
        "    ds = load_oscar()\n",
        "    source_name = f\"OSCAR/{LANG}\"\n",
        "\n",
        "# â€”â€”â€” Helpers â€”â€”â€”\n",
        "def text_of(ex: Dict[str, Any]) -> str:\n",
        "    # ROOTS, mC4, and OSCAR all expose a 'text' column\n",
        "    return (ex.get(\"text\") or \"\").strip()\n",
        "\n",
        "def keep_example(ex: Dict[str, Any]) -> bool:\n",
        "    if not kw:\n",
        "        return True\n",
        "    hay = \" \".join([\n",
        "        text_of(ex),\n",
        "        str(ex.get(\"url\") or \"\"),\n",
        "        str(ex.get(\"meta\") or \"\"),\n",
        "    ]).lower()\n",
        "    return kw in hay\n",
        "\n",
        "def row_from_example(ex: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    t = text_of(ex)\n",
        "    return {\n",
        "        \"source\": source_name,\n",
        "        \"chars\": len(t),\n",
        "        \"snippet\": t[:300].replace(\"\\n\",\" \").replace(\"\\r\",\" \")\n",
        "    }\n",
        "\n",
        "# â€”â€”â€” Reservoir-sample up to SAMPLES rows â€”â€”â€”\n",
        "sample: List[Dict[str, Any]] = []\n",
        "accepted = 0\n",
        "scanned = 0\n",
        "\n",
        "for ex in ds:\n",
        "    scanned += 1\n",
        "    if keep_example(ex):\n",
        "        accepted += 1\n",
        "        if len(sample) < SAMPLES:\n",
        "            sample.append(ex)\n",
        "        else:\n",
        "            j = random.randint(0, accepted - 1)\n",
        "            if j < SAMPLES:\n",
        "                sample[j] = ex\n",
        "    if scanned >= MAX_RECORDS_TO_SCAN or len(sample) >= SAMPLES:\n",
        "        break\n",
        "\n",
        "# â€”â€”â€” Display & save â€”â€”â€”\n",
        "if not sample:\n",
        "    print(\"No matches found. Try clearing KEYWORD_FILTER or increasing MAX_RECORDS_TO_SCAN.\")\n",
        "else:\n",
        "    rows = [row_from_example(ex) for ex in sample]\n",
        "    df = pd.DataFrame(rows)\n",
        "    display(df)\n",
        "\n",
        "    out_path = \"/content/multilingual_subset.json\"\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(rows, f, ensure_ascii=False, indent=2)\n",
        "    print(f\"\\nSaved {len(rows)} records to {out_path}\")\n",
        "    print(f\"Dataset: {source_name} | Scanned: {scanned} | Accepted: {accepted} | Keyword: {KEYWORD_FILTER!r}\")\n"
      ],
      "metadata": {
        "id": "YGPJlq58uUtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MMLU (Massive Multitask Language Understanding)**\n",
        "\n",
        "A benchmark covering 57 subjects with varying difficulty levels, assessing LLMs' general knowledge and reasoning abilities"
      ],
      "metadata": {
        "id": "bTbG-2KqwGXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title MMLU sample â†’ DataFrame + JSON/CSV\n",
        "# Fixes ArrowTypeError by normalizing fields across subjects BEFORE combining.\n",
        "# Tries \"cais/mmlu\" first; if not available, falls back to \"hendrycks_test\" and\n",
        "# builds a clean, uniform in-memory list (no Arrow concat of mismatched schemas).\n",
        "\n",
        "!pip -q install datasets pandas\n",
        "\n",
        "import random, json, os, math\n",
        "import pandas as pd\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "# ---- Parameters (edit) ----\n",
        "SUBJECTS = [\"abstract_algebra\", \"professional_law\", \"medical_genetics\"]  # fallback subjects\n",
        "N_SAMPLES = 8\n",
        "SPLIT_PREFERENCE = [\"dev\", \"validation\", \"test\"]  # try in this order\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "def _ensure_str(x):\n",
        "    return \"\" if x is None else str(x)\n",
        "\n",
        "def _coerce_choices(ch):\n",
        "    \"\"\"Return a list of up to 4 strings A..D.\"\"\"\n",
        "    if ch is None:\n",
        "        return []\n",
        "    # If dict-like {\"A\": \"...\", \"B\": \"...\"} convert to list\n",
        "    if isinstance(ch, dict):\n",
        "        order = [\"A\",\"B\",\"C\",\"D\"]\n",
        "        return [_ensure_str(ch.get(k, \"\")) for k in order]\n",
        "    # If already list/tuple, cast to strings\n",
        "    if isinstance(ch, (list, tuple)):\n",
        "        return [_ensure_str(v) for v in list(ch)[:4]]\n",
        "    # Unknown format -> single choice fallback\n",
        "    return [_ensure_str(ch)]\n",
        "\n",
        "def _answer_letter(ans, choices):\n",
        "    \"\"\"Normalize answer to a letter A-D when possible.\"\"\"\n",
        "    if ans is None:\n",
        "        return None\n",
        "    # numeric index (int or digit string)\n",
        "    if isinstance(ans, int):\n",
        "        return \"ABCD\"[ans] if 0 <= ans < 4 else None\n",
        "    s = str(ans).strip()\n",
        "    if s.isdigit():\n",
        "        i = int(s)\n",
        "        return \"ABCD\"[i] if 0 <= i < 4 else None\n",
        "    # Already a letter?\n",
        "    u = s.upper()\n",
        "    if u in {\"A\",\"B\",\"C\",\"D\"}:\n",
        "        return u\n",
        "    # Sometimes the answer is the full text; map by exact match\n",
        "    try:\n",
        "        idx = [c.strip() for c in choices].index(s)\n",
        "        return \"ABCD\"[idx] if 0 <= idx < 4 else None\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def _normalize_record(ex, subject_hint=None):\n",
        "    \"\"\"Return uniform dict: subject, question, A..D, correct_letter, correct_choice_text.\"\"\"\n",
        "    # Try common field names\n",
        "    q = ex.get(\"question\") or ex.get(\"input\") or ex.get(\"prompt\") or \"\"\n",
        "    ch = ex.get(\"choices\") or ex.get(\"options\")\n",
        "    ch = _coerce_choices(ch)\n",
        "    ans = ex.get(\"answer\") or ex.get(\"target\") or ex.get(\"label\")\n",
        "    subject = ex.get(\"subject\") or ex.get(\"category\") or ex.get(\"task\") or subject_hint or \"unknown\"\n",
        "\n",
        "    letter = _answer_letter(ans, ch)\n",
        "    correct_text = None\n",
        "    if letter and len(ch) >= \"ABCD\".index(letter) + 1:\n",
        "        correct_text = ch[\"ABCD\".index(letter)]\n",
        "\n",
        "    row = {\n",
        "        \"subject\": _ensure_str(subject),\n",
        "        \"question\": _ensure_str(q),\n",
        "        \"A\": ch[0] if len(ch) > 0 else None,\n",
        "        \"B\": ch[1] if len(ch) > 1 else None,\n",
        "        \"C\": ch[2] if len(ch) > 2 else None,\n",
        "        \"D\": ch[3] if len(ch) > 3 else None,\n",
        "        \"correct_letter\": letter,\n",
        "        \"correct_choice_text\": correct_text,\n",
        "    }\n",
        "    return row\n",
        "\n",
        "# ---------- Loaders ----------\n",
        "def load_cais_mmlu(n_samples=N_SAMPLES, seed=SEED):\n",
        "    \"\"\"Preferred: unified MMLU.\"\"\"\n",
        "    for sp in SPLIT_PREFERENCE:\n",
        "        try:\n",
        "            ds = load_dataset(\"cais/mmlu\", split=sp)\n",
        "            # Downsample\n",
        "            if len(ds) > n_samples:\n",
        "                ds = ds.shuffle(seed=seed).select(range(n_samples))\n",
        "            rows = [_normalize_record(ex) for ex in ds]\n",
        "            return \"cais/mmlu\", sp, rows\n",
        "        except Exception:\n",
        "            continue\n",
        "    return None\n",
        "\n",
        "def load_hendrycks_fallback(n_samples=N_SAMPLES, seed=SEED):\n",
        "    \"\"\"Fallback: per-subject datasets; normalize to a Python list instead of Arrow-concatenating.\"\"\"\n",
        "    pool = []\n",
        "    used_split = None\n",
        "    for sp in SPLIT_PREFERENCE:\n",
        "        subject_any = False\n",
        "        for subj in SUBJECTS:\n",
        "            try:\n",
        "                sub = load_dataset(\"hendrycks_test\", subj, split=sp)\n",
        "                for ex in sub:\n",
        "                    pool.append(_normalize_record(ex, subject_hint=subj))\n",
        "                used_split = sp\n",
        "                subject_any = True\n",
        "            except Exception:\n",
        "                # some subjects/splits may be missing\n",
        "                pass\n",
        "        if subject_any:\n",
        "            break\n",
        "\n",
        "    if not pool:\n",
        "        return None\n",
        "\n",
        "    # Shuffle + take a small sample\n",
        "    random.shuffle(pool)\n",
        "    rows = pool[:n_samples]\n",
        "    return \"hendrycks_test\", used_split, rows\n",
        "\n",
        "def load_any(n_samples=N_SAMPLES, seed=SEED):\n",
        "    r = load_cais_mmlu(n_samples, seed)\n",
        "    if r: return r\n",
        "    r = load_hendrycks_fallback(n_samples, seed)\n",
        "    if r: return r\n",
        "    # Last-resort local mock to ensure demo output\n",
        "    mock = [\n",
        "        {\"question\":\"Which number is prime?\",\"choices\":[\"12\",\"15\",\"17\",\"21\"],\"answer\":\"C\",\"subject\":\"mock\"},\n",
        "        {\"question\":\"Which organ pumps blood?\",\"choices\":[\"Liver\",\"Heart\",\"Lung\",\"Kidney\"],\"answer\":1,\"subject\":\"mock\"},\n",
        "    ]\n",
        "    rows = [_normalize_record(ex) for ex in mock]\n",
        "    return \"local_mock\", \"n/a\", rows\n",
        "\n",
        "# ---------- Run ----------\n",
        "provider, used_split, rows = load_any()\n",
        "df = pd.DataFrame(rows)\n",
        "\n",
        "print(f\"âœ… Loaded provider: {provider}  |  split: {used_split}  |  rows: {len(df)}\")\n",
        "display(df)\n",
        "\n",
        "# Save to files for download\n",
        "OUT_JSON = \"/content/mmlu_sample.json\"\n",
        "OUT_CSV  = \"/content/mmlu_sample.csv\"\n",
        "df.to_json(OUT_JSON, orient=\"records\", force_ascii=False, indent=2)\n",
        "df.to_csv(OUT_CSV, index=False)\n",
        "print(f\"\\nSaved JSON: {OUT_JSON}\\nSaved CSV : {OUT_CSV}\")\n",
        "\n",
        "# Mini quiz preview\n",
        "if len(rows):\n",
        "    r = rows[0]\n",
        "    print(\"\\nâ€” Example item â€”\")\n",
        "    print(\"Subject:\", r[\"subject\"])\n",
        "    print(\"Q:\", r[\"question\"])\n",
        "    print(f\"A) {r.get('A')}\\nB) {r.get('B')}\\nC) {r.get('C')}\\nD) {r.get('D')}\")\n",
        "    print(\"Correct:\", r.get(\"correct_letter\"), \"â†’\", r.get(\"correct_choice_text\"))\n"
      ],
      "metadata": {
        "id": "cTLASykDwKlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HellaSwag**\n",
        "\n",
        "A challenging dataset focusing on common sense reasoning, testing LLMs' ability to understand and complete sentences."
      ],
      "metadata": {
        "id": "ngWl_V0Uw58u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title HellaSwag sample â†’ DataFrame + JSON/CSV\n",
        "# Tries \"hellaswag\" first, then \"rowanz/hellaswag\".\n",
        "# Normalizes fields to avoid ArrowTypeError/mixed dtypes.\n",
        "\n",
        "!pip -q install datasets pandas\n",
        "\n",
        "import random, json, os\n",
        "import pandas as pd\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "# ---- Parameters (edit as you like) ----\n",
        "N_SAMPLES = 8\n",
        "SPLIT_PREFERENCE = [\"validation\", \"train\", \"test\"]  # test may lack gold labels\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "def _ensure_str(x):\n",
        "    return \"\" if x is None else str(x)\n",
        "\n",
        "def _coerce_endings(ch):\n",
        "    \"\"\"Return a list of up to 4 strings for options A..D.\"\"\"\n",
        "    if ch is None:\n",
        "        return []\n",
        "    if isinstance(ch, dict):\n",
        "        order = [\"A\",\"B\",\"C\",\"D\"]\n",
        "        return [_ensure_str(ch.get(k, \"\")) for k in order]\n",
        "    if isinstance(ch, (list, tuple)):\n",
        "        return [_ensure_str(v) for v in list(ch)[:4]]\n",
        "    # Unknown format -> single item fallback\n",
        "    return [_ensure_str(ch)]\n",
        "\n",
        "def _answer_letter(ans, choices):\n",
        "    \"\"\"Normalize answer to A-D; returns None if unavailable (e.g., test set).\"\"\"\n",
        "    if ans is None:\n",
        "        return None\n",
        "    if isinstance(ans, int):\n",
        "        return \"ABCD\"[ans] if 0 <= ans < 4 else None\n",
        "    s = str(ans).strip()\n",
        "    if s.isdigit():\n",
        "        i = int(s)\n",
        "        return \"ABCD\"[i] if 0 <= i < 4 else None\n",
        "    u = s.upper()\n",
        "    if u in {\"A\",\"B\",\"C\",\"D\"}:\n",
        "        return u\n",
        "    # Sometimes the answer is full text; try exact match\n",
        "    try:\n",
        "        idx = [c.strip() for c in choices].index(s)\n",
        "        return \"ABCD\"[idx] if 0 <= idx < 4 else None\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def _normalize_record(ex):\n",
        "    \"\"\"\n",
        "    Output schema:\n",
        "    category, context, A..D, correct_letter, correct_ending_text\n",
        "    \"\"\"\n",
        "    # Context fields vary; join whatâ€™s available\n",
        "    ctx_parts = [\n",
        "        ex.get(\"context\"),\n",
        "        ex.get(\"ctx\"),\n",
        "        ex.get(\"ctx_a\"),\n",
        "        ex.get(\"ctx_b\"),\n",
        "    ]\n",
        "    context = \" \".join([_ensure_str(p) for p in ctx_parts if p])\n",
        "\n",
        "    # Options/endings vary by name\n",
        "    endings = (ex.get(\"endings\")\n",
        "               or ex.get(\"ending_options\")\n",
        "               or ex.get(\"options\")\n",
        "               or ex.get(\"choices\"))\n",
        "    endings = _coerce_endings(endings)\n",
        "\n",
        "    # Label (gold) may be missing/-1 on test\n",
        "    label = ex.get(\"label\") or ex.get(\"answer\") or ex.get(\"gold\")\n",
        "    letter = _answer_letter(label, endings)\n",
        "\n",
        "    correct_text = None\n",
        "    if letter and len(endings) >= \"ABCD\".index(letter) + 1:\n",
        "        correct_text = endings[\"ABCD\".index(letter)]\n",
        "\n",
        "    category = (ex.get(\"activity_label\")\n",
        "                or ex.get(\"category\")\n",
        "                or ex.get(\"source_id\")\n",
        "                or \"unknown\")\n",
        "\n",
        "    row = {\n",
        "        \"category\": _ensure_str(category),\n",
        "        \"context\": context,\n",
        "        \"A\": endings[0] if len(endings) > 0 else None,\n",
        "        \"B\": endings[1] if len(endings) > 1 else None,\n",
        "        \"C\": endings[2] if len(endings) > 2 else None,\n",
        "        \"D\": endings[3] if len(endings) > 3 else None,\n",
        "        \"correct_letter\": letter,\n",
        "        \"correct_ending_text\": correct_text,\n",
        "    }\n",
        "    return row\n",
        "\n",
        "# ---------- Loader ----------\n",
        "def load_hellaswag_any(n_samples=N_SAMPLES, seed=SEED):\n",
        "    # Prefer official registry name; fall back to author namespace\n",
        "    for name in [\"hellaswag\", \"rowanz/hellaswag\"]:\n",
        "        for sp in SPLIT_PREFERENCE:\n",
        "            try:\n",
        "                ds = load_dataset(name, split=sp)\n",
        "                if len(ds) > n_samples:\n",
        "                    ds = ds.shuffle(seed=seed).select(range(n_samples))\n",
        "                rows = [_normalize_record(ex) for ex in ds]\n",
        "                return name, sp, rows\n",
        "            except Exception:\n",
        "                continue\n",
        "    # Local mock to guarantee demo output\n",
        "    mock = [\n",
        "        {\n",
        "            \"ctx_a\": \"You push open the heavy door and step into the dim hallway.\",\n",
        "            \"ctx_b\": \"You hear footsteps behind you and turn around to\",\n",
        "            \"endings\": [\n",
        "                \"check the time on your watch.\",\n",
        "                \"see a friend waving hello.\",\n",
        "                \"run quickly out the front door.\",\n",
        "                \"see who is following you.\"\n",
        "            ],\n",
        "            \"label\": 3,\n",
        "            \"activity_label\": \"narrative\"\n",
        "        },\n",
        "        {\n",
        "            \"context\": \"Fold the paper in half along the dotted line, then\",\n",
        "            \"endings\": [\n",
        "                \"cut carefully along the edge.\",\n",
        "                \"place it on the stove.\",\n",
        "                \"pour water into the bowl.\",\n",
        "                \"paint the edges with oil.\"\n",
        "            ],\n",
        "            \"label\": 0,\n",
        "            \"activity_label\": \"instructions\"\n",
        "        },\n",
        "    ]\n",
        "    rows = [_normalize_record(ex) for ex in mock]\n",
        "    return \"local_mock\", \"n/a\", rows\n",
        "\n",
        "# ---------- Run ----------\n",
        "provider, used_split, rows = load_hellaswag_any()\n",
        "df = pd.DataFrame(rows)\n",
        "\n",
        "print(f\"âœ… Loaded provider: {provider}  |  split: {used_split}  |  rows: {len(df)}\")\n",
        "display(df)\n",
        "\n",
        "# ---- Save to files for download ----\n",
        "OUT_JSON = \"/content/hellaswag_sample.json\"\n",
        "OUT_CSV  = \"/content/hellaswag_sample.csv\"\n",
        "df.to_json(OUT_JSON, orient=\"records\", force_ascii=False, indent=2)\n",
        "df.to_csv(OUT_CSV, index=False)\n",
        "print(f\"\\nSaved JSON: {OUT_JSON}\\nSaved CSV : {OUT_CSV}\")\n",
        "\n",
        "# ---- Mini quiz preview (first item) ----\n",
        "if len(rows):\n",
        "    r = rows[0]\n",
        "    print(\"\\nâ€” Example item â€”\")\n",
        "    print(\"Category:\", r[\"category\"])\n",
        "    print(\"Context:\", r[\"context\"])\n",
        "    print(f\"A) {r.get('A')}\\nB) {r.get('B')}\\nC) {r.get('C')}\\nD) {r.get('D')}\")\n",
        "    print(\"Correct:\", r.get(\"correct_letter\"), \"â†’\", r.get(\"correct_ending_text\"))\n"
      ],
      "metadata": {
        "id": "4ctlLL9Pw-xB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HumanEval**\n",
        "\n",
        "A benchmark for evaluating code generation capabilities, assessing the functional correctness of LLM-generated code."
      ],
      "metadata": {
        "id": "sMwPJiiJxuXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title HumanEval sample â†’ DataFrame + JSON/CSV\n",
        "# Loads a small sample from HumanEval, normalizes fields, previews a table,\n",
        "# and saves full records to /content as JSON and CSV.\n",
        "\n",
        "!pip -q install datasets pandas\n",
        "\n",
        "import random, json, os\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "\n",
        "# ---- Parameters (edit as you like) ----\n",
        "N_SAMPLES = 5\n",
        "SPLIT_PREFERENCE = [\"test\", \"validation\", \"dev\", \"train\"]  # HumanEval usually only has \"test\"\n",
        "PROVIDER_CANDIDATES = [\n",
        "    \"openai_humaneval\",          # primary on HF\n",
        "    \"openai/openai_humaneval\",   # namespace fallback\n",
        "    \"evalplus/humaneval\",        # common fork\n",
        "    \"nuprl/humaneval\",           # another mirror/fork\n",
        "]\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "def _ensure_str(x):\n",
        "    return \"\" if x is None else str(x)\n",
        "\n",
        "def _shorten(s, maxlen=160):\n",
        "    s = _ensure_str(s).strip().replace(\"\\r\", \" \")\n",
        "    return s if len(s) <= maxlen else s[: maxlen - 1] + \"â€¦\"\n",
        "\n",
        "def _normalize_record(ex):\n",
        "    \"\"\"\n",
        "    Output schema for table preview:\n",
        "      task_id, entry_point, prompt_preview, tests_preview, has_canonical_solution, approx_asserts\n",
        "    Full fields are kept for JSON/CSV.\n",
        "    \"\"\"\n",
        "    task_id = ex.get(\"task_id\") or ex.get(\"id\") or ex.get(\"name\") or \"unknown\"\n",
        "    entry_point = ex.get(\"entry_point\") or ex.get(\"function_name\") or \"\"\n",
        "    prompt = ex.get(\"prompt\") or ex.get(\"question\") or \"\"\n",
        "    canon = ex.get(\"canonical_solution\") or ex.get(\"solution\") or ex.get(\"reference_solution\")\n",
        "    tests_code = (ex.get(\"test\") or ex.get(\"tests\") or ex.get(\"test_code\")\n",
        "                  or ex.get(\"unit_tests\") or ex.get(\"test_cases\") or \"\")\n",
        "    approx_asserts = _ensure_str(tests_code).lower().count(\"assert\")\n",
        "\n",
        "    row = {\n",
        "        # Preview columns (concise)\n",
        "        \"task_id\": _ensure_str(task_id),\n",
        "        \"entry_point\": _ensure_str(entry_point),\n",
        "        \"prompt_preview\": _shorten(prompt, 180),\n",
        "        \"tests_preview\": _shorten(tests_code, 180),\n",
        "        \"has_canonical_solution\": bool(canon),\n",
        "        \"approx_asserts\": approx_asserts,\n",
        "        # Full data (kept for file export)\n",
        "        \"_full_prompt\": _ensure_str(prompt),\n",
        "        \"_full_tests\": _ensure_str(tests_code),\n",
        "        \"_full_canonical_solution\": _ensure_str(canon) if canon is not None else None,\n",
        "    }\n",
        "    return row\n",
        "\n",
        "def load_humaneval_any(n_samples=N_SAMPLES, seed=SEED):\n",
        "    for name in PROVIDER_CANDIDATES:\n",
        "        for sp in SPLIT_PREFERENCE:\n",
        "            try:\n",
        "                ds = load_dataset(name, split=sp)\n",
        "                # Downsample deterministically\n",
        "                if len(ds) > n_samples:\n",
        "                    ds = ds.shuffle(seed=seed).select(range(n_samples))\n",
        "                rows = [_normalize_record(ex) for ex in ds]\n",
        "                return name, sp, rows\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "    # Local mock to guarantee demo output (no internet, etc.)\n",
        "    mock = [\n",
        "        {\n",
        "            \"task_id\": \"HumanEval/Mock1\",\n",
        "            \"entry_point\": \"add\",\n",
        "            \"prompt\": \"def add(a: int, b: int) -> int:\\n    \\\"\\\"\\\"Return the sum of a and b.\\\"\\\"\\\"\\n\",\n",
        "            \"canonical_solution\": \"def add(a, b):\\n    return a + b\\n\",\n",
        "            \"test\": \"def check():\\n    assert add(1,2)==3\\n    assert add(-1,5)==4\\n\",\n",
        "        },\n",
        "        {\n",
        "            \"task_id\": \"HumanEval/Mock2\",\n",
        "            \"entry_point\": \"is_palindrome\",\n",
        "            \"prompt\": \"def is_palindrome(s: str) -> bool:\\n    \\\"\\\"\\\"Return True iff s reads the same forwards and backwards.\\\"\\\"\\\"\\n\",\n",
        "            \"canonical_solution\": \"def is_palindrome(s):\\n    t=s.lower(); return t==t[::-1]\\n\",\n",
        "            \"test\": \"def check():\\n    assert is_palindrome('abba')\\n    assert not is_palindrome('abc')\\n\",\n",
        "        },\n",
        "    ]\n",
        "    rows = [_normalize_record(ex) for ex in mock]\n",
        "    return \"local_mock\", \"n/a\", rows\n",
        "\n",
        "# ---------- Run ----------\n",
        "provider, used_split, rows = load_humaneval_any()\n",
        "df = pd.DataFrame(rows, columns=[\n",
        "    \"task_id\", \"entry_point\", \"prompt_preview\", \"tests_preview\",\n",
        "    \"has_canonical_solution\", \"approx_asserts\",\n",
        "])\n",
        "\n",
        "print(f\"âœ… Loaded provider: {provider}  |  split: {used_split}  |  rows: {len(df)}\")\n",
        "display(df)\n",
        "\n",
        "# ---- Save full records to files ----\n",
        "OUT_JSON = \"/content/humaneval_sample.json\"\n",
        "OUT_CSV  = \"/content/humaneval_sample.csv\"\n",
        "\n",
        "# For files, keep the full fields (not just previews)\n",
        "file_rows = []\n",
        "for r in rows:\n",
        "    file_rows.append({\n",
        "        \"task_id\": r[\"task_id\"],\n",
        "        \"entry_point\": r[\"entry_point\"],\n",
        "        \"prompt\": r[\"_full_prompt\"],\n",
        "        \"tests\": r[\"_full_tests\"],\n",
        "        \"canonical_solution\": r[\"_full_canonical_solution\"],\n",
        "    })\n",
        "\n",
        "with open(OUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(file_rows, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "pd.DataFrame(file_rows).to_csv(OUT_CSV, index=False)\n",
        "print(f\"\\nSaved JSON: {OUT_JSON}\\nSaved CSV : {OUT_CSV}\")\n",
        "\n",
        "# ---- Mini coding task preview (first item) ----\n",
        "if len(rows):\n",
        "    r = rows[0]\n",
        "    print(\"\\nâ€” Example coding task â€”\")\n",
        "    print(\"Task ID:\", r[\"task_id\"])\n",
        "    print(\"Entry point:\", r[\"entry_point\"])\n",
        "    print(\"\\n--- Prompt ---\\n\", r[\"_full_prompt\"])\n",
        "    if r[\"_full_canonical_solution\"]:\n",
        "        print(\"\\n--- Canonical Solution (reference) ---\\n\", r[\"_full_canonical_solution\"])\n",
        "    print(\"\\n--- Tests (snippet) ---\\n\", _shorten(r[\"_full_tests\"], 500))\n"
      ],
      "metadata": {
        "id": "W6tB_PFqxyB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BIG-Bench (Beyond the Imitation Game Benchmark)**\n",
        "\n",
        "A collection of diverse and challenging tasks, pushing the boundaries of LLM reasoning abilities."
      ],
      "metadata": {
        "id": "x2YHNVD3yIsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title BIG-bench sample â†’ DataFrame + JSON/CSV\n",
        "# Dynamically samples a few tasks from BIG-bench, normalizes fields, previews a table,\n",
        "# and saves to /content. Falls back to BIG-bench Hard (lukaemon/bbh) if needed.\n",
        "\n",
        "!pip -q install datasets pandas\n",
        "\n",
        "import random, json, os\n",
        "import pandas as pd\n",
        "from datasets import load_dataset, get_dataset_config_names\n",
        "\n",
        "# ---- Parameters (edit as you like) ----\n",
        "N_SAMPLES_TOTAL = 8            # total rows to show\n",
        "MAX_PER_TASK = 10              # cap pulled from any single task before downsampling\n",
        "TASKS_TO_TRY = 4               # how many different tasks to sample from (when discoverable)\n",
        "SPLIT_PREFERENCE = [\"validation\", \"train\", \"test\"]\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "\n",
        "# For BBH fallback\n",
        "BBH_TASKS = [\n",
        "    \"date_understanding\",\n",
        "    \"logical_deduction_three_objects\",\n",
        "    \"penguins_in_a_table\",\n",
        "    \"tracking_shuffled_objects_three_objects\",\n",
        "    \"reasoning_about_colored_objects\",\n",
        "]\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "def _ensure_str(x):\n",
        "    return \"\" if x is None else str(x)\n",
        "\n",
        "def _shorten(s, maxlen=180):\n",
        "    s = _ensure_str(s).replace(\"\\r\", \" \").strip()\n",
        "    return s if len(s) <= maxlen else s[: maxlen - 1] + \"â€¦\"\n",
        "\n",
        "def _split_answer_choices(s):\n",
        "    # BIG-bench sometimes stores answer choices as a single string joined by \" ||| \"\n",
        "    parts = [p.strip() for p in s.split(\"|||\")] if isinstance(s, str) and \"|||\" in s else [s]\n",
        "    return [p for p in parts if p != \"\"]\n",
        "\n",
        "def _coerce_choices(ex):\n",
        "    \"\"\"\n",
        "    Try to extract up to 4 options if present:\n",
        "    - 'answer_choices' (string with '|||')\n",
        "    - 'choices' / 'options' / 'endings' (list/dict)\n",
        "    - 'multiple_choice_targets' (list)\n",
        "    \"\"\"\n",
        "    cand = (\n",
        "        ex.get(\"answer_choices\")\n",
        "        or ex.get(\"choices\")\n",
        "        or ex.get(\"options\")\n",
        "        or ex.get(\"endings\")\n",
        "        or ex.get(\"multiple_choice_targets\")\n",
        "        or ex.get(\"target_scores\")   # sometimes dict of option->score\n",
        "    )\n",
        "    if cand is None:\n",
        "        return []\n",
        "    if isinstance(cand, str):\n",
        "        return _split_answer_choices(cand)[:4]\n",
        "    if isinstance(cand, dict):\n",
        "        # keep stable order by key name if A..D; else arbitrary but deterministic\n",
        "        keys = list(cand.keys())\n",
        "        if set(keys) >= {\"A\",\"B\",\"C\",\"D\"}:\n",
        "            ordered = [cand[k] for k in [\"A\",\"B\",\"C\",\"D\"]]\n",
        "        else:\n",
        "            ordered = [cand[k] for k in sorted(keys)][:4]\n",
        "        return [_ensure_str(x) for x in ordered]\n",
        "    if isinstance(cand, (list, tuple)):\n",
        "        return [_ensure_str(x) for x in list(cand)[:4]]\n",
        "    return [_ensure_str(cand)]\n",
        "\n",
        "def _gold_from_example(ex):\n",
        "    \"\"\"\n",
        "    Extract a gold target as text and/or an index if present.\n",
        "    Many BIG-bench tasks use 'target' or 'targets' (list of strings).\n",
        "    Some MC tasks use 'label', 'answer_index', 'correct_choice', etc.\n",
        "    \"\"\"\n",
        "    # textual target(s)\n",
        "    tgt = ex.get(\"target\")\n",
        "    tgts = ex.get(\"targets\")\n",
        "    gold_text = None\n",
        "    if isinstance(tgt, str):\n",
        "        gold_text = tgt\n",
        "    elif isinstance(tgts, (list, tuple)) and tgts:\n",
        "        gold_text = _ensure_str(tgts[0])  # first target\n",
        "\n",
        "    # index-like labels\n",
        "    for key in [\"label\", \"answer_index\", \"correct_choice\", \"target_index\"]:\n",
        "        if key in ex and ex[key] is not None:\n",
        "            try:\n",
        "                idx = int(ex[key])\n",
        "                return gold_text, idx\n",
        "            except Exception:\n",
        "                pass\n",
        "    return gold_text, None\n",
        "\n",
        "def _letter_from_index(i):\n",
        "    return \"ABCD\"[i] if isinstance(i, int) and 0 <= i < 4 else None\n",
        "\n",
        "def _normalize_record(ex, task_hint=\"unknown\"):\n",
        "    \"\"\"\n",
        "    Unified row:\n",
        "      task, input_preview, A..D (if any), gold_letter, gold_text_preview\n",
        "    \"\"\"\n",
        "    # Input / prompt fields seen across BIG-bench variants\n",
        "    ctx_parts = [\n",
        "        ex.get(\"inputs\"),\n",
        "        ex.get(\"input\"),\n",
        "        ex.get(\"prompt\"),\n",
        "        ex.get(\"question\"),\n",
        "        ex.get(\"context\"),\n",
        "        ex.get(\"ctx\"),\n",
        "    ]\n",
        "    inp = \" \".join([_ensure_str(p) for p in ctx_parts if p])\n",
        "\n",
        "    choices = _coerce_choices(ex)\n",
        "    gold_text, gold_idx = _gold_from_example(ex)\n",
        "    gold_letter = _letter_from_index(gold_idx)\n",
        "\n",
        "    # If no index but we *do* have choices and a textual gold, try exact-match mapping\n",
        "    if gold_letter is None and choices and gold_text:\n",
        "        try:\n",
        "            idx = [c.strip() for c in choices].index(gold_text.strip())\n",
        "            gold_letter = _letter_from_index(idx)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    row = {\n",
        "        \"task\": _ensure_str(task_hint),\n",
        "        \"input_preview\": _shorten(inp, 220),\n",
        "        \"A\": choices[0] if len(choices) > 0 else None,\n",
        "        \"B\": choices[1] if len(choices) > 1 else None,\n",
        "        \"C\": choices[2] if len(choices) > 2 else None,\n",
        "        \"D\": choices[3] if len(choices) > 3 else None,\n",
        "        \"gold_letter\": gold_letter,\n",
        "        \"gold_text_preview\": _shorten(gold_text, 160) if gold_text else None,\n",
        "        # Keep full for file export\n",
        "        \"_full_input\": _ensure_str(inp),\n",
        "        \"_full_gold_text\": _ensure_str(gold_text) if gold_text is not None else None,\n",
        "    }\n",
        "    return row\n",
        "\n",
        "# ---------- Loaders ----------\n",
        "def load_tasksource_bigbench(n_total=N_SAMPLES_TOTAL, seed=SEED):\n",
        "    \"\"\"\n",
        "    Discover a few BIG-bench tasks via config names and sample from them.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        configs = get_dataset_config_names(\"tasksource/bigbench\")\n",
        "        if not configs:\n",
        "            return None\n",
        "        random.Random(seed).shuffle(configs)\n",
        "        chosen = configs[:TASKS_TO_TRY]\n",
        "        pool = []\n",
        "        for cfg in chosen:\n",
        "            loaded_any = False\n",
        "            for sp in SPLIT_PREFERENCE:\n",
        "                try:\n",
        "                    ds = load_dataset(\"tasksource/bigbench\", cfg, split=sp)\n",
        "                    if len(ds) > MAX_PER_TASK:\n",
        "                        ds = ds.shuffle(seed=seed).select(range(MAX_PER_TASK))\n",
        "                    for ex in ds:\n",
        "                        pool.append(_normalize_record(ex, task_hint=cfg))\n",
        "                    loaded_any = True\n",
        "                    break\n",
        "                except Exception:\n",
        "                    continue\n",
        "            # proceed to next cfg (even if not found)\n",
        "        if not pool:\n",
        "            return None\n",
        "        random.shuffle(pool)\n",
        "        return (\"tasksource/bigbench\", \"mixed\", pool[:n_total])\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def load_google_bigbench(n_total=N_SAMPLES_TOTAL, seed=SEED):\n",
        "    \"\"\"\n",
        "    Try google/bigbench with discovered configs.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        configs = get_dataset_config_names(\"google/bigbench\")\n",
        "        if not configs:\n",
        "            return None\n",
        "        random.Random(seed).shuffle(configs)\n",
        "        chosen = configs[:TASKS_TO_TRY]\n",
        "        pool = []\n",
        "        for cfg in chosen:\n",
        "            for sp in SPLIT_PREFERENCE:\n",
        "                try:\n",
        "                    ds = load_dataset(\"google/bigbench\", cfg, split=sp)\n",
        "                    if len(ds) > MAX_PER_TASK:\n",
        "                        ds = ds.shuffle(seed=seed).select(range(MAX_PER_TASK))\n",
        "                    for ex in ds:\n",
        "                        pool.append(_normalize_record(ex, task_hint=cfg))\n",
        "                    break\n",
        "                except Exception:\n",
        "                    continue\n",
        "        if not pool:\n",
        "            return None\n",
        "        random.shuffle(pool)\n",
        "        return (\"google/bigbench\", \"mixed\", pool[:n_total])\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def load_bbh_fallback(n_total=N_SAMPLES_TOTAL, seed=SEED):\n",
        "    \"\"\"\n",
        "    BIG-bench Hard subset fallback via lukaemon/bbh.\n",
        "    \"\"\"\n",
        "    pool = []\n",
        "    used_tasks = []\n",
        "    for t in BBH_TASKS:\n",
        "        try:\n",
        "            ds = load_dataset(\"lukaemon/bbh\", t, split=\"test\")\n",
        "            if len(ds) > MAX_PER_TASK:\n",
        "                ds = ds.shuffle(seed=seed).select(range(MAX_PER_TASK))\n",
        "            for ex in ds:\n",
        "                pool.append(_normalize_record(ex, task_hint=t))\n",
        "            used_tasks.append(t)\n",
        "        except Exception:\n",
        "            continue\n",
        "    if not pool:\n",
        "        return None\n",
        "    random.shuffle(pool)\n",
        "    return (\"lukaemon/bbh\", \"test (subset of BIG-bench)\", pool[:n_total])\n",
        "\n",
        "def load_any():\n",
        "    for fn in (load_tasksource_bigbench, load_google_bigbench, load_bbh_fallback):\n",
        "        r = fn()\n",
        "        if r:\n",
        "            return r\n",
        "    # Last resort: tiny mock so the demo still displays something\n",
        "    mock = [\n",
        "        {\n",
        "            \"inputs\": \"Translate to French: 'The cat sits on the mat.'\",\n",
        "            \"answer_choices\": \"Le chat dort ||| Le chat est sur le tapis ||| Le chien est sur le lit ||| Le tapis est sous le chat\",\n",
        "            \"target\": \"Le chat est sur le tapis\",\n",
        "        },\n",
        "        {\n",
        "            \"inputs\": \"If today is Monday, what day will it be in two days?\",\n",
        "            \"choices\": [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\"],\n",
        "            \"label\": 2\n",
        "        },\n",
        "    ]\n",
        "    rows = [_normalize_record(ex, task_hint=\"mock_bigbench\") for ex in mock]\n",
        "    return (\"local_mock\", \"n/a\", rows)\n",
        "\n",
        "# ---------- Run ----------\n",
        "provider, used_split, rows = load_any()\n",
        "df = pd.DataFrame(rows, columns=[\n",
        "    \"task\", \"input_preview\", \"A\", \"B\", \"C\", \"D\", \"gold_letter\", \"gold_text_preview\"\n",
        "])\n",
        "\n",
        "print(f\"âœ… Loaded provider: {provider}  |  split: {used_split}  |  rows: {len(df)}\")\n",
        "display(df)\n",
        "\n",
        "# ---- Save full records to files ----\n",
        "OUT_JSON = \"/content/bigbench_sample.json\"\n",
        "OUT_CSV  = \"/content/bigbench_sample.csv\"\n",
        "\n",
        "file_rows = []\n",
        "for r in rows:\n",
        "    file_rows.append({\n",
        "        \"task\": r[\"task\"],\n",
        "        \"input\": r[\"_full_input\"],\n",
        "        \"gold_text\": r[\"_full_gold_text\"],\n",
        "        \"A\": r.get(\"A\"),\n",
        "        \"B\": r.get(\"B\"),\n",
        "        \"C\": r.get(\"C\"),\n",
        "        \"D\": r.get(\"D\"),\n",
        "        \"gold_letter\": r.get(\"gold_letter\"),\n",
        "    })\n",
        "\n",
        "with open(OUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(file_rows, f, ensure_ascii=False, indent=2)\n",
        "pd.DataFrame(file_rows).to_csv(OUT_CSV, index=False)\n",
        "print(f\"\\nSaved JSON: {OUT_JSON}\\nSaved CSV : {OUT_CSV}\")\n",
        "\n",
        "# ---- Mini item preview (first row) ----\n",
        "if len(rows):\n",
        "    r = rows[0]\n",
        "    print(\"\\nâ€” Example item â€”\")\n",
        "    print(\"Task:\", r[\"task\"])\n",
        "    print(\"Input:\", _shorten(r[\"_full_input\"], 500))\n",
        "    if r.get(\"A\") or r.get(\"B\") or r.get(\"C\") or r.get(\"D\"):\n",
        "        print(f\"A) {r.get('A')}\\nB) {r.get('B')}\\nC) {r.get('C')}\\nD) {r.get('D')}\")\n",
        "    if r.get(\"gold_letter\") or r.get(\"_full_gold_text\"):\n",
        "        print(\"Gold:\", r.get(\"gold_letter\"), \"â†’\", r.get(\"_full_gold_text\"))\n"
      ],
      "metadata": {
        "id": "Q18c5fqdyMfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ARC (AI2 Reasoning Challenge)**\n",
        "\n",
        "A benchmark focusing on scientific reasoning, using grade-school science questions in a multiple-choice format"
      ],
      "metadata": {
        "id": "YZ1Nlw5ly2KR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ARC (AI2 Reasoning Challenge) sample â†’ DataFrame + JSON/CSV\n",
        "# Loads a small sample from ARC-Easy/ARC-Challenge, normalizes fields, previews a table,\n",
        "# and saves /content/arc_sample.json and /content/arc_sample.csv.\n",
        "\n",
        "!pip -q install datasets pandas\n",
        "\n",
        "import random, json, os\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "\n",
        "# ---- Parameters (edit as you like) ----\n",
        "N_SAMPLES = 8\n",
        "CONFIGS = [\"ARC-Challenge\", \"ARC-Easy\"]     # order to try\n",
        "SPLIT_PREFERENCE = [\"validation\", \"train\", \"test\"]  # prefer splits with answers\n",
        "PROVIDERS = [\"ai2_arc\", \"allenai/ai2_arc\"]  # dataset names to try in order\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "def _ensure_str(x):\n",
        "    return \"\" if x is None else str(x)\n",
        "\n",
        "def _shorten(s, maxlen=220):\n",
        "    s = _ensure_str(s).replace(\"\\r\", \" \").strip()\n",
        "    return s if len(s) <= maxlen else s[: maxlen - 1] + \"â€¦\"\n",
        "\n",
        "def _choices_map(choices):\n",
        "    \"\"\"\n",
        "    Return mapping like {'A': '...', 'B': '...', ...}.\n",
        "    ARC usually stores choices as:\n",
        "      choices = {'label': ['A','B','C','D'], 'text': ['..','..','..','..']}\n",
        "    but sometimes it's a list of dicts [{'label': 'A', 'text': '...'}, ...].\n",
        "    \"\"\"\n",
        "    m = {}\n",
        "    if choices is None:\n",
        "        return m\n",
        "    # case 1: dict with parallel lists\n",
        "    if isinstance(choices, dict):\n",
        "        labels = choices.get(\"label\") or choices.get(\"labels\") or []\n",
        "        texts  = choices.get(\"text\")  or choices.get(\"texts\")  or []\n",
        "        for lab, txt in zip(labels, texts):\n",
        "            key = _ensure_str(lab).strip().upper()\n",
        "            m[key] = _ensure_str(txt)\n",
        "        return m\n",
        "    # case 2: list of dicts\n",
        "    if isinstance(choices, (list, tuple)):\n",
        "        for it in choices:\n",
        "            if isinstance(it, dict):\n",
        "                key = _ensure_str(it.get(\"label\") or it.get(\"key\")).strip().upper()\n",
        "                val = _ensure_str(it.get(\"text\") or it.get(\"value\"))\n",
        "                if key:\n",
        "                    m[key] = val\n",
        "        return m\n",
        "    # fallback: single string or unknown\n",
        "    m[\"A\"] = _ensure_str(choices)\n",
        "    return m\n",
        "\n",
        "def _normalize_record(ex, cfg_name):\n",
        "    \"\"\"\n",
        "    Output schema:\n",
        "      dataset, question_preview, A..E, correct_letter, correct_choice_text\n",
        "    \"\"\"\n",
        "    q = ex.get(\"question\") or ex.get(\"prompt\") or ex.get(\"input\") or \"\"\n",
        "    choices = _choices_map(ex.get(\"choices\"))\n",
        "    ans = ex.get(\"answerKey\") or ex.get(\"label\") or ex.get(\"answer\")\n",
        "    letter = _ensure_str(ans).strip().upper() if ans is not None else None\n",
        "    # Only accept standard A-E letters\n",
        "    if letter not in {\"A\",\"B\",\"C\",\"D\",\"E\"}:\n",
        "        letter = None\n",
        "    correct_text = choices.get(letter) if letter else None\n",
        "\n",
        "    row = {\n",
        "        \"dataset\": _ensure_str(cfg_name),\n",
        "        \"question_preview\": _shorten(q, 240),\n",
        "        \"A\": choices.get(\"A\"),\n",
        "        \"B\": choices.get(\"B\"),\n",
        "        \"C\": choices.get(\"C\"),\n",
        "        \"D\": choices.get(\"D\"),\n",
        "        \"E\": choices.get(\"E\"),\n",
        "        \"correct_letter\": letter,\n",
        "        \"correct_choice_text\": correct_text,\n",
        "        # keep full for file export\n",
        "        \"_full_question\": _ensure_str(q),\n",
        "    }\n",
        "    return row\n",
        "\n",
        "# ---------- Loader ----------\n",
        "def load_arc_any(n_samples=N_SAMPLES, seed=SEED):\n",
        "    rows = []\n",
        "    used = []  # (provider, config, split) for info\n",
        "    for prov in PROVIDERS:\n",
        "        for cfg in CONFIGS:\n",
        "            if len(rows) >= n_samples:\n",
        "                break\n",
        "            for sp in SPLIT_PREFERENCE:\n",
        "                if len(rows) >= n_samples:\n",
        "                    break\n",
        "                try:\n",
        "                    ds = load_dataset(prov, cfg, split=sp)\n",
        "                    # Downsample deterministically\n",
        "                    if len(ds) > (n_samples - len(rows)):\n",
        "                        ds = ds.shuffle(seed=seed).select(range(n_samples - len(rows)))\n",
        "                    for ex in ds:\n",
        "                        rows.append(_normalize_record(ex, cfg))\n",
        "                    used.append((prov, cfg, sp))\n",
        "                except Exception:\n",
        "                    continue\n",
        "        if rows:\n",
        "            break\n",
        "\n",
        "    if rows:\n",
        "        provider_label = \", \".join(sorted({u[0] for u in used}))\n",
        "        split_label = \"mixed\" if len({u[2] for u in used}) > 1 else (used[0][2] if used else \"n/a\")\n",
        "        return provider_label, split_label, rows[:n_samples]\n",
        "\n",
        "    # Local mock to guarantee demo output\n",
        "    mock = [\n",
        "        {\n",
        "            \"question\": \"What gas do plants absorb from the atmosphere to perform photosynthesis?\",\n",
        "            \"choices\": {\"label\": [\"A\",\"B\",\"C\",\"D\",\"E\"], \"text\": [\n",
        "                \"Oxygen\", \"Hydrogen\", \"Carbon dioxide\", \"Nitrogen\", \"Helium\"\n",
        "            ]},\n",
        "            \"answerKey\": \"C\"\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"A student mixes sand and salt. Which method is BEST to separate them?\",\n",
        "            \"choices\": [\n",
        "                {\"label\": \"A\", \"text\": \"Use a magnet\"},\n",
        "                {\"label\": \"B\", \"text\": \"Filter then evaporate water\"},\n",
        "                {\"label\": \"C\", \"text\": \"Burn the mixture\"},\n",
        "                {\"label\": \"D\", \"text\": \"Freeze the mixture\"},\n",
        "                {\"label\": \"E\", \"text\": \"Add more salt\"}\n",
        "            ],\n",
        "            \"answerKey\": \"B\"\n",
        "        },\n",
        "    ]\n",
        "    rows = [_normalize_record(ex, \"mock_arc\") for ex in mock]\n",
        "    return \"local_mock\", \"n/a\", rows\n",
        "\n",
        "# ---------- Run ----------\n",
        "provider, used_split, rows = load_arc_any()\n",
        "df = pd.DataFrame(rows, columns=[\n",
        "    \"dataset\", \"question_preview\", \"A\", \"B\", \"C\", \"D\", \"E\", \"correct_letter\", \"correct_choice_text\"\n",
        "])\n",
        "\n",
        "print(f\"âœ… Loaded provider: {provider}  |  split: {used_split}  |  rows: {len(df)}\")\n",
        "display(df)\n",
        "\n",
        "# ---- Save full records to files ----\n",
        "OUT_JSON = \"/content/arc_sample.json\"\n",
        "OUT_CSV  = \"/content/arc_sample.csv\"\n",
        "\n",
        "file_rows = []\n",
        "for r in rows:\n",
        "    file_rows.append({\n",
        "        \"dataset\": r[\"dataset\"],\n",
        "        \"question\": r[\"_full_question\"],\n",
        "        \"A\": r.get(\"A\"), \"B\": r.get(\"B\"), \"C\": r.get(\"C\"), \"D\": r.get(\"D\"), \"E\": r.get(\"E\"),\n",
        "        \"correct_letter\": r.get(\"correct_letter\"),\n",
        "        \"correct_choice_text\": r.get(\"correct_choice_text\"),\n",
        "    })\n",
        "\n",
        "with open(OUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(file_rows, f, ensure_ascii=False, indent=2)\n",
        "pd.DataFrame(file_rows).to_csv(OUT_CSV, index=False)\n",
        "print(f\"\\nSaved JSON: {OUT_JSON}\\nSaved CSV : {OUT_CSV}\")\n",
        "\n",
        "# ---- Mini quiz preview (first row) ----\n",
        "if len(rows):\n",
        "    r = rows[0]\n",
        "    print(\"\\nâ€” Example item â€”\")\n",
        "    print(\"Dataset:\", r[\"dataset\"])\n",
        "    print(\"Q:\", r[\"_full_question\"])\n",
        "    print(f\"A) {r.get('A')}\\nB) {r.get('B')}\\nC) {r.get('C')}\\nD) {r.get('D')}\\nE) {r.get('E')}\")\n",
        "    print(\"Correct:\", r.get(\"correct_letter\"), \"â†’\", r.get(\"correct_choice_text\"))\n"
      ],
      "metadata": {
        "id": "XCF9TvFMy8nB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GSM8K (Grade School Math 8K)**\n",
        "\n",
        "A benchmark designed explicitly for evaluating LLMs' mathematical reasoning skills, focusing on elementary math problems."
      ],
      "metadata": {
        "id": "r-piEV6wzeJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title GSM8K sample â†’ DataFrame + JSON/CSV\n",
        "# Loads a small sample from GSM8K (Grade School Math 8K), normalizes the final answer,\n",
        "# previews a table, and saves to /content as JSON and CSV.\n",
        "\n",
        "!pip -q install datasets pandas\n",
        "\n",
        "import random, json, re\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "\n",
        "# ---- Parameters (edit as you like) ----\n",
        "N_SAMPLES = 8\n",
        "CONFIGS = [\"main\", \"socratic\"]                # prefer 'main', then 'socratic'\n",
        "SPLIT_PREFERENCE = [\"test\", \"train\"]          # both have answers in GSM8K\n",
        "PROVIDERS = [\"openai/gsm8k\", \"gsm8k\"]         # dataset names to try in order\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "def _ensure_str(x): return \"\" if x is None else str(x)\n",
        "\n",
        "def _shorten(s, maxlen=220):\n",
        "    s = _ensure_str(s).replace(\"\\r\",\" \").strip()\n",
        "    return s if len(s) <= maxlen else s[:maxlen-1] + \"â€¦\"\n",
        "\n",
        "FINAL_RE = re.compile(r\"####\\s*(.+)$\", re.MULTILINE)\n",
        "\n",
        "def parse_final_answer(answer_text):\n",
        "    \"\"\"\n",
        "    Extract the final answer from GSM8K's solution text (after the last '####').\n",
        "    Returns (final_text, final_numeric or None).\n",
        "    \"\"\"\n",
        "    txt = _ensure_str(answer_text)\n",
        "    m_all = list(FINAL_RE.finditer(txt))\n",
        "    if not m_all:\n",
        "        return None, None\n",
        "    final_text = m_all[-1].group(1).strip()\n",
        "\n",
        "    # Try to coerce a numeric form (handles commas, signs, decimals, simple fractions)\n",
        "    # Examples: \"2,345\", \"-7.5\", \"3/4\", \"24 dollars\", \"24.0 apples\"\n",
        "    num = None\n",
        "    # fraction like a/b\n",
        "    frac = re.fullmatch(r\"\\s*([+-]?\\d+)\\s*/\\s*(\\d+)\\s*\", final_text)\n",
        "    if frac:\n",
        "        try:\n",
        "            num = int(frac.group(1)) / int(frac.group(2))\n",
        "        except Exception:\n",
        "            num = None\n",
        "    if num is None:\n",
        "        # general number at start\n",
        "        mnum = re.match(r\"\\s*([+-]?\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?|[+-]?\\d+(?:\\.\\d+)?)(?:\\b|$)\", final_text)\n",
        "        if mnum:\n",
        "            try:\n",
        "                num = float(mnum.group(1).replace(\",\", \"\"))\n",
        "            except Exception:\n",
        "                num = None\n",
        "    return final_text, num\n",
        "\n",
        "def _normalize_record(ex, cfg_name, split_name):\n",
        "    q = ex.get(\"question\") or ex.get(\"prompt\") or \"\"\n",
        "    a = ex.get(\"answer\") or ex.get(\"solution\") or \"\"\n",
        "    final_text, final_num = parse_final_answer(a)\n",
        "\n",
        "    return {\n",
        "        \"config\": cfg_name,\n",
        "        \"split\": split_name,\n",
        "        \"question_preview\": _shorten(q, 240),\n",
        "        \"final_answer\": final_text,\n",
        "        \"final_answer_numeric\": final_num,\n",
        "        \"solution_preview\": _shorten(a, 240),\n",
        "        # keep full for file export\n",
        "        \"_full_question\": _ensure_str(q),\n",
        "        \"_full_solution\": _ensure_str(a),\n",
        "    }\n",
        "\n",
        "# ---------- Loader ----------\n",
        "def load_gsm8k_any(n_samples=N_SAMPLES, seed=SEED):\n",
        "    rows = []\n",
        "    used = []  # (provider, config, split)\n",
        "    for prov in PROVIDERS:\n",
        "        for cfg in CONFIGS:\n",
        "            if len(rows) >= n_samples:\n",
        "                break\n",
        "            for sp in SPLIT_PREFERENCE:\n",
        "                if len(rows) >= n_samples:\n",
        "                    break\n",
        "                try:\n",
        "                    ds = load_dataset(prov, cfg, split=sp)\n",
        "                    # Downsample deterministically\n",
        "                    take = min(n_samples - len(rows), len(ds))\n",
        "                    if take <= 0:\n",
        "                        continue\n",
        "                    if len(ds) > take:\n",
        "                        ds = ds.shuffle(seed=seed).select(range(take))\n",
        "                    for ex in ds:\n",
        "                        rows.append(_normalize_record(ex, cfg, sp))\n",
        "                    used.append((prov, cfg, sp))\n",
        "                except Exception:\n",
        "                    continue\n",
        "        if rows:\n",
        "            break\n",
        "\n",
        "    if rows:\n",
        "        provider_label = \", \".join(sorted({u[0] for u in used}))\n",
        "        split_label = \"mixed\" if len({u[2] for u in used}) > 1 else (used[0][2] if used else \"n/a\")\n",
        "        return provider_label, split_label, rows[:n_samples]\n",
        "\n",
        "    # Local mock to guarantee demo output\n",
        "    mock = [\n",
        "        {\n",
        "            \"question\": \"Sara has 3 boxes with 4 apples each. She buys 5 more apples. How many apples now?\",\n",
        "            \"answer\": \"She starts with 3*4 = 12 apples. Then she buys 5 more to have 17.\\n#### 17\"\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"A pen costs $2 and a notebook costs $3. If Ali buys 4 pens and 2 notebooks, how much does he pay?\",\n",
        "            \"answer\": \"4 pens cost 4*2 = 8, 2 notebooks cost 2*3 = 6, total 8+6 = 14 dollars.\\n#### 14\"\n",
        "        },\n",
        "    ]\n",
        "    rows = [_normalize_record(ex, \"mock\", \"n/a\") for ex in mock]\n",
        "    return \"local_mock\", \"n/a\", rows\n",
        "\n",
        "# ---------- Run ----------\n",
        "provider, used_split, rows = load_gsm8k_any()\n",
        "df = pd.DataFrame(rows, columns=[\n",
        "    \"config\", \"split\", \"question_preview\", \"final_answer\", \"final_answer_numeric\", \"solution_preview\"\n",
        "])\n",
        "\n",
        "print(f\"âœ… Loaded provider: {provider}  |  split: {used_split}  |  rows: {len(df)}\")\n",
        "display(df)\n",
        "\n",
        "# ---- Save full records to files ----\n",
        "OUT_JSON = \"/content/gsm8k_sample.json\"\n",
        "OUT_CSV  = \"/content/gsm8k_sample.csv\"\n",
        "\n",
        "file_rows = []\n",
        "for r in rows:\n",
        "    file_rows.append({\n",
        "        \"config\": r[\"config\"],\n",
        "        \"split\": r[\"split\"],\n",
        "        \"question\": r[\"_full_question\"],\n",
        "        \"solution\": r[\"_full_solution\"],\n",
        "        \"final_answer\": r[\"final_answer\"],\n",
        "        \"final_answer_numeric\": r[\"final_answer_numeric\"],\n",
        "    })\n",
        "\n",
        "with open(OUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(file_rows, f, ensure_ascii=False, indent=2)\n",
        "pd.DataFrame(file_rows).to_csv(OUT_CSV, index=False)\n",
        "print(f\"\\nSaved JSON: {OUT_JSON}\\nSaved CSV : {OUT_CSV}\")\n",
        "\n",
        "# ---- Mini item preview (first row) ----\n",
        "if len(rows):\n",
        "    r = rows[0]\n",
        "    print(\"\\nâ€” Example problem â€”\")\n",
        "    print(\"Config/Split:\", r[\"config\"], \"/\", r[\"split\"])\n",
        "    print(\"Q:\", r[\"_full_question\"])\n",
        "    print(\"\\n--- Solution (snippet) ---\")\n",
        "    print(_shorten(r[\"_full_solution\"], 500))\n",
        "    print(\"\\nFinal Answer:\", r[\"final_answer\"], \"| Numeric:\", r[\"final_answer_numeric\"])\n"
      ],
      "metadata": {
        "id": "i5EstWUKzrCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TruthfulQA**\n",
        "\n",
        "A dataset for evaluating LLMs' truthfulness and ability to avoid generating false or misleading information."
      ],
      "metadata": {
        "id": "6LqMbWajz5eM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title TruthfulQA sample â†’ DataFrame + JSON/CSV\n",
        "# Handles mc1_targets/mc2_targets in both forms:\n",
        "#  (a) {answer_text: score_or_bool}  (b) {\"choices\":[...], \"labels\":[0/1,...]}\n",
        "# Also supports the \"generation\" config.\n",
        "\n",
        "!pip -q install datasets pandas\n",
        "\n",
        "import random, json\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "\n",
        "# ---- Parameters ----\n",
        "N_SAMPLES = 8\n",
        "CONFIGS = [\"multiple_choice\", \"generation\"]\n",
        "SPLIT_PREFERENCE = [\"validation\", \"test\", \"train\"]\n",
        "PROVIDERS = [\"truthfulqa/truthful_qa\", \"truthful_qa\", \"allenai/truthful_qa\"]\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "def _s(x): return \"\" if x is None else str(x)\n",
        "\n",
        "def _short(s, n=220):\n",
        "    s = _s(s).replace(\"\\r\",\" \").strip()\n",
        "    return s if len(s) <= n else s[:n-1] + \"â€¦\"\n",
        "\n",
        "def _choices_from_generic(ex):\n",
        "    for key in [\"choices\",\"options\",\"answer_choices\",\"mc1_choices\",\"mc2_choices\",\"endings\"]:\n",
        "        v = ex.get(key)\n",
        "        if isinstance(v, (list, tuple)):\n",
        "            return [ _s(x) for x in v ][:4]\n",
        "        if isinstance(v, dict):\n",
        "            # Some dumps have {\"A\":\"..\",\"B\":\"..\"} or {\"text\":[...]}\n",
        "            if \"text\" in v and isinstance(v[\"text\"], list):\n",
        "                return [ _s(x) for x in v[\"text\"] ][:4]\n",
        "            if \"choices\" in v and isinstance(v[\"choices\"], list):\n",
        "                return [ _s(x) for x in v[\"choices\"] ][:4]\n",
        "            # Otherwise take values in key order\n",
        "            return [ _s(v[k]) for k in sorted(v.keys()) ][:4]\n",
        "        if isinstance(v, str) and \"|||\" in v:\n",
        "            return [ _s(p.strip()) for p in v.split(\"|||\") ][:4]\n",
        "    return []\n",
        "\n",
        "def _extract_mc_targets(v):\n",
        "    \"\"\"\n",
        "    Normalize mc*_targets into (choices:list[str], correct_index:int|None).\n",
        "    Supports:\n",
        "      1) { \"choices\":[..], \"labels\":[0/1,..] }\n",
        "      2) { \"choices\":[..], \"scores\":[..] }\n",
        "      3) { answer_text: score_or_bool, ... }\n",
        "      4) list of choices (no labels)\n",
        "    \"\"\"\n",
        "    if isinstance(v, dict):\n",
        "        # Case 1/2: explicit arrays\n",
        "        if isinstance(v.get(\"choices\"), list):\n",
        "            choices = [ _s(x) for x in v[\"choices\"] ][:4]\n",
        "            labels = v.get(\"labels\") or v.get(\"targets\") or v.get(\"is_correct\")\n",
        "            scores = v.get(\"scores\") or v.get(\"values\")\n",
        "            idx = None\n",
        "            if isinstance(labels, list) and labels:\n",
        "                # pick first True/1\n",
        "                for i, lab in enumerate(labels[:len(choices)]):\n",
        "                    if bool(lab):\n",
        "                        idx = i; break\n",
        "            if idx is None and isinstance(scores, list) and scores:\n",
        "                best = None\n",
        "                for i, sc in enumerate(scores[:len(choices)]):\n",
        "                    try:\n",
        "                        val = float(sc)\n",
        "                    except Exception:\n",
        "                        val = 1.0 if bool(sc) else 0.0\n",
        "                    if best is None or val > best[1]:\n",
        "                        best = (i, val)\n",
        "                if best: idx = best[0]\n",
        "            return choices, idx\n",
        "        # Case 3: mapping answer_text -> score/bool\n",
        "        key_texts = [k for k in v.keys() if isinstance(k, str)]\n",
        "        if key_texts:\n",
        "            # keep a stable order\n",
        "            choices = [ _s(k) for k in key_texts ][:4]\n",
        "            # choose highest score / True\n",
        "            best = None\n",
        "            for i, k in enumerate(choices):\n",
        "                val = v.get(k, 0)\n",
        "                try:\n",
        "                    score = float(val) if not isinstance(val, bool) else (1.0 if val else 0.0)\n",
        "                except Exception:\n",
        "                    score = 1.0 if bool(val) else 0.0\n",
        "                if best is None or score > best[1]:\n",
        "                    best = (i, score)\n",
        "            idx = best[0] if best else None\n",
        "            return choices, idx\n",
        "    # Case 4: list\n",
        "    if isinstance(v, (list, tuple)):\n",
        "        return [ _s(x) for x in v ][:4], None\n",
        "    return [], None\n",
        "\n",
        "def _choices_and_index(ex):\n",
        "    \"\"\"\n",
        "    Best-effort extraction of MC choices and the correct index.\n",
        "    Priority: mc1_targets â†’ mc2_targets â†’ generic choices.\n",
        "    \"\"\"\n",
        "    for key in [\"mc1_targets\", \"mc2_targets\"]:\n",
        "        v = ex.get(key)\n",
        "        if v is not None:\n",
        "            ch, idx = _extract_mc_targets(v)\n",
        "            if ch:\n",
        "                return ch, idx\n",
        "    # If targets missing, fall back to generic fields\n",
        "    ch = _choices_from_generic(ex)\n",
        "    # Sometimes a numeric label exists separately\n",
        "    idx = None\n",
        "    for k in [\"label\",\"answer_index\",\"target_index\",\"mc1_idx_correct\",\"mc2_idx_correct\"]:\n",
        "        if k in ex and ex[k] is not None:\n",
        "            try:\n",
        "                i = int(ex[k]);\n",
        "                if 0 <= i < len(ch): idx = i\n",
        "            except Exception:\n",
        "                pass\n",
        "    return ch, idx\n",
        "\n",
        "def _normalize_row_mc(ex, split_name):\n",
        "    q = ex.get(\"question\") or ex.get(\"prompt\") or ex.get(\"input\") or \"\"\n",
        "    cat = ex.get(\"category\") or ex.get(\"type\") or ex.get(\"domain\") or \"unknown\"\n",
        "    choices, idx = _choices_and_index(ex)\n",
        "    letter = \"ABCD\"[idx] if isinstance(idx, int) and 0 <= idx < 4 else None\n",
        "    correct_text = choices[idx] if isinstance(idx, int) and idx < len(choices) else None\n",
        "    return {\n",
        "        \"config\": \"multiple_choice\",\n",
        "        \"split\": split_name,\n",
        "        \"category\": _s(cat),\n",
        "        \"question_preview\": _short(s, 240) if (s:=q) else \"\",\n",
        "        \"A\": choices[0] if len(choices) > 0 else None,\n",
        "        \"B\": choices[1] if len(choices) > 1 else None,\n",
        "        \"C\": choices[2] if len(choices) > 2 else None,\n",
        "        \"D\": choices[3] if len(choices) > 3 else None,\n",
        "        \"correct_letter\": letter,\n",
        "        \"correct_choice_text\": correct_text,\n",
        "        \"_full_question\": _s(q),\n",
        "        \"_full_best_answer\": None,\n",
        "        \"_full_correct_answers\": None,\n",
        "        \"_full_incorrect_answers\": None,\n",
        "    }\n",
        "\n",
        "def _normalize_row_gen(ex, split_name):\n",
        "    q = ex.get(\"question\") or ex.get(\"prompt\") or ex.get(\"input\") or \"\"\n",
        "    cat = ex.get(\"category\") or ex.get(\"type\") or ex.get(\"domain\") or \"unknown\"\n",
        "    best = ex.get(\"best_answer\")\n",
        "    corr = ex.get(\"correct_answers\")\n",
        "    inc  = ex.get(\"incorrect_answers\")\n",
        "    choices = []\n",
        "    if best: choices.append(_s(best))\n",
        "    if isinstance(corr, (list, tuple)):\n",
        "        for x in corr:\n",
        "            if len(choices) >= 4: break\n",
        "            sx = _s(x)\n",
        "            if sx not in choices: choices.append(sx)\n",
        "    if isinstance(inc, (list, tuple)):\n",
        "        for x in inc:\n",
        "            if len(choices) >= 4: break\n",
        "            sx = _s(x)\n",
        "            if sx not in choices: choices.append(sx)\n",
        "    return {\n",
        "        \"config\": \"generation\",\n",
        "        \"split\": split_name,\n",
        "        \"category\": _s(cat),\n",
        "        \"question_preview\": _short(q, 240),\n",
        "        \"A\": choices[0] if len(choices) > 0 else None,\n",
        "        \"B\": choices[1] if len(choices) > 1 else None,\n",
        "        \"C\": choices[2] if len(choices) > 2 else None,\n",
        "        \"D\": choices[3] if len(choices) > 3 else None,\n",
        "        \"correct_letter\": \"A\" if best and choices and choices[0] == _s(best) else None,\n",
        "        \"correct_choice_text\": _s(best) if best else None,\n",
        "        \"_full_question\": _s(q),\n",
        "        \"_full_best_answer\": _s(best) if best else None,\n",
        "        \"_full_correct_answers\": json.dumps(corr, ensure_ascii=False) if isinstance(corr, (list, tuple)) else None,\n",
        "        \"_full_incorrect_answers\": json.dumps(inc, ensure_ascii=False) if isinstance(inc, (list, tuple)) else None,\n",
        "    }\n",
        "\n",
        "# ---------- Loader ----------\n",
        "def load_truthfulqa_any(n_samples=N_SAMPLES, seed=SEED):\n",
        "    rows, used = [], []\n",
        "    for prov in PROVIDERS:\n",
        "        for cfg in CONFIGS:\n",
        "            for sp in SPLIT_PREFERENCE:\n",
        "                try:\n",
        "                    ds = load_dataset(prov, cfg, split=sp)\n",
        "                except Exception:\n",
        "                    continue\n",
        "                take = min(n_samples - len(rows), len(ds))\n",
        "                if take <= 0: break\n",
        "                if len(ds) > take:\n",
        "                    ds = ds.shuffle(seed=seed).select(range(take))\n",
        "                for ex in ds:\n",
        "                    rows.append(_normalize_row_mc(ex, sp) if cfg == \"multiple_choice\"\n",
        "                                else _normalize_row_gen(ex, sp))\n",
        "                used.append((prov, cfg, sp))\n",
        "                if len(rows) >= n_samples: break\n",
        "            if len(rows) >= n_samples: break\n",
        "        if rows: break\n",
        "\n",
        "    if rows:\n",
        "        provider_label = \", \".join(sorted({u[0] for u in used}))\n",
        "        split_label = \"mixed\" if len({u[2] for u in used}) > 1 else (used[0][2] if used else \"n/a\")\n",
        "        return provider_label, split_label, rows[:n_samples]\n",
        "\n",
        "    # Local mock as last resort\n",
        "    mock_mc = {\"question\":\"Do humans need oxygen to live?\",\n",
        "               \"mc1_targets\":{\"choices\":[\"Yes\",\"No\",\"Only at night\",\"Only when running\"],\"labels\":[1,0,0,0]},\n",
        "               \"category\":\"health\"}\n",
        "    mock_gen = {\"question\":\"Is the Earth flat?\",\n",
        "                \"best_answer\":\"No. The Earth is approximately spherical; measurements and photos confirm this.\",\n",
        "                \"correct_answers\":[\"The Earth is round/spherical.\"],\n",
        "                \"incorrect_answers\":[\"Yes, it's flat.\"]}\n",
        "    return \"local_mock\",\"n/a\",[\n",
        "        _normalize_row_mc(mock_mc, \"n/a\"),\n",
        "        _normalize_row_gen(mock_gen, \"n/a\"),\n",
        "    ]\n",
        "\n",
        "# ---------- Run ----------\n",
        "provider, used_split, rows = load_truthfulqa_any()\n",
        "df = pd.DataFrame(rows, columns=[\n",
        "    \"config\",\"split\",\"category\",\"question_preview\",\n",
        "    \"A\",\"B\",\"C\",\"D\",\"correct_letter\",\"correct_choice_text\"\n",
        "])\n",
        "\n",
        "print(f\"âœ… Loaded provider: {provider}  |  split: {used_split}  |  rows: {len(df)}\")\n",
        "display(df)\n",
        "\n",
        "# ---- Save full records ----\n",
        "OUT_JSON = \"/content/truthfulqa_sample.json\"\n",
        "OUT_CSV  = \"/content/truthfulqa_sample.csv\"\n",
        "\n",
        "file_rows = [{\n",
        "    \"config\": r[\"config\"], \"split\": r[\"split\"], \"category\": r[\"category\"],\n",
        "    \"question\": r[\"_full_question\"],\n",
        "    \"A\": r.get(\"A\"), \"B\": r.get(\"B\"), \"C\": r.get(\"C\"), \"D\": r.get(\"D\"),\n",
        "    \"correct_letter\": r.get(\"correct_letter\"),\n",
        "    \"correct_choice_text\": r.get(\"correct_choice_text\"),\n",
        "    \"best_answer\": r.get(\"_full_best_answer\"),\n",
        "    \"correct_answers\": r.get(\"_full_correct_answers\"),\n",
        "    \"incorrect_answers\": r.get(\"_full_incorrect_answers\"),\n",
        "} for r in rows]\n",
        "\n",
        "with open(OUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(file_rows, f, ensure_ascii=False, indent=2)\n",
        "pd.DataFrame(file_rows).to_csv(OUT_CSV, index=False)\n",
        "print(f\"\\nSaved JSON: {OUT_JSON}\\nSaved CSV : {OUT_CSV}\")\n",
        "\n",
        "# ---- Mini item preview ----\n",
        "if rows:\n",
        "    r = rows[0]\n",
        "    print(\"\\nâ€” Example item â€”\")\n",
        "    print(\"Config/Split:\", r[\"config\"], \"/\", r[\"split\"])\n",
        "    print(\"Category:\", r[\"category\"])\n",
        "    print(\"Q:\", r[\"_full_question\"])\n",
        "    if any(r.get(k) for k in [\"A\",\"B\",\"C\",\"D\"]):\n",
        "        print(f\"A) {r.get('A')}\\nB) {r.get('B')}\\nC) {r.get('C')}\\nD) {r.get('D')}\")\n",
        "    if r.get(\"correct_letter\") or r.get(\"correct_choice_text\"):\n",
        "        print(\"Correct:\", r.get(\"correct_letter\"), \"â†’\", r.get(\"correct_choice_text\"))\n",
        "    if r.get(\"_full_best_answer\"):\n",
        "        print(\"\\nBest Answer:\\n\", r.get(\"_full_best_answer\"))\n"
      ],
      "metadata": {
        "id": "Ey5sBGMgz__F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
