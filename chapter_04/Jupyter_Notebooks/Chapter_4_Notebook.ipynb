{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bccc40cb",
   "metadata": {},
   "source": [
    "# Chapter 4: Building Your First RAG System - From Theory to Implementation\n",
    "\n",
    "*Notebook companion for Chapter 4 of Data Strategy for LLMs*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b4dc98",
   "metadata": {},
   "source": [
    "# Setup From Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c50804",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b951073a",
   "metadata": {},
   "source": [
    "### Jupyter Kernel Setup Fix\n",
    "\n",
    "**If you're seeing an error like \"Running cells with 'Python X.X.X' requires the ipykernel package\", this cell will fix it!**\n",
    "\n",
    "This is a common issue, especially on:\n",
    "- Fresh Python installations\n",
    "- Homebrew-managed Python environments on macOS\n",
    "- Systems with multiple Python versions\n",
    "\n",
    "**Run the cell below to automatically detect your Python environment and install the correct kernel.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63000a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ipykernel is already installed. No fix needed.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "def check_and_fix_kernel():\n",
    "    \"\"\"\n",
    "    Checks if the environment is local and if ipykernel is missing.\n",
    "    If both conditions are true, it attempts to install the kernel.\n",
    "    \"\"\"\n",
    "    # Step 1: Detect if running in Google Colab\n",
    "    if 'google.colab' in sys.modules:\n",
    "        print(\" Running in Google Colab. No kernel fix needed.\")\n",
    "        return\n",
    "\n",
    "    # Step 2: If local, check if ipykernel is already installed\n",
    "    try:\n",
    "        import ipykernel\n",
    "        print(\" ipykernel is already installed. No fix needed.\")\n",
    "        return\n",
    "    except ImportError:\n",
    "        print(\" ipykernel not found. Attempting installation...\")\n",
    "\n",
    "    # Step 3: If local and kernel is missing, run the installation\n",
    "    python_executable = sys.executable\n",
    "    python_version = f\"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\"\n",
    "    \n",
    "    print(f\"DETECTED Python: {python_executable}\")\n",
    "    print(f\"PYTHON VERSION: {python_version}\")\n",
    "    \n",
    "    # Method 1: Try standard installation\n",
    "    try:\n",
    "        subprocess.run(\n",
    "            [python_executable, '-m', 'pip', 'install', 'ipykernel', '-U', '--user', '--force-reinstall'],\n",
    "            capture_output=True, text=True, check=True\n",
    "        )\n",
    "        print(\"SUCCESS: Successfully installed ipykernel (Method 1)\")\n",
    "        method_used = 1\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(\"WARNING: Method 1 failed, trying with --break-system-packages...\")\n",
    "        # Method 2: Try with --break-system-packages\n",
    "        try:\n",
    "            subprocess.run(\n",
    "                [python_executable, '-m', 'pip', 'install', 'ipykernel', '-U', '--user', '--force-reinstall', '--break-system-packages'],\n",
    "                capture_output=True, text=True, check=True\n",
    "            )\n",
    "            print(\"SUCCESS: Successfully installed ipykernel (Method 2 - with system override)\")\n",
    "            method_used = 2\n",
    "        except subprocess.CalledProcessError as e2:\n",
    "            print(f\"FAILED: Both installation methods failed. Error: {e2.stderr}\")\n",
    "            print(\"\\nConsider creating a virtual environment manually.\")\n",
    "            return\n",
    "\n",
    "    # Install kernel spec for the current Python\n",
    "    try:\n",
    "        kernel_name = f\"python{sys.version_info.major}{sys.version_info.minor}\"\n",
    "        display_name = f\"Python {python_version}\"\n",
    "        \n",
    "        subprocess.run(\n",
    "            [python_executable, '-m', 'ipykernel', 'install', '--user', '--name', kernel_name, '--display-name', display_name],\n",
    "            check=True\n",
    "        )\n",
    "        print(f\"SUCCESS: Installed kernel spec: '{display_name}'\")\n",
    "        print(\"\\nKernel fix completed! Please RESTART your Jupyter server and select the new kernel.\")\n",
    "    except Exception as e:\n",
    "        print(f\"WARNING: Kernel spec installation warning: {e}\")\n",
    "\n",
    "# Run the check and fix function\n",
    "check_and_fix_kernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69919396",
   "metadata": {},
   "source": [
    "#### What This Fix Does\n",
    "\n",
    "The cell above automatically handles the most common kernel installation scenarios:\n",
    "\n",
    "**Method 1 - Standard Installation:**\n",
    "- Tries the standard `pip install ipykernel` approach\n",
    "- Works for most regular Python installations\n",
    "\n",
    "**Method 2 - System Override (Homebrew/Externally Managed):**\n",
    "- Uses `--break-system-packages` flag for Homebrew Python\n",
    "- Handles \"externally-managed-environment\" errors\n",
    "- Essential for macOS Homebrew Python environments\n",
    "\n",
    "**Method 3 - Virtual Environment Fallback:**\n",
    "- Creates a clean virtual environment if other methods fail\n",
    "- Installs ipykernel in isolation\n",
    "- Provides a \"AI Notebook Python\" kernel option\n",
    "\n",
    "**After running the fix:**\n",
    "- Your Jupyter interface should show available kernels\n",
    "- Select the one that matches your Python version\n",
    "- All notebook cells should run without kernel errors\n",
    "\n",
    "This approach ensures the notebook works on fresh machines, different Python distributions, and various operating systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "## Complete Future-Proof OpenAI Setup\n",
    "### Comprehensive Error Handling & API Evolution Adaptation\n",
    "\n",
    "This notebook provides robust OpenAI API setup that handles current errors and adapts to future API changes:\n",
    "\n",
    "**Error Handling:** Billing, authentication, model deprecation, rate limits, network issues\n",
    "**Future-Proofing:** SDK version compatibility, adaptive response parsing, flexible error patterns\n",
    "**Cross-Platform:** Local Jupyter, Google Colab, Python 3.8+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207f7b23",
   "metadata": {},
   "source": [
    "#### API Key Setup\n",
    "\n",
    "Before we dive into the architecture, let's set up our environment to work with OpenAI. For this book, I'm using OpenAI as our primary LLM gateway. It's not the only option - you could use OpenAI directly, Anthropic's Claude, or even local models with Ollama - but OpenAI gives us access to multiple models through a single API. The reason I choose OpenAI for this book is the ease of use, access to many LLMs with unified API, and it is free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment: Local Jupyter\n",
      "SUCCESS: openai\n",
      "SUCCESS: python-dotenv\n",
      "SUCCESS: packaging\n"
     ]
    }
   ],
   "source": [
    "# Smart Environment Setup\n",
    "import sys, os, subprocess, importlib.util\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"Environment: {'Google Colab' if IN_COLAB else 'Local Jupyter'}\")\n",
    "\n",
    "def smart_install(package, min_version=None):\n",
    "    \"\"\"Install packages with multiple fallback strategies\"\"\"\n",
    "    package_spec = f\"{package}>={min_version}\" if min_version else package\n",
    "    strategies = [\n",
    "        [sys.executable, '-m', 'pip', 'install', package_spec, '--quiet'],\n",
    "        [sys.executable, '-m', 'pip', 'install', package_spec, '--user', '--quiet'],\n",
    "        [sys.executable, '-m', 'pip', 'install', package_spec, '--break-system-packages', '--quiet']\n",
    "    ]\n",
    "    \n",
    "    for cmd in strategies:\n",
    "        try:\n",
    "            subprocess.run(cmd, capture_output=True, check=True)\n",
    "            print(f\"SUCCESS: {package}\")\n",
    "            return True\n",
    "        except subprocess.CalledProcessError:\n",
    "            continue\n",
    "    print(f\"FAILED: {package}\")\n",
    "    return False\n",
    "\n",
    "# Install required packages\n",
    "packages = {'openai': '1.0.0', 'python-dotenv': None, 'packaging': None}\n",
    "for pkg, ver in packages.items():\n",
    "    smart_install(pkg, ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import modules with graceful fallbacks\n",
    "import os, re, time, json, getpass\n",
    "from typing import Optional, List, Dict, Tuple\n",
    "\n",
    "# OpenAI client import\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "    OPENAI_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"WARNING: OpenAI not available. Install with: pip install openai\")\n",
    "    OPENAI_AVAILABLE = False\n",
    "    class OpenAI:\n",
    "        def __init__(self): pass\n",
    "\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    DOTENV_AVAILABLE = True\n",
    "except ImportError:\n",
    "    DOTENV_AVAILABLE = False\n",
    "    def load_dotenv(): pass\n",
    "\n",
    "try:\n",
    "    from packaging import version\n",
    "    VERSION_CHECK = True\n",
    "except ImportError:\n",
    "    VERSION_CHECK = False\n",
    "\n",
    "print(\"Modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "api-validator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key validator ready\n"
     ]
    }
   ],
   "source": [
    "# Future-Proof API Key Validator\n",
    "class APIKeyValidator:\n",
    "    def __init__(self):\n",
    "        self.patterns = [\n",
    "            r'^sk-[A-Za-z0-9]{20,}$',\n",
    "            r'^sk-proj-[A-Za-z0-9\\-_]{20,}$',\n",
    "            r'^sk-[A-Za-z0-9\\-_]{40,}$'\n",
    "        ]\n",
    "        self.invalid_keys = {\n",
    "            'your_api_key_here', 'sk-your-key-here', 'sk-...', 'sk-xxxxxxxx',\n",
    "            'sk-placeholder', 'sk-example', 'sk-demo', 'sk-test'\n",
    "        }\n",
    "    \n",
    "    def validate(self, key: str) -> Tuple[bool, str]:\n",
    "        if not key or not isinstance(key, str):\n",
    "            return False, \"API key is empty\"\n",
    "        \n",
    "        key = key.strip()\n",
    "        \n",
    "        if key.lower() in [k.lower() for k in self.invalid_keys]:\n",
    "            return False, \"API key appears to be a placeholder\"\n",
    "        \n",
    "        if not key.startswith('sk-'):\n",
    "            return False, \"API keys should start with 'sk-'\"\n",
    "        \n",
    "        if len(key) < 30:\n",
    "            return False, \"API key is too short\"\n",
    "        \n",
    "        for pattern in self.patterns:\n",
    "            if re.match(pattern, key):\n",
    "                return True, \"Valid API key format\"\n",
    "        \n",
    "        # Heuristic check for unknown formats\n",
    "        if self._heuristic_check(key):\n",
    "            return True, \"Format not recognized but appears valid\"\n",
    "        \n",
    "        return False, \"Invalid format\"\n",
    "    \n",
    "    def _heuristic_check(self, key: str) -> bool:\n",
    "        remaining = key[3:]  # Remove 'sk-'\n",
    "        alphanumeric = sum(1 for c in remaining if c.isalnum())\n",
    "        unique_chars = len(set(remaining.lower()))\n",
    "        return alphanumeric >= len(remaining) * 0.8 and unique_chars >= 8\n",
    "\n",
    "validator = APIKeyValidator()\n",
    "print(\"API key validator ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "api-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: Valid API key format\n",
      "\n",
      "API key configured successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load API key from shared configuration\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add repository root to Python path\n",
    "repo_root = Path().cwd()\n",
    "while not (repo_root / 'utils').exists() and repo_root.parent != repo_root:\n",
    "    repo_root = repo_root.parent\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "\n",
    "from utils.config import get_openai_api_key\n",
    "\n",
    "try:\n",
    "    api_key = get_openai_api_key()\n",
    "    print(\"OpenAI API key loaded successfully from .env file\")\n",
    "except ValueError as e:\n",
    "    print(\"API key setup required:\")\n",
    "    print(str(e))\n",
    "    print(\"\\nQuick setup:\")\n",
    "    print(\"1. Copy .env.example to .env: cp .env.example .env\")\n",
    "    print(\"2. Edit .env and add your OpenAI API key\")\n",
    "    print(\"3. Get your key from: https://platform.openai.com/api-keys\")\n",
    "    print(\"4. Restart this notebook kernel\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039d58db",
   "metadata": {},
   "source": [
    "#### Connecting with OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "connection-test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection test OK\n"
     ]
    }
   ],
   "source": [
    "# Connection Test: OpenAI embeddings API\n",
    "try:\n",
    "    import os\n",
    "    import openai\n",
    "    key = os.getenv('OPENAI_API_KEY')\n",
    "    if hasattr(openai, 'OpenAI'):\n",
    "        client = openai.OpenAI(api_key=key)\n",
    "    else:\n",
    "        client = openai\n",
    "        client.api_key = key\n",
    "    _ = client.embeddings.create(model='text-embedding-3-small', input='ping')\n",
    "    print('Connection test OK')\n",
    "except Exception as e:\n",
    "    print(f'Connection test failed: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "connection-test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection test OK\n"
     ]
    }
   ],
   "source": [
    "# Connection Test: OpenAI embeddings API\n",
    "try:\n",
    "    import os\n",
    "    import openai\n",
    "    key = os.getenv('OPENAI_API_KEY')\n",
    "    if hasattr(openai, 'OpenAI'):\n",
    "        client = openai.OpenAI(api_key=key)\n",
    "    else:\n",
    "        client = openai\n",
    "        client.api_key = key\n",
    "    _ = client.embeddings.create(model='text-embedding-3-small', input='ping')\n",
    "    print('Connection test OK')\n",
    "except Exception as e:\n",
    "    print(f'Connection test failed: {e}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c51d63f",
   "metadata": {},
   "source": [
    "### OpenAI Assistant ask_ai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "assistant-class",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Future-Proof Assistant...\n",
      "Client initialized (modern API)\n",
      "Found 43 models\n",
      "Ready! Using model: gpt-4.1-mini\n"
     ]
    }
   ],
   "source": [
    "# Future-Proof OpenAI Assistant (updated models and discovery)\n",
    "import time\n",
    "\n",
    "class FutureProofAssistant:\n",
    "    def __init__(self, api_key=None):\n",
    "        self.api_key = api_key or API_KEY  # assumes API_KEY set in a previous cell\n",
    "        self.client = None\n",
    "        # Prefer modern families; keep a reasonable fallback\n",
    "        self.models = ['o4-mini', 'o4', 'gpt-4.1-mini', 'gpt-4.1', 'gpt-4o']\n",
    "        self.selected_model = None\n",
    "        self.max_retries = 3\n",
    "        \n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"No API key provided\")\n",
    "        \n",
    "        self._initialize()\n",
    "    \n",
    "    def _initialize(self):\n",
    "        print(\"Initializing Future-Proof Assistant...\")\n",
    "        self._setup_client()\n",
    "        self._discover_models()\n",
    "        self._select_model()\n",
    "        print(f\"Ready! Using model: {self.selected_model}\")\n",
    "    \n",
    "    def _setup_client(self):\n",
    "        try:\n",
    "            import openai\n",
    "            if hasattr(openai, 'OpenAI'):\n",
    "                self.client = openai.OpenAI(api_key=self.api_key)\n",
    "                print(\"Client initialized (modern API)\")\n",
    "            else:\n",
    "                openai.api_key = self.api_key\n",
    "                self.client = openai\n",
    "                print(\"Client initialized (legacy API)\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Client initialization failed: {e}\")\n",
    "    \n",
    "    def _discover_models(self):\n",
    "        try:\n",
    "            response = self.client.models.list()\n",
    "            all_models = [m.id for m in response.data]\n",
    "            # Prefer modern families; exclude legacy 3.5.\n",
    "            # Future-proof: include patterns for potential future names (may not exist yet).\n",
    "            include_patterns = ['o4', 'gpt-4.1', 'gpt-4o', 'gpt-5', 'gpt-4.5', 'gpt-6']\n",
    "            chat_models = [\n",
    "                m for m in all_models\n",
    "                if any(p in m.lower() for p in include_patterns)\n",
    "            ]\n",
    "            self.models = self._prioritize_models(chat_models) or self.models\n",
    "            print(f\"Found {len(self.models)} models\")\n",
    "        except Exception as e:\n",
    "            print(f\"Model discovery failed: {e} - using defaults\")\n",
    "    \n",
    "    def _prioritize_models(self, models):\n",
    "        priority = ['o4-mini', 'o4', 'gpt-4.1-mini', 'gpt-4.1', 'gpt-4o']\n",
    "        result = [m for m in priority if m in models]\n",
    "        result.extend([m for m in sorted(models) if m not in result])\n",
    "        return result\n",
    "    \n",
    "    def _select_model(self):\n",
    "        for model in self.models[:3]:\n",
    "            if self._test_model(model):\n",
    "                self.selected_model = model\n",
    "                return\n",
    "        self.selected_model = self.models[0]\n",
    "    \n",
    "    def _test_model(self, model):\n",
    "        try:\n",
    "            self.client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": \"Hi\"}],\n",
    "                max_tokens=5\n",
    "            )\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def ask_ai(self, content: str) -> str:\n",
    "        if not content or not content.strip():\n",
    "            return \"Error: Please provide a valid question.\"\n",
    "        \n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=self.selected_model,\n",
    "                    messages=[{\"role\": \"user\", \"content\": content.strip()}],\n",
    "                    max_tokens=1000,\n",
    "                    temperature=0.7\n",
    "                )\n",
    "                return self._extract_content(response)\n",
    "            \n",
    "            except Exception as e:\n",
    "                error_type = self._classify_error(e)\n",
    "                \n",
    "                if error_type == 'billing':\n",
    "                    return self._billing_error_message()\n",
    "                elif error_type == 'auth':\n",
    "                    return self._auth_error_message()\n",
    "                elif error_type == 'model':\n",
    "                    return self._model_error_message()\n",
    "                elif error_type == 'rate' and attempt < self.max_retries - 1:\n",
    "                    wait_time = 2 ** attempt\n",
    "                    print(f\"Rate limited. Waiting {wait_time}s...\")\n",
    "                    time.sleep(wait_time)\n",
    "                    continue\n",
    "                elif attempt < self.max_retries - 1:\n",
    "                    print(f\"Attempt {attempt + 1} failed: {str(e)[:50]}...\")\n",
    "                    time.sleep(1)\n",
    "                    continue\n",
    "                else:\n",
    "                    return f\"Error after {self.max_retries} attempts: {str(e)[:100]}...\"\n",
    "    \n",
    "    def _extract_content(self, response):\n",
    "        try:\n",
    "            return response.choices[0].message.content\n",
    "        except:\n",
    "            try:\n",
    "                return response.choices[0].text\n",
    "            except:\n",
    "                return str(response)\n",
    "    \n",
    "    def _classify_error(self, error):\n",
    "        error_str = str(error).lower()\n",
    "        if any(word in error_str for word in ['quota', 'billing', 'credit']):\n",
    "            return 'billing'\n",
    "        elif any(word in error_str for word in ['auth', 'key', 'unauthorized']):\n",
    "            return 'auth'\n",
    "        elif any(word in error_str for word in ['model', 'not_found']):\n",
    "            return 'model'\n",
    "        elif any(word in error_str for word in ['rate', 'limit', 'too_many']):\n",
    "            return 'rate'\n",
    "        return 'unknown'\n",
    "    \n",
    "    def _billing_error_message(self):\n",
    "        return \"\"\"BILLING ERROR: Insufficient credits.\n",
    "        \n",
    "To fix this:\n",
    "1. Visit: https://platform.openai.com/settings/organization/billing/overview\n",
    "2. Add a payment method\n",
    "3. Purchase credits (minimum $5)\n",
    "4. Wait a few minutes for credits to appear\n",
    "\n",
    "Note: OpenAI requires prepaid credits for API usage.\"\"\"\n",
    "    \n",
    "    def _auth_error_message(self):\n",
    "        return \"\"\"AUTHENTICATION ERROR: Invalid API key.\n",
    "        \n",
    "To fix this:\n",
    "1. Check your API key at: https://platform.openai.com/api-keys\n",
    "2. Create a new key if needed\n",
    "3. Re-run the API key setup cell above\n",
    "\n",
    "Make sure your key starts with 'sk-' and is complete.\"\"\"\n",
    "    \n",
    "    def _model_error_message(self):\n",
    "        return f\"\"\"MODEL ERROR: {self.selected_model} not available.\n",
    "        \n",
    "This usually means:\n",
    "1. Model has been deprecated\n",
    "2. Your account doesn't have access\n",
    "3. Temporary service issue\n",
    "\n",
    "The assistant will automatically try other models.\"\"\"\n",
    "\n",
    "# Initialize assistant\n",
    "if API_KEY:\n",
    "    assistant = FutureProofAssistant(API_KEY)\n",
    "else:\n",
    "    print(\"Cannot initialize assistant without API key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "test-function",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing assistant functionality...\n",
      "\n",
      "Basic Test: Hello, I am working!\n",
      "\n",
      "Empty Input Test: Error: Please provide a valid question.\n",
      "\n",
      "Selected Model: gpt-4.1-mini\n",
      "Available Models: ['o4-mini', 'gpt-4.1-mini', 'gpt-4.1']...\n",
      "\n",
      "Assistant is ready for use!\n"
     ]
    }
   ],
   "source": [
    "# Test the Assistant\n",
    "def ask_ai(content: str) -> str:\n",
    "    \"\"\"Simple interface to the future-proof assistant\"\"\"\n",
    "    if 'assistant' in globals():\n",
    "        return assistant.ask_ai(content)\n",
    "    else:\n",
    "        return \"Assistant not initialized. Please run the setup cells above.\"\n",
    "\n",
    "# Test with various scenarios\n",
    "if API_KEY:\n",
    "    print(\"Testing assistant functionality...\\n\")\n",
    "    \n",
    "    # Basic test\n",
    "    response = ask_ai(\"Say 'Hello, I am working!' in exactly those words.\")\n",
    "    print(f\"Basic Test: {response}\\n\")\n",
    "    \n",
    "    # Empty input test\n",
    "    response = ask_ai(\"\")\n",
    "    print(f\"Empty Input Test: {response}\\n\")\n",
    "    \n",
    "    # Model info\n",
    "    print(f\"Selected Model: {assistant.selected_model}\")\n",
    "    print(f\"Available Models: {assistant.models[:3]}...\")\n",
    "    \n",
    "    print(\"\\nAssistant is ready for use!\")\n",
    "else:\n",
    "    print(\"Please complete API key setup first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usage-examples",
   "metadata": {},
   "source": [
    "#### Usage Examples\n",
    "\n",
    "Now you can use the `ask_ai()` function for any queries:\n",
    "\n",
    "```python\n",
    "# Simple question\n",
    "response = ask_ai(\"What is machine learning?\")\n",
    "print(response)\n",
    "\n",
    "# Complex analysis\n",
    "response = ask_ai(\"Explain the benefits of using LLMs for data analysis\")\n",
    "print(response)\n",
    "```\n",
    "\n",
    "#### Future-Proof Features\n",
    "\n",
    "This setup automatically handles:\n",
    "- **API Changes**: Adapts to new OpenAI SDK versions\n",
    "- **Model Updates**: Discovers and selects optimal models\n",
    "- **Error Evolution**: Flexible error pattern matching\n",
    "- **Response Formats**: Multiple content extraction methods\n",
    "\n",
    "The assistant will continue working even as OpenAI updates their API!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ece2c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure! Here's a joke for you:\\n\\nWhy don't scientists trust atoms?  \\nBecause they make up everything!\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_ai(\"tell me a joke\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cc35d1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "640b74c6",
   "metadata": {},
   "source": [
    "# Chapter 4 code Starts Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085aefbe",
   "metadata": {},
   "source": [
    "## The Inexing Pipeline - Building Our Knowledge Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3ddfb1",
   "metadata": {},
   "source": [
    "### Installing Chromadb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a699dd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (0.5.23)\n",
      "Requirement already satisfied: build>=1.0.3 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from chromadb) (1.3.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from chromadb) (2.11.7)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from chromadb) (0.116.1)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from chromadb) (1.26.4)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from chromadb) (4.14.1)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from chromadb) (1.22.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from chromadb) (0.57b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from chromadb) (1.36.0)\n",
      "Requirement already satisfied: tokenizers<=0.20.3,>=0.13.2 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from chromadb) (0.20.3)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from chromadb) (1.74.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from chromadb) (0.16.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from chromadb) (33.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from chromadb) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from chromadb) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from chromadb) (3.11.1)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from chromadb) (14.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from tokenizers<=0.20.3,>=0.13.2->chromadb) (0.34.4)\n",
      "Requirement already satisfied: filelock in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb) (2025.7.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb) (25.0)\n",
      "Requirement already satisfied: requests in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb) (2.32.4)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb) (1.1.7)\n",
      "Requirement already satisfied: pyproject_hooks in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from fastapi>=0.95.2->chromadb) (0.47.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from starlette<0.48.0,>=0.40.0->fastapi>=0.95.2->chromadb) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi>=0.95.2->chromadb) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi>=0.95.2->chromadb) (1.3.1)\n",
      "Requirement already satisfied: certifi in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.40.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Requirement already satisfied: coloredlogs in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (6.31.1)\n",
      "Requirement already satisfied: sympy in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.36.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.36.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.57b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.57b0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.57b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.57b0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.57b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.57b0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.57b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from opentelemetry-instrumentation==0.57b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from opentelemetry-instrumentation-asgi==0.57b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.9.1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb) (3.4.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/lib/python3.12/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install chromadb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1c35cd",
   "metadata": {},
   "source": [
    "### Initialize the vector store for indexing\n",
    "\n",
    "The following code sets up the minimal infrastructure for our indexing pipeline.\n",
    "\n",
    "- __What this does__\n",
    "  - `chroma_client = chromadb.PersistentClient(path=\"db\")`: Initializes a persistent ChromaDB client at `./db` (local disk for this demo)\n",
    "  - `collection = chroma_client.get_or_create_collection(name=\"chapter4_collection\")`: Creates or opens the `chapter4_collection` where embeddings and source text will be stored\n",
    "\n",
    "- __Why this matters__\n",
    "  - The collection acts like a vector “table” we’ll reuse throughout the notebook\n",
    "  - Persistence lets you run subsequent cells without re-indexing each time\n",
    "\n",
    "- __Notes__\n",
    "  - Local persistence is convenient for learning\n",
    "  - For production, prefer a managed/vector DB with proper lifecycle, observability, and access controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5e6e29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Environment Verification ===\n",
      "Python executable: /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/.venv-ch4/bin/python\n",
      "Python version: 3.12.11 (main, Jun  3 2025, 15:41:47) [Clang 17.0.0 (clang-1700.0.13.3)]\n",
      "SUCCESS: Using Chapter 4 environment (.venv-ch4)\n",
      "Working directory: /Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/notebooks\n",
      "NumPy version: 1.26.4\n",
      "SUCCESS: NumPy version compatible with ChromaDB\n",
      "SUCCESS: ChromaDB available\n",
      "SUCCESS: OpenAI available\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"=== Environment Verification ===\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Check if we're in the correct Chapter 4 environment\n",
    "if '.venv-ch4' in sys.executable:\n",
    "    print(\"SUCCESS: Using Chapter 4 environment (.venv-ch4)\")\n",
    "else:\n",
    "    print(\"WARNING: NOT using Chapter 4 environment\")\n",
    "    print(\"   Expected path should contain '.venv-ch4'\")\n",
    "\n",
    "# Check current working directory\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Verify key packages and versions\n",
    "try:\n",
    "    import numpy\n",
    "    print(f\"NumPy version: {numpy.__version__}\")\n",
    "    if numpy.__version__.startswith('1.'):\n",
    "        print(\"SUCCESS: NumPy version compatible with ChromaDB\")\n",
    "    else:\n",
    "        print(\"WARNING: NumPy version may cause ChromaDB issues\")\n",
    "except ImportError:\n",
    "    print(\"ERROR: NumPy not installed\")\n",
    "\n",
    "try:\n",
    "    import chromadb\n",
    "    print(\"SUCCESS: ChromaDB available\")\n",
    "except ImportError as e:\n",
    "    print(f\"ERROR: ChromaDB not available: {e}\")\n",
    "\n",
    "try:\n",
    "    import openai\n",
    "    print(\"SUCCESS: OpenAI available\")\n",
    "except ImportError:\n",
    "    print(\"ERROR: OpenAI not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47faad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, make sure you have the necessary libraries installed\n",
    "# pip install chromadb\n",
    "\n",
    "import chromadb\n",
    "\n",
    "# --- 1. Setup --- \n",
    "# For this example, we'll use a persistent, on-disk database.\n",
    "# This is NOT a good practice for any real project.\n",
    "chroma_client = chromadb.PersistentClient(path=\"ch4_db\")\n",
    "\n",
    "# Get or create a collection. This is like a table in a traditional database.\n",
    "# We can also specify the embedding model we want to use.\n",
    "collection = chroma_client.get_or_create_collection(name=\"chapter4_collection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9899b1",
   "metadata": {},
   "source": [
    "### Results and verification\n",
    "\n",
    "After running the above code:\n",
    "\n",
    "- __Expected results__\n",
    "  - ChromaDB client connected to local database\n",
    "  - Collection handle ready for document operations\n",
    "\n",
    "- __Verify the results__\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a4d0b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database directory exists: True\n",
      "Collection count: 4\n",
      "Collection name: chapter4_collection\n"
     ]
    }
   ],
   "source": [
    "# Check if database directory was created\n",
    "import os\n",
    "print(f\"Database directory exists: {os.path.exists('ch4_db')}\")\n",
    "\n",
    "# Verify collection was created\n",
    "print(f\"Collection count: {collection.count()}\")\n",
    "print(f\"Collection name: {collection.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31dc8407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document id_0 already exists in the collection.\n",
      "Document id_1 already exists in the collection.\n",
      "Document id_2 already exists in the collection.\n",
      "Document id_3 already exists in the collection.\n",
      "\n",
      "The collection now contains 4 items.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Our Raw Data --- \n",
    "# In a real system, this would come from files, a database, or an API.\n",
    "# For our example, we'll just use a list of strings.\n",
    "documents = [\n",
    "    \"The company's new AI policy, effective June 1st, requires all employees to complete a mandatory training course.\",\n",
    "    \"Our Q2 financial results show a 15% increase in revenue, driven by strong sales in the European market.\",\n",
    "    \"The Phoenix Project, our next-generation AI platform, is scheduled for a beta release in the third quarter.\",\n",
    "    \"All travel and expense reports must be submitted through the new online portal by the 25th of each month.\"\n",
    "]\n",
    "\n",
    "# --- 3. The Indexing Process --- \n",
    "# We need to add each document to our collection. ChromaDB will handle\n",
    "# the embedding process for us automatically if we don't provide our own.\n",
    "# We also need to provide a unique ID for each document.\n",
    "\n",
    "# It's good practice to check if the document already exists before adding.\n",
    "existing_ids = collection.get(ids=[f\"id_{i}\" for i in range(len(documents))])['ids']\n",
    "\n",
    "for i, doc in enumerate(documents):\n",
    "    # Create a predictable ID for this document (id_0, id_1, etc.)\n",
    "    doc_id = f\"id_{i}\"\n",
    "    \n",
    "    # Only add the document if it's not already in the collection\n",
    "    if doc_id not in existing_ids:\n",
    "        collection.add(\n",
    "            documents=[doc],  # The actual text content\n",
    "            ids=[doc_id]      # Our unique identifier\n",
    "        )\n",
    "        print(f\"Added document {doc_id} to the collection.\")\n",
    "    else:\n",
    "        print(f\"Document {doc_id} already exists in the collection.\")\n",
    "\n",
    "# --- 4. Verification --- \n",
    "# Let's check how many items are in our collection.\n",
    "count = collection.count()\n",
    "print(f\"\\nThe collection now contains {count} items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44095da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document IDs: ['id_0', 'id_1', 'id_2', 'id_3']\n",
      "First document preview: The company's new AI policy, effective June 1st, r...\n"
     ]
    }
   ],
   "source": [
    "# Let's also peek at what's actually stored\n",
    "all_data = collection.get()\n",
    "print(f\"Document IDs: {all_data['ids']}\")\n",
    "print(f\"First document preview: {all_data['documents'][0][:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c7a02c",
   "metadata": {},
   "source": [
    "## The Query Pipeline - Finding and Using Knowledge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8530c3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. The Core RAG Function (Enhanced with Debugging) ---\n",
    "def ask_rag(query: str, db_path=\"ch4_db\", collection_name=\"chapter4_collection\", debug=True):\n",
    "    \"\"\"Takes a user query, retrieves context, and generates an answer with detailed debugging.\"\"\"\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"QUERY: '{query}'\")\n",
    "        print(\"=\" * 50)\n",
    "    \n",
    "    # === DATABASE CONNECTION SETUP ===\n",
    "    try:\n",
    "        if 'chroma_client' not in globals():\n",
    "            chroma_client = chromadb.PersistentClient(path=db_path)\n",
    "            if debug: print(\"STATUS: Created new ChromaDB client\")\n",
    "        else:\n",
    "            chroma_client = globals()['chroma_client']\n",
    "            if debug: print(\"STATUS: Reusing existing ChromaDB client\")\n",
    "    except ValueError:\n",
    "        chromadb.reset()\n",
    "        chroma_client = chromadb.PersistentClient(path=db_path)\n",
    "        if debug: print(\"STATUS: Reset and created new ChromaDB client\")\n",
    "    \n",
    "    collection = chroma_client.get_collection(name=collection_name)\n",
    "    if debug: print(f\"COLLECTION: Connected to {collection_name}\")\n",
    "    \n",
    "    # === STEP 1A: RETRIEVE RELEVANT DOCUMENTS ===\n",
    "    if debug: print(f\"\\nSTEP 1: Searching for documents similar to: '{query}'\")\n",
    "    \n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=2,\n",
    "        include=['documents', 'distances', 'metadatas']  # Fixed: removed 'ids', added 'metadatas'\n",
    "    )\n",
    "    \n",
    "    retrieved_documents = results['documents'][0]\n",
    "    distances = results['distances'][0]\n",
    "    metadatas = results.get('metadatas', [{}] * len(retrieved_documents))[0]  # Safe access to metadatas\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"RESULTS: Found {len(retrieved_documents)} documents:\")\n",
    "        for i, (distance, doc, metadata) in enumerate(zip(distances, retrieved_documents, metadatas)):\n",
    "            # Use metadata ID if available, otherwise use index\n",
    "            doc_id = metadata.get('id', f'doc_{i}') if metadata else f'doc_{i}'\n",
    "            print(f\"  {i+1}. ID: {doc_id} | Similarity: {1-distance:.3f} | Preview: {doc[:60]}...\")\n",
    "    \n",
    "    # Combine all retrieved documents into a single context string\n",
    "    context = \"\\n\\n\".join(retrieved_documents)\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"\\nCONTEXT: Combined {len(retrieved_documents)} documents into context\")\n",
    "        print(f\"CONTEXT LENGTH: {len(context)} characters\")\n",
    "        print(\"\\nFULL CONTEXT:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(context)\n",
    "        print(\"-\" * 40)\n",
    "    \n",
    "    # === STEP 1B: CONSTRUCT THE PROMPT ===\n",
    "    if debug: print(f\"\\nSTEP 2: Constructing prompt with context and query\")\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are an expert assistant. Use the following retrieved context to answer the user's question.\n",
    "    If the answer is not in the context, state that you cannot find the information.\n",
    "    Do not use any other information.\n",
    "\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "\n",
    "    <question>\n",
    "    {query}\n",
    "    </question>\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"PROMPT LENGTH: {len(prompt)} characters\")\n",
    "        print(\"\\nFULL PROMPT BEING SENT TO LLM:\")\n",
    "        print(\"=\" * 60)\n",
    "        print(prompt)\n",
    "        print(\"=\" * 60)\n",
    "        print(\"\\nPROMPT BREAKDOWN:\")\n",
    "        print(\"- Instructions: Lines 2-4 (system instructions)\")\n",
    "        print(\"- Context section: Between <context> and </context> tags\")\n",
    "        print(\"- Question section: Between <question> and </question> tags\")\n",
    "        print(\"- Answer prompt: Final 'Answer:' line\")\n",
    "    \n",
    "    # === STEP 1C: GENERATE THE ANSWER ===\n",
    "    if debug: print(f\"\\nSTEP 3: Sending prompt to LLM\")\n",
    "    \n",
    "    response = ask_ai(prompt)\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"\\nLLM RESPONSE: {response}\")\n",
    "        print(\"=\" * 50)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c1e99bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY: 'What is the new AI policy?'\n",
      "==================================================\n",
      "STATUS: Reusing existing ChromaDB client\n",
      "COLLECTION: Connected to chapter4_collection\n",
      "\n",
      "STEP 1: Searching for documents similar to: 'What is the new AI policy?'\n",
      "RESULTS: Found 2 documents:\n",
      "  1. ID: doc_0 | Similarity: 0.159 | Preview: The company's new AI policy, effective June 1st, requires al...\n",
      "  2. ID: doc_1 | Similarity: 0.031 | Preview: The Phoenix Project, our next-generation AI platform, is sch...\n",
      "\n",
      "CONTEXT: Combined 2 documents into context\n",
      "CONTEXT LENGTH: 221 characters\n",
      "\n",
      "FULL CONTEXT:\n",
      "----------------------------------------\n",
      "The company's new AI policy, effective June 1st, requires all employees to complete a mandatory training course.\n",
      "\n",
      "The Phoenix Project, our next-generation AI platform, is scheduled for a beta release in the third quarter.\n",
      "----------------------------------------\n",
      "\n",
      "STEP 2: Constructing prompt with context and query\n",
      "PROMPT LENGTH: 560 characters\n",
      "\n",
      "FULL PROMPT BEING SENT TO LLM:\n",
      "============================================================\n",
      "\n",
      "    You are an expert assistant. Use the following retrieved context to answer the user's question.\n",
      "    If the answer is not in the context, state that you cannot find the information.\n",
      "    Do not use any other information.\n",
      "\n",
      "    <context>\n",
      "    The company's new AI policy, effective June 1st, requires all employees to complete a mandatory training course.\n",
      "\n",
      "The Phoenix Project, our next-generation AI platform, is scheduled for a beta release in the third quarter.\n",
      "    </context>\n",
      "\n",
      "    <question>\n",
      "    What is the new AI policy?\n",
      "    </question>\n",
      "\n",
      "    Answer:\n",
      "    \n",
      "============================================================\n",
      "\n",
      "PROMPT BREAKDOWN:\n",
      "- Instructions: Lines 2-4 (system instructions)\n",
      "- Context section: Between <context> and </context> tags\n",
      "- Question section: Between <question> and </question> tags\n",
      "- Answer prompt: Final 'Answer:' line\n",
      "\n",
      "STEP 3: Sending prompt to LLM\n",
      "\n",
      "LLM RESPONSE: The new AI policy requires all employees to complete a mandatory training course and is effective June 1st.\n",
      "==================================================\n",
      "\n",
      "Query: What is the new AI policy?\n",
      "Answer: The new AI policy requires all employees to complete a mandatory training course and is effective June 1st.\n",
      "QUERY: 'What were the Q1 financial results?'\n",
      "==================================================\n",
      "STATUS: Reusing existing ChromaDB client\n",
      "COLLECTION: Connected to chapter4_collection\n",
      "\n",
      "STEP 1: Searching for documents similar to: 'What were the Q1 financial results?'\n",
      "RESULTS: Found 2 documents:\n",
      "  1. ID: doc_0 | Similarity: 0.123 | Preview: Our Q2 financial results show a 15% increase in revenue, dri...\n",
      "  2. ID: doc_1 | Similarity: -0.628 | Preview: All travel and expense reports must be submitted through the...\n",
      "\n",
      "CONTEXT: Combined 2 documents into context\n",
      "CONTEXT LENGTH: 210 characters\n",
      "\n",
      "FULL CONTEXT:\n",
      "----------------------------------------\n",
      "Our Q2 financial results show a 15% increase in revenue, driven by strong sales in the European market.\n",
      "\n",
      "All travel and expense reports must be submitted through the new online portal by the 25th of each month.\n",
      "----------------------------------------\n",
      "\n",
      "STEP 2: Constructing prompt with context and query\n",
      "PROMPT LENGTH: 558 characters\n",
      "\n",
      "FULL PROMPT BEING SENT TO LLM:\n",
      "============================================================\n",
      "\n",
      "    You are an expert assistant. Use the following retrieved context to answer the user's question.\n",
      "    If the answer is not in the context, state that you cannot find the information.\n",
      "    Do not use any other information.\n",
      "\n",
      "    <context>\n",
      "    Our Q2 financial results show a 15% increase in revenue, driven by strong sales in the European market.\n",
      "\n",
      "All travel and expense reports must be submitted through the new online portal by the 25th of each month.\n",
      "    </context>\n",
      "\n",
      "    <question>\n",
      "    What were the Q1 financial results?\n",
      "    </question>\n",
      "\n",
      "    Answer:\n",
      "    \n",
      "============================================================\n",
      "\n",
      "PROMPT BREAKDOWN:\n",
      "- Instructions: Lines 2-4 (system instructions)\n",
      "- Context section: Between <context> and </context> tags\n",
      "- Question section: Between <question> and </question> tags\n",
      "- Answer prompt: Final 'Answer:' line\n",
      "\n",
      "STEP 3: Sending prompt to LLM\n",
      "\n",
      "LLM RESPONSE: I cannot find the information about the Q1 financial results in the provided context.\n",
      "==================================================\n",
      "\n",
      "Query: What were the Q1 financial results?\n",
      "Answer: I cannot find the information about the Q1 financial results in the provided context.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Let's Ask a Question! --- \n",
    "\n",
    "\n",
    "user_query = \"What is the new AI policy?\"\n",
    "final_answer = ask_rag(user_query)\n",
    "\n",
    "print(f\"\\nQuery: {user_query}\")\n",
    "print(f\"Answer: {final_answer}\")\n",
    "\n",
    "user_query_2 = \"What were the Q1 financial results?\"\n",
    "final_answer_2 = ask_rag(user_query_2)\n",
    "\n",
    "print(f\"\\nQuery: {user_query_2}\")\n",
    "print(f\"Answer: {final_answer_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2475f6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c35e199c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/Users/relhousieny/code/personal/books/data-strategy-book/27July2025/chapter4/chapter4/notebooks/ingest_case_study_docs.py': [Errno 2] No such file or directory\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Seed four tiny case-study documents into ChromaDB (idempotent)\n",
    "import subprocess, sys, os\n",
    "\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "script_path = os.path.join(repo_root, \"chapter4\", \"notebooks\", \"ingest_case_study_docs.py\")\n",
    "\n",
    "result = subprocess.run([sys.executable, script_path], capture_output=True, text=True)\n",
    "print(result.stdout or result.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "111e0b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Personal ===\n",
      "\n",
      "Query: Top threads with Alice last 7 days\n",
      "QUERY: 'Top threads with Alice last 7 days'\n",
      "==================================================\n",
      "STATUS: Reusing existing ChromaDB client\n",
      "COLLECTION: Connected to chapter4_collection\n",
      "\n",
      "STEP 1: Searching for documents similar to: 'Top threads with Alice last 7 days'\n",
      "RESULTS: Found 2 documents:\n",
      "  1. ID: doc_0 | Similarity: -0.646 | Preview: The Phoenix Project, our next-generation AI platform, is sch...\n",
      "  2. ID: doc_1 | Similarity: -0.847 | Preview: All travel and expense reports must be submitted through the...\n",
      "\n",
      "CONTEXT: Combined 2 documents into context\n",
      "CONTEXT LENGTH: 214 characters\n",
      "\n",
      "FULL CONTEXT:\n",
      "----------------------------------------\n",
      "The Phoenix Project, our next-generation AI platform, is scheduled for a beta release in the third quarter.\n",
      "\n",
      "All travel and expense reports must be submitted through the new online portal by the 25th of each month.\n",
      "----------------------------------------\n",
      "\n",
      "STEP 2: Constructing prompt with context and query\n",
      "PROMPT LENGTH: 561 characters\n",
      "\n",
      "FULL PROMPT BEING SENT TO LLM:\n",
      "============================================================\n",
      "\n",
      "    You are an expert assistant. Use the following retrieved context to answer the user's question.\n",
      "    If the answer is not in the context, state that you cannot find the information.\n",
      "    Do not use any other information.\n",
      "\n",
      "    <context>\n",
      "    The Phoenix Project, our next-generation AI platform, is scheduled for a beta release in the third quarter.\n",
      "\n",
      "All travel and expense reports must be submitted through the new online portal by the 25th of each month.\n",
      "    </context>\n",
      "\n",
      "    <question>\n",
      "    Top threads with Alice last 7 days\n",
      "    </question>\n",
      "\n",
      "    Answer:\n",
      "    \n",
      "============================================================\n",
      "\n",
      "PROMPT BREAKDOWN:\n",
      "- Instructions: Lines 2-4 (system instructions)\n",
      "- Context section: Between <context> and </context> tags\n",
      "- Question section: Between <question> and </question> tags\n",
      "- Answer prompt: Final 'Answer:' line\n",
      "\n",
      "STEP 3: Sending prompt to LLM\n",
      "\n",
      "LLM RESPONSE: I cannot find the information about the top threads with Alice in the last 7 days in the provided context.\n",
      "==================================================\n",
      "Answer: I cannot find the information about the top threads with Alice in the last 7 days in the provided context.\n",
      "\n",
      "Query: What deadlines do I have this week?\n",
      "QUERY: 'What deadlines do I have this week?'\n",
      "==================================================\n",
      "STATUS: Reusing existing ChromaDB client\n",
      "COLLECTION: Connected to chapter4_collection\n",
      "\n",
      "STEP 1: Searching for documents similar to: 'What deadlines do I have this week?'\n",
      "RESULTS: Found 2 documents:\n",
      "  1. ID: doc_0 | Similarity: -0.468 | Preview: All travel and expense reports must be submitted through the...\n",
      "  2. ID: doc_1 | Similarity: -0.539 | Preview: The Phoenix Project, our next-generation AI platform, is sch...\n",
      "\n",
      "CONTEXT: Combined 2 documents into context\n",
      "CONTEXT LENGTH: 214 characters\n",
      "\n",
      "FULL CONTEXT:\n",
      "----------------------------------------\n",
      "All travel and expense reports must be submitted through the new online portal by the 25th of each month.\n",
      "\n",
      "The Phoenix Project, our next-generation AI platform, is scheduled for a beta release in the third quarter.\n",
      "----------------------------------------\n",
      "\n",
      "STEP 2: Constructing prompt with context and query\n",
      "PROMPT LENGTH: 562 characters\n",
      "\n",
      "FULL PROMPT BEING SENT TO LLM:\n",
      "============================================================\n",
      "\n",
      "    You are an expert assistant. Use the following retrieved context to answer the user's question.\n",
      "    If the answer is not in the context, state that you cannot find the information.\n",
      "    Do not use any other information.\n",
      "\n",
      "    <context>\n",
      "    All travel and expense reports must be submitted through the new online portal by the 25th of each month.\n",
      "\n",
      "The Phoenix Project, our next-generation AI platform, is scheduled for a beta release in the third quarter.\n",
      "    </context>\n",
      "\n",
      "    <question>\n",
      "    What deadlines do I have this week?\n",
      "    </question>\n",
      "\n",
      "    Answer:\n",
      "    \n",
      "============================================================\n",
      "\n",
      "PROMPT BREAKDOWN:\n",
      "- Instructions: Lines 2-4 (system instructions)\n",
      "- Context section: Between <context> and </context> tags\n",
      "- Question section: Between <question> and </question> tags\n",
      "- Answer prompt: Final 'Answer:' line\n",
      "\n",
      "STEP 3: Sending prompt to LLM\n",
      "\n",
      "LLM RESPONSE: The deadline you have this week is to submit all travel and expense reports through the new online portal by the 25th of the month.\n",
      "==================================================\n",
      "Answer: The deadline you have this week is to submit all travel and expense reports through the new online portal by the 25th of the month.\n",
      "\n",
      "=== Domain ===\n",
      "\n",
      "Query: Compare API v1 vs v2 authentication flow\n",
      "QUERY: 'Compare API v1 vs v2 authentication flow'\n",
      "==================================================\n",
      "STATUS: Reusing existing ChromaDB client\n",
      "COLLECTION: Connected to chapter4_collection\n",
      "\n",
      "STEP 1: Searching for documents similar to: 'Compare API v1 vs v2 authentication flow'\n",
      "RESULTS: Found 2 documents:\n",
      "  1. ID: doc_0 | Similarity: -0.903 | Preview: The company's new AI policy, effective June 1st, requires al...\n",
      "  2. ID: doc_1 | Similarity: -0.919 | Preview: All travel and expense reports must be submitted through the...\n",
      "\n",
      "CONTEXT: Combined 2 documents into context\n",
      "CONTEXT LENGTH: 219 characters\n",
      "\n",
      "FULL CONTEXT:\n",
      "----------------------------------------\n",
      "The company's new AI policy, effective June 1st, requires all employees to complete a mandatory training course.\n",
      "\n",
      "All travel and expense reports must be submitted through the new online portal by the 25th of each month.\n",
      "----------------------------------------\n",
      "\n",
      "STEP 2: Constructing prompt with context and query\n",
      "PROMPT LENGTH: 572 characters\n",
      "\n",
      "FULL PROMPT BEING SENT TO LLM:\n",
      "============================================================\n",
      "\n",
      "    You are an expert assistant. Use the following retrieved context to answer the user's question.\n",
      "    If the answer is not in the context, state that you cannot find the information.\n",
      "    Do not use any other information.\n",
      "\n",
      "    <context>\n",
      "    The company's new AI policy, effective June 1st, requires all employees to complete a mandatory training course.\n",
      "\n",
      "All travel and expense reports must be submitted through the new online portal by the 25th of each month.\n",
      "    </context>\n",
      "\n",
      "    <question>\n",
      "    Compare API v1 vs v2 authentication flow\n",
      "    </question>\n",
      "\n",
      "    Answer:\n",
      "    \n",
      "============================================================\n",
      "\n",
      "PROMPT BREAKDOWN:\n",
      "- Instructions: Lines 2-4 (system instructions)\n",
      "- Context section: Between <context> and </context> tags\n",
      "- Question section: Between <question> and </question> tags\n",
      "- Answer prompt: Final 'Answer:' line\n",
      "\n",
      "STEP 3: Sending prompt to LLM\n",
      "\n",
      "LLM RESPONSE: I cannot find the information regarding the comparison of API v1 vs v2 authentication flow in the provided context.\n",
      "==================================================\n",
      "Answer: I cannot find the information regarding the comparison of API v1 vs v2 authentication flow in the provided context.\n",
      "\n",
      "Query: List all preconditions for Procedure X\n",
      "QUERY: 'List all preconditions for Procedure X'\n",
      "==================================================\n",
      "STATUS: Reusing existing ChromaDB client\n",
      "COLLECTION: Connected to chapter4_collection\n",
      "\n",
      "STEP 1: Searching for documents similar to: 'List all preconditions for Procedure X'\n",
      "RESULTS: Found 2 documents:\n",
      "  1. ID: doc_0 | Similarity: -0.679 | Preview: The company's new AI policy, effective June 1st, requires al...\n",
      "  2. ID: doc_1 | Similarity: -0.794 | Preview: All travel and expense reports must be submitted through the...\n",
      "\n",
      "CONTEXT: Combined 2 documents into context\n",
      "CONTEXT LENGTH: 219 characters\n",
      "\n",
      "FULL CONTEXT:\n",
      "----------------------------------------\n",
      "The company's new AI policy, effective June 1st, requires all employees to complete a mandatory training course.\n",
      "\n",
      "All travel and expense reports must be submitted through the new online portal by the 25th of each month.\n",
      "----------------------------------------\n",
      "\n",
      "STEP 2: Constructing prompt with context and query\n",
      "PROMPT LENGTH: 570 characters\n",
      "\n",
      "FULL PROMPT BEING SENT TO LLM:\n",
      "============================================================\n",
      "\n",
      "    You are an expert assistant. Use the following retrieved context to answer the user's question.\n",
      "    If the answer is not in the context, state that you cannot find the information.\n",
      "    Do not use any other information.\n",
      "\n",
      "    <context>\n",
      "    The company's new AI policy, effective June 1st, requires all employees to complete a mandatory training course.\n",
      "\n",
      "All travel and expense reports must be submitted through the new online portal by the 25th of each month.\n",
      "    </context>\n",
      "\n",
      "    <question>\n",
      "    List all preconditions for Procedure X\n",
      "    </question>\n",
      "\n",
      "    Answer:\n",
      "    \n",
      "============================================================\n",
      "\n",
      "PROMPT BREAKDOWN:\n",
      "- Instructions: Lines 2-4 (system instructions)\n",
      "- Context section: Between <context> and </context> tags\n",
      "- Question section: Between <question> and </question> tags\n",
      "- Answer prompt: Final 'Answer:' line\n",
      "\n",
      "STEP 3: Sending prompt to LLM\n",
      "\n",
      "LLM RESPONSE: I cannot find the information about the preconditions for Procedure X in the provided context.\n",
      "==================================================\n",
      "Answer: I cannot find the information about the preconditions for Procedure X in the provided context.\n",
      "\n",
      "=== Enterprise ===\n",
      "\n",
      "Query: Latest customer escalation for Acme Corp\n",
      "QUERY: 'Latest customer escalation for Acme Corp'\n",
      "==================================================\n",
      "STATUS: Reusing existing ChromaDB client\n",
      "COLLECTION: Connected to chapter4_collection\n",
      "\n",
      "STEP 1: Searching for documents similar to: 'Latest customer escalation for Acme Corp'\n",
      "RESULTS: Found 2 documents:\n",
      "  1. ID: doc_0 | Similarity: -0.540 | Preview: All travel and expense reports must be submitted through the...\n",
      "  2. ID: doc_1 | Similarity: -0.562 | Preview: The company's new AI policy, effective June 1st, requires al...\n",
      "\n",
      "CONTEXT: Combined 2 documents into context\n",
      "CONTEXT LENGTH: 219 characters\n",
      "\n",
      "FULL CONTEXT:\n",
      "----------------------------------------\n",
      "All travel and expense reports must be submitted through the new online portal by the 25th of each month.\n",
      "\n",
      "The company's new AI policy, effective June 1st, requires all employees to complete a mandatory training course.\n",
      "----------------------------------------\n",
      "\n",
      "STEP 2: Constructing prompt with context and query\n",
      "PROMPT LENGTH: 572 characters\n",
      "\n",
      "FULL PROMPT BEING SENT TO LLM:\n",
      "============================================================\n",
      "\n",
      "    You are an expert assistant. Use the following retrieved context to answer the user's question.\n",
      "    If the answer is not in the context, state that you cannot find the information.\n",
      "    Do not use any other information.\n",
      "\n",
      "    <context>\n",
      "    All travel and expense reports must be submitted through the new online portal by the 25th of each month.\n",
      "\n",
      "The company's new AI policy, effective June 1st, requires all employees to complete a mandatory training course.\n",
      "    </context>\n",
      "\n",
      "    <question>\n",
      "    Latest customer escalation for Acme Corp\n",
      "    </question>\n",
      "\n",
      "    Answer:\n",
      "    \n",
      "============================================================\n",
      "\n",
      "PROMPT BREAKDOWN:\n",
      "- Instructions: Lines 2-4 (system instructions)\n",
      "- Context section: Between <context> and </context> tags\n",
      "- Question section: Between <question> and </question> tags\n",
      "- Answer prompt: Final 'Answer:' line\n",
      "\n",
      "STEP 3: Sending prompt to LLM\n",
      "\n",
      "LLM RESPONSE: I cannot find the information about the latest customer escalation for Acme Corp in the provided context.\n",
      "==================================================\n",
      "Answer: I cannot find the information about the latest customer escalation for Acme Corp in the provided context.\n",
      "\n",
      "Query: What is our PTO policy for contractors?\n",
      "QUERY: 'What is our PTO policy for contractors?'\n",
      "==================================================\n",
      "STATUS: Reusing existing ChromaDB client\n",
      "COLLECTION: Connected to chapter4_collection\n",
      "\n",
      "STEP 1: Searching for documents similar to: 'What is our PTO policy for contractors?'\n",
      "RESULTS: Found 2 documents:\n",
      "  1. ID: doc_0 | Similarity: -0.430 | Preview: The company's new AI policy, effective June 1st, requires al...\n",
      "  2. ID: doc_1 | Similarity: -0.819 | Preview: The Phoenix Project, our next-generation AI platform, is sch...\n",
      "\n",
      "CONTEXT: Combined 2 documents into context\n",
      "CONTEXT LENGTH: 221 characters\n",
      "\n",
      "FULL CONTEXT:\n",
      "----------------------------------------\n",
      "The company's new AI policy, effective June 1st, requires all employees to complete a mandatory training course.\n",
      "\n",
      "The Phoenix Project, our next-generation AI platform, is scheduled for a beta release in the third quarter.\n",
      "----------------------------------------\n",
      "\n",
      "STEP 2: Constructing prompt with context and query\n",
      "PROMPT LENGTH: 573 characters\n",
      "\n",
      "FULL PROMPT BEING SENT TO LLM:\n",
      "============================================================\n",
      "\n",
      "    You are an expert assistant. Use the following retrieved context to answer the user's question.\n",
      "    If the answer is not in the context, state that you cannot find the information.\n",
      "    Do not use any other information.\n",
      "\n",
      "    <context>\n",
      "    The company's new AI policy, effective June 1st, requires all employees to complete a mandatory training course.\n",
      "\n",
      "The Phoenix Project, our next-generation AI platform, is scheduled for a beta release in the third quarter.\n",
      "    </context>\n",
      "\n",
      "    <question>\n",
      "    What is our PTO policy for contractors?\n",
      "    </question>\n",
      "\n",
      "    Answer:\n",
      "    \n",
      "============================================================\n",
      "\n",
      "PROMPT BREAKDOWN:\n",
      "- Instructions: Lines 2-4 (system instructions)\n",
      "- Context section: Between <context> and </context> tags\n",
      "- Question section: Between <question> and </question> tags\n",
      "- Answer prompt: Final 'Answer:' line\n",
      "\n",
      "STEP 3: Sending prompt to LLM\n",
      "\n",
      "LLM RESPONSE: I cannot find the information regarding the PTO policy for contractors in the provided context.\n",
      "==================================================\n",
      "Answer: I cannot find the information regarding the PTO policy for contractors in the provided context.\n",
      "\n",
      "=== Moderation ===\n",
      "\n",
      "Query: Classify this post and cite policy section: 'I hate everyone in this group'\n",
      "QUERY: 'Classify this post and cite policy section: 'I hate everyone in this group''\n",
      "==================================================\n",
      "STATUS: Reusing existing ChromaDB client\n",
      "COLLECTION: Connected to chapter4_collection\n",
      "\n",
      "STEP 1: Searching for documents similar to: 'Classify this post and cite policy section: 'I hate everyone in this group''\n",
      "RESULTS: Found 2 documents:\n",
      "  1. ID: doc_0 | Similarity: -0.837 | Preview: The company's new AI policy, effective June 1st, requires al...\n",
      "  2. ID: doc_1 | Similarity: -0.906 | Preview: The Phoenix Project, our next-generation AI platform, is sch...\n",
      "\n",
      "CONTEXT: Combined 2 documents into context\n",
      "CONTEXT LENGTH: 221 characters\n",
      "\n",
      "FULL CONTEXT:\n",
      "----------------------------------------\n",
      "The company's new AI policy, effective June 1st, requires all employees to complete a mandatory training course.\n",
      "\n",
      "The Phoenix Project, our next-generation AI platform, is scheduled for a beta release in the third quarter.\n",
      "----------------------------------------\n",
      "\n",
      "STEP 2: Constructing prompt with context and query\n",
      "PROMPT LENGTH: 609 characters\n",
      "\n",
      "FULL PROMPT BEING SENT TO LLM:\n",
      "============================================================\n",
      "\n",
      "    You are an expert assistant. Use the following retrieved context to answer the user's question.\n",
      "    If the answer is not in the context, state that you cannot find the information.\n",
      "    Do not use any other information.\n",
      "\n",
      "    <context>\n",
      "    The company's new AI policy, effective June 1st, requires all employees to complete a mandatory training course.\n",
      "\n",
      "The Phoenix Project, our next-generation AI platform, is scheduled for a beta release in the third quarter.\n",
      "    </context>\n",
      "\n",
      "    <question>\n",
      "    Classify this post and cite policy section: 'I hate everyone in this group'\n",
      "    </question>\n",
      "\n",
      "    Answer:\n",
      "    \n",
      "============================================================\n",
      "\n",
      "PROMPT BREAKDOWN:\n",
      "- Instructions: Lines 2-4 (system instructions)\n",
      "- Context section: Between <context> and </context> tags\n",
      "- Question section: Between <question> and </question> tags\n",
      "- Answer prompt: Final 'Answer:' line\n",
      "\n",
      "STEP 3: Sending prompt to LLM\n",
      "\n",
      "LLM RESPONSE: I cannot find the information regarding the classification of the post or the specific policy section related to the statement 'I hate everyone in this group' in the provided context.\n",
      "==================================================\n",
      "Answer: I cannot find the information regarding the classification of the post or the specific policy section related to the statement 'I hate everyone in this group' in the provided context.\n",
      "\n",
      "Query: Is this self-harm content? Provide intervention steps: 'I feel like hurting myself'\n",
      "QUERY: 'Is this self-harm content? Provide intervention steps: 'I feel like hurting myself''\n",
      "==================================================\n",
      "STATUS: Reusing existing ChromaDB client\n",
      "COLLECTION: Connected to chapter4_collection\n",
      "\n",
      "STEP 1: Searching for documents similar to: 'Is this self-harm content? Provide intervention steps: 'I feel like hurting myself''\n",
      "RESULTS: Found 2 documents:\n",
      "  1. ID: doc_0 | Similarity: -0.868 | Preview: The Phoenix Project, our next-generation AI platform, is sch...\n",
      "  2. ID: doc_1 | Similarity: -0.906 | Preview: The company's new AI policy, effective June 1st, requires al...\n",
      "\n",
      "CONTEXT: Combined 2 documents into context\n",
      "CONTEXT LENGTH: 221 characters\n",
      "\n",
      "FULL CONTEXT:\n",
      "----------------------------------------\n",
      "The Phoenix Project, our next-generation AI platform, is scheduled for a beta release in the third quarter.\n",
      "\n",
      "The company's new AI policy, effective June 1st, requires all employees to complete a mandatory training course.\n",
      "----------------------------------------\n",
      "\n",
      "STEP 2: Constructing prompt with context and query\n",
      "PROMPT LENGTH: 617 characters\n",
      "\n",
      "FULL PROMPT BEING SENT TO LLM:\n",
      "============================================================\n",
      "\n",
      "    You are an expert assistant. Use the following retrieved context to answer the user's question.\n",
      "    If the answer is not in the context, state that you cannot find the information.\n",
      "    Do not use any other information.\n",
      "\n",
      "    <context>\n",
      "    The Phoenix Project, our next-generation AI platform, is scheduled for a beta release in the third quarter.\n",
      "\n",
      "The company's new AI policy, effective June 1st, requires all employees to complete a mandatory training course.\n",
      "    </context>\n",
      "\n",
      "    <question>\n",
      "    Is this self-harm content? Provide intervention steps: 'I feel like hurting myself'\n",
      "    </question>\n",
      "\n",
      "    Answer:\n",
      "    \n",
      "============================================================\n",
      "\n",
      "PROMPT BREAKDOWN:\n",
      "- Instructions: Lines 2-4 (system instructions)\n",
      "- Context section: Between <context> and </context> tags\n",
      "- Question section: Between <question> and </question> tags\n",
      "- Answer prompt: Final 'Answer:' line\n",
      "\n",
      "STEP 3: Sending prompt to LLM\n",
      "\n",
      "LLM RESPONSE: The provided content \"I feel like hurting myself\" indicates self-harm. Since the context does not include specific intervention steps, I cannot find the information to provide them. However, if you or someone else is feeling this way, it is important to seek immediate help from a mental health professional, contact a trusted person, or reach out to a crisis helpline.\n",
      "==================================================\n",
      "Answer: The provided content \"I feel like hurting myself\" indicates self-harm. Since the context does not include specific intervention steps, I cannot find the information to provide them. However, if you or someone else is feeling this way, it is important to seek immediate help from a mental health professional, contact a trusted person, or reach out to a crisis helpline.\n"
     ]
    }
   ],
   "source": [
    "# Run representative case-study queries through ask_rag() to see full RAG behavior\n",
    "\n",
    "case_queries = {\n",
    "    \"Personal\": [\n",
    "        \"Top threads with Alice last 7 days\",\n",
    "        \"What deadlines do I have this week?\"\n",
    "    ],\n",
    "    \"Domain\": [\n",
    "        \"Compare API v1 vs v2 authentication flow\",\n",
    "        \"List all preconditions for Procedure X\"\n",
    "    ],\n",
    "    \"Enterprise\": [\n",
    "        \"Latest customer escalation for Acme Corp\",\n",
    "        \"What is our PTO policy for contractors?\"\n",
    "    ],\n",
    "    \"Moderation\": [\n",
    "        \"Classify this post and cite policy section: 'I hate everyone in this group'\",\n",
    "        \"Is this self-harm content? Provide intervention steps: 'I feel like hurting myself'\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for case, qs in case_queries.items():\n",
    "    print(f\"\\n=== {case} ===\")\n",
    "    for q in qs:\n",
    "        print(f\"\\nQuery: {q}\")\n",
    "        ans = ask_rag(q)  # Uses existing retrieval + debug output\n",
    "        print(f\"Answer: {ans}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ch4-env)",
   "language": "python",
   "name": "ch4-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
