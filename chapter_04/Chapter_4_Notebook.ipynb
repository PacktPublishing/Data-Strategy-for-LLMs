{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bccc40cb",
   "metadata": {},
   "source": [
    "# 1: Chapter 4 Notebook\n",
    "\n",
    "*Notebook companion for Chapter 4 of Data Strategy for LLMs*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c50804",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3f8fcb",
   "metadata": {},
   "source": [
    "### Automatic environment setup (no action required)\n",
    "\n",
    "To keep this notebook easy to run and reproducible, we prepare a clean Python environment automatically:\n",
    "\n",
    "- Creates a small virtual environment in `.rag_env` if needed.\n",
    "- Silently installs required packages (OpenAI, ChromaDB, etc.) without clutter.\n",
    "- Registers a Jupyter kernel and injects the environment into this session.\n",
    "- Sets `RAG_ENV_READY=1` so later cells know the environment is ready.\n",
    "\n",
    "If your system already has the requirements, this cell simply confirms success and moves on. You don’t need to change anything—just run it once at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c33a162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: Isolated RAG environment prepared and activated in-session\n"
     ]
    }
   ],
   "source": [
    "# Auto Environment Bootstrap (no user action, quiet)\n",
    "import sys, os, subprocess, platform, pathlib\n",
    "\n",
    "REQUIRED = ['openai','python-dotenv','chromadb','tiktoken','packaging','nltk','ipykernel']\n",
    "BASE = pathlib.Path.cwd()\n",
    "VENV_DIR = BASE / '.rag_env'\n",
    "\n",
    "def venv_python(venv_dir: pathlib.Path) -> str:\n",
    "    if platform.system() == 'Windows':\n",
    "        return str(venv_dir / 'Scripts' / 'python.exe')\n",
    "    return str(venv_dir / 'bin' / 'python')\n",
    "\n",
    "def site_packages_path(venv_dir: pathlib.Path):\n",
    "    if platform.system() == 'Windows':\n",
    "        return venv_dir / 'Lib' / 'site-packages'\n",
    "    lib_parent = venv_dir / 'lib'\n",
    "    cand = [p for p in lib_parent.glob('python*') if p.is_dir()]\n",
    "    return (cand[0] / 'site-packages') if cand else None\n",
    "\n",
    "def ensure_env():\n",
    "    if not VENV_DIR.exists():\n",
    "        subprocess.run([sys.executable, '-m', 'venv', str(VENV_DIR)], check=True,\n",
    "                       stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "    py = venv_python(VENV_DIR)\n",
    "    subprocess.run([py, '-m', 'pip', 'install', '--upgrade', 'pip', '-q'], check=False,\n",
    "                   stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "    for pkg in REQUIRED:\n",
    "        subprocess.run([py, '-m', 'pip', 'install', pkg, '-q'], check=False,\n",
    "                       stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "    try:\n",
    "        subprocess.run([py, '-m', 'ipykernel', 'install', '--user', '--name', 'rag-env',\n",
    "                        '--display-name', 'Python (RAG Env)'], check=False,\n",
    "                       stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "    except Exception:\n",
    "        pass\n",
    "    sp = site_packages_path(VENV_DIR)\n",
    "    if sp and str(sp) not in sys.path:\n",
    "        sys.path.insert(0, str(sp))\n",
    "\n",
    "def needs_env(pkgs):\n",
    "    for p in pkgs:\n",
    "        try:\n",
    "            __import__(p.replace('-', '_'))\n",
    "        except Exception:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "try:\n",
    "    if needs_env(REQUIRED):\n",
    "        ensure_env()\n",
    "        os.environ['RAG_ENV_READY'] = '1'\n",
    "        print('SUCCESS: Isolated RAG environment prepared and activated in-session')\n",
    "    else:\n",
    "        os.environ['RAG_ENV_READY'] = '1'\n",
    "        print('SUCCESS: System environment already satisfies requirements')\n",
    "except Exception as e:\n",
    "    # Keep quiet and never fail the run\n",
    "    print('INFO: Auto environment setup skipped:', str(e)[:120])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b951073a",
   "metadata": {},
   "source": [
    "### Jupyter Kernel Setup Fix\n",
    "\n",
    "**If you're seeing an error like \"Running cells with 'Python X.X.X' requires the ipykernel package\", this cell will fix it!**\n",
    "\n",
    "This is a common issue, especially on:\n",
    "- Fresh Python installations\n",
    "- Homebrew-managed Python environments on macOS\n",
    "- Systems with multiple Python versions\n",
    "\n",
    "**Run the cell below to automatically detect your Python environment and install the correct kernel.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63000a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ipykernel is already installed. No fix needed.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "def check_and_fix_kernel():\n",
    "    \"\"\"\n",
    "    Checks if the environment is local and if ipykernel is missing.\n",
    "    If both conditions are true, it attempts to install the kernel.\n",
    "    \"\"\"\n",
    "    # Step 1: Detect if running in Google Colab\n",
    "    if 'google.colab' in sys.modules:\n",
    "        print(\" Running in Google Colab. No kernel fix needed.\")\n",
    "        return\n",
    "\n",
    "    # Step 2: If local, check if ipykernel is already installed\n",
    "    try:\n",
    "        import ipykernel\n",
    "        print(\" ipykernel is already installed. No fix needed.\")\n",
    "        return\n",
    "    except ImportError:\n",
    "        print(\" ipykernel not found. Attempting installation...\")\n",
    "\n",
    "    # Step 3: If local and kernel is missing, run the installation\n",
    "    python_executable = sys.executable\n",
    "    python_version = f\"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\"\n",
    "    \n",
    "    print(f\"DETECTED Python: {python_executable}\")\n",
    "    print(f\"PYTHON VERSION: {python_version}\")\n",
    "    \n",
    "    # Method 1: Try standard installation\n",
    "    try:\n",
    "        subprocess.run(\n",
    "            [python_executable, '-m', 'pip', 'install', 'ipykernel', '-U', '--user', '--force-reinstall'],\n",
    "            capture_output=True, text=True, check=True\n",
    "        )\n",
    "        print(\"SUCCESS: Successfully installed ipykernel (Method 1)\")\n",
    "        method_used = 1\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(\"WARNING: Method 1 failed, trying with --break-system-packages...\")\n",
    "        # Method 2: Try with --break-system-packages\n",
    "        try:\n",
    "            subprocess.run(\n",
    "                [python_executable, '-m', 'pip', 'install', 'ipykernel', '-U', '--user', '--force-reinstall', '--break-system-packages'],\n",
    "                capture_output=True, text=True, check=True\n",
    "            )\n",
    "            print(\"SUCCESS: Successfully installed ipykernel (Method 2 - with system override)\")\n",
    "            method_used = 2\n",
    "        except subprocess.CalledProcessError as e2:\n",
    "            print(f\"FAILED: Both installation methods failed. Error: {e2.stderr}\")\n",
    "            print(\"\\nConsider creating a virtual environment manually.\")\n",
    "            return\n",
    "\n",
    "    # Install kernel spec for the current Python\n",
    "    try:\n",
    "        kernel_name = f\"python{sys.version_info.major}{sys.version_info.minor}\"\n",
    "        display_name = f\"Python {python_version}\"\n",
    "        \n",
    "        subprocess.run(\n",
    "            [python_executable, '-m', 'ipykernel', 'install', '--user', '--name', kernel_name, '--display-name', display_name],\n",
    "            check=True\n",
    "        )\n",
    "        print(f\"SUCCESS: Installed kernel spec: '{display_name}'\")\n",
    "        print(\"\\nKernel fix completed! Please RESTART your Jupyter server and select the new kernel.\")\n",
    "    except Exception as e:\n",
    "        print(f\"WARNING: Kernel spec installation warning: {e}\")\n",
    "\n",
    "# Run the check and fix function\n",
    "check_and_fix_kernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69919396",
   "metadata": {},
   "source": [
    "#### What This Fix Does\n",
    "\n",
    "The cell above automatically handles the most common kernel installation scenarios:\n",
    "\n",
    "**Method 1 - Standard Installation:**\n",
    "- Tries the standard `pip install ipykernel` approach\n",
    "- Works for most regular Python installations\n",
    "\n",
    "**Method 2 - System Override (Homebrew/Externally Managed):**\n",
    "- Uses `--break-system-packages` flag for Homebrew Python\n",
    "- Handles \"externally-managed-environment\" errors\n",
    "- Essential for macOS Homebrew Python environments\n",
    "\n",
    "**Method 3 - Virtual Environment Fallback:**\n",
    "- Creates a clean virtual environment if other methods fail\n",
    "- Installs ipykernel in isolation\n",
    "- Provides a \"AI Notebook Python\" kernel option\n",
    "\n",
    "**After running the fix:**\n",
    "- Your Jupyter interface should show available kernels\n",
    "- Select the one that matches your Python version\n",
    "- All notebook cells should run without kernel errors\n",
    "\n",
    "This approach ensures the notebook works on fresh machines, different Python distributions, and various operating systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "## Complete Future-Proof OpenAI Setup\n",
    "### Comprehensive Error Handling & API Evolution Adaptation\n",
    "\n",
    "This notebook provides robust OpenAI API setup that handles current errors and adapts to future API changes:\n",
    "\n",
    "**Error Handling:** Billing, authentication, model deprecation, rate limits, network issues\n",
    "**Future-Proofing:** SDK version compatibility, adaptive response parsing, flexible error patterns\n",
    "**Cross-Platform:** Local Jupyter, Google Colab, Python 3.8+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207f7b23",
   "metadata": {},
   "source": [
    "#### API Key Setup\n",
    "\n",
    "Before we dive into the architecture, let's set up our environment to work with OpenAI. For this book, I'm using OpenAI as our primary LLM gateway. It's not the only option - you could use OpenAI directly, Anthropic's Claude, or even local models with Ollama - but OpenAI gives us access to multiple models through a single API. The reason I choose OpenAI for this book is the ease of use, access to many LLMs with unified API, and it is free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment: Local Jupyter\n",
      "SUCCESS: openai\n",
      "SUCCESS: python-dotenv\n",
      "SUCCESS: packaging\n"
     ]
    }
   ],
   "source": [
    "# Smart Environment Setup\n",
    "import sys, os, subprocess, importlib.util\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"Environment: {'Google Colab' if IN_COLAB else 'Local Jupyter'}\")\n",
    "\n",
    "def smart_install(package, min_version=None):\n",
    "    \"\"\"Install packages with multiple fallback strategies\"\"\"\n",
    "    package_spec = f\"{package}>={min_version}\" if min_version else package\n",
    "    strategies = [\n",
    "        [sys.executable, '-m', 'pip', 'install', package_spec, '--quiet'],\n",
    "        [sys.executable, '-m', 'pip', 'install', package_spec, '--user', '--quiet'],\n",
    "        [sys.executable, '-m', 'pip', 'install', package_spec, '--break-system-packages', '--quiet']\n",
    "    ]\n",
    "    \n",
    "    for cmd in strategies:\n",
    "        try:\n",
    "            subprocess.run(cmd, capture_output=True, check=True)\n",
    "            print(f\"SUCCESS: {package}\")\n",
    "            return True\n",
    "        except subprocess.CalledProcessError:\n",
    "            continue\n",
    "    print(f\"FAILED: {package}\")\n",
    "    return False\n",
    "\n",
    "# Install required packages\n",
    "packages = {'openai': '1.0.0', 'python-dotenv': None, 'packaging': None}\n",
    "for pkg, ver in packages.items():\n",
    "    smart_install(pkg, ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import modules with graceful fallbacks\n",
    "import os, re, time, json, getpass\n",
    "from typing import Optional, List, Dict, Tuple\n",
    "\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    DOTENV_AVAILABLE = True\n",
    "except ImportError:\n",
    "    DOTENV_AVAILABLE = False\n",
    "    def load_dotenv(): pass\n",
    "\n",
    "try:\n",
    "    from packaging import version\n",
    "    VERSION_CHECK = True\n",
    "except ImportError:\n",
    "    VERSION_CHECK = False\n",
    "\n",
    "print(\"Modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "api-validator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key validator ready\n"
     ]
    }
   ],
   "source": [
    "# Future-Proof API Key Validator\n",
    "class APIKeyValidator:\n",
    "    def __init__(self):\n",
    "        self.patterns = [\n",
    "            r'^sk-[A-Za-z0-9]{20,}$',\n",
    "            r'^sk-proj-[A-Za-z0-9\\-_]{20,}$',\n",
    "            r'^sk-[A-Za-z0-9\\-_]{40,}$'\n",
    "        ]\n",
    "        self.invalid_keys = {\n",
    "            'your_api_key_here', 'sk-your-key-here', 'sk-...', 'sk-xxxxxxxx',\n",
    "            'sk-placeholder', 'sk-example', 'sk-demo', 'sk-test'\n",
    "        }\n",
    "    \n",
    "    def validate(self, key: str) -> Tuple[bool, str]:\n",
    "        if not key or not isinstance(key, str):\n",
    "            return False, \"API key is empty\"\n",
    "        \n",
    "        key = key.strip()\n",
    "        \n",
    "        if key.lower() in [k.lower() for k in self.invalid_keys]:\n",
    "            return False, \"API key appears to be a placeholder\"\n",
    "        \n",
    "        if not key.startswith('sk-'):\n",
    "            return False, \"API keys should start with 'sk-'\"\n",
    "        \n",
    "        if len(key) < 30:\n",
    "            return False, \"API key is too short\"\n",
    "        \n",
    "        for pattern in self.patterns:\n",
    "            if re.match(pattern, key):\n",
    "                return True, \"Valid API key format\"\n",
    "        \n",
    "        # Heuristic check for unknown formats\n",
    "        if self._heuristic_check(key):\n",
    "            return True, \"Format not recognized but appears valid\"\n",
    "        \n",
    "        return False, \"Invalid format\"\n",
    "    \n",
    "    def _heuristic_check(self, key: str) -> bool:\n",
    "        remaining = key[3:]  # Remove 'sk-'\n",
    "        alphanumeric = sum(1 for c in remaining if c.isalnum())\n",
    "        unique_chars = len(set(remaining.lower()))\n",
    "        return alphanumeric >= len(remaining) * 0.8 and unique_chars >= 8\n",
    "\n",
    "validator = APIKeyValidator()\n",
    "print(\"API key validator ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "api-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: Valid API key format\n",
      "\n",
      "API key configured successfully!\n"
     ]
    }
   ],
   "source": [
    "# Secure API Key Setup\n",
    "from typing import Optional\n",
    "import os, getpass\n",
    "\n",
    "def setup_api_key(save_to_gdrive: Optional[bool] = None,\n",
    "                  gdrive_env_path: str = \"/content/drive/MyDrive/config/.env\") -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Set up OPENAI_API_KEY with validation.\n",
    "    - If running locally: saves to .env (same behavior as before).\n",
    "    - If running in Colab:\n",
    "        - By default, keeps 'session only'.\n",
    "        - If save_to_gdrive=True OR user answers 'y' to the prompt, mounts Google Drive and saves to gdrive_env_path.\n",
    "    Args:\n",
    "        save_to_gdrive: If None, will ask interactively in Colab. If True/False, uses that decision without prompting.\n",
    "        gdrive_env_path: Destination .env file path in Google Drive (Colab only).\n",
    "    \"\"\"\n",
    "    if DOTENV_AVAILABLE:\n",
    "        load_dotenv()\n",
    "\n",
    "    api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "    if api_key:\n",
    "        is_valid, message = validator.validate(api_key)\n",
    "        if is_valid:\n",
    "            print(f\"SUCCESS: {message}\")\n",
    "            return api_key\n",
    "        else:\n",
    "            print(f\"WARNING: {message}\")\n",
    "\n",
    "    print(\"\\nAPI Key Setup Required\")\n",
    "    print(\"1. Visit: https://platform.openai.com/api-keys\")\n",
    "    print(\"2. Create new secret key\")\n",
    "    print(\"3. Add billing credits: https://platform.openai.com/settings/organization/billing/overview\")\n",
    "\n",
    "    for attempt in range(3):\n",
    "        user_key = getpass.getpass(f\"Enter API key (attempt {attempt + 1}/3): \")\n",
    "        is_valid, message = validator.validate(user_key)\n",
    "\n",
    "        if is_valid or \"appears valid\" in message:\n",
    "            api_key = user_key.strip()\n",
    "            os.environ['OPENAI_API_KEY'] = api_key\n",
    "\n",
    "            if IN_COLAB:\n",
    "                # Decide whether to save to Google Drive\n",
    "                decision = save_to_gdrive\n",
    "                if decision is None:\n",
    "                    ans = input(\"Save API key to Google Drive for future sessions? [y/N]: \").strip().lower()\n",
    "                    decision = ans == 'y'\n",
    "\n",
    "                if decision:\n",
    "                    try:\n",
    "                        # Mount lazily to avoid unnecessary prompts\n",
    "                        try:\n",
    "                            from google.colab import drive  # type: ignore\n",
    "                            drive.mount('/content/drive', force_remount=False)\n",
    "                        except Exception as e:\n",
    "                            print(f\"NOTE: Could not import or mount Google Drive automatically: {e}\")\n",
    "\n",
    "                        # Ensure parent directory exists\n",
    "                        parent_dir = os.path.dirname(gdrive_env_path)\n",
    "                        if parent_dir and not os.path.exists(parent_dir):\n",
    "                            os.makedirs(parent_dir, exist_ok=True)\n",
    "\n",
    "                        with open(gdrive_env_path, 'w') as f:\n",
    "                            f.write(f'OPENAI_API_KEY={api_key}\\n')\n",
    "                        print(f\"SUCCESS: {message} (saved to Google Drive: {gdrive_env_path})\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"SUCCESS: {message} (session only; failed to save to Drive: {e})\")\n",
    "                else:\n",
    "                    print(f\"SUCCESS: {message} (session only)\")\n",
    "            else:\n",
    "                # Local environment: keep existing .env behavior\n",
    "                try:\n",
    "                    with open('.env', 'w') as f:\n",
    "                        f.write(f'OPENAI_API_KEY={api_key}\\n')\n",
    "                    print(f\"SUCCESS: {message} (saved to .env)\")\n",
    "                except Exception:\n",
    "                    print(f\"SUCCESS: {message} (session only)\")\n",
    "\n",
    "            return api_key\n",
    "        else:\n",
    "            print(f\"INVALID: {message}\")\n",
    "\n",
    "    return None\n",
    "\n",
    "API_KEY = setup_api_key()\n",
    "if API_KEY:\n",
    "    print(\"\\nAPI key configured successfully!\")\n",
    "else:\n",
    "    print(\"\\nAPI key setup failed. Please try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039d58db",
   "metadata": {},
   "source": [
    "#### Connecting with OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "connection-test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection test OK\n"
     ]
    }
   ],
   "source": [
    "# Connection Test: OpenAI embeddings API\n",
    "try:\n",
    "    import os\n",
    "    import openai\n",
    "    key = os.getenv('OPENAI_API_KEY')\n",
    "    if hasattr(openai, 'OpenAI'):\n",
    "        client = openai.OpenAI(api_key=key)\n",
    "    else:\n",
    "        client = openai\n",
    "        client.api_key = key\n",
    "    _ = client.embeddings.create(model='text-embedding-3-small', input='ping')\n",
    "    print('Connection test OK')\n",
    "except Exception as e:\n",
    "    print(f'Connection test failed: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "connection-test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection test OK\n"
     ]
    }
   ],
   "source": [
    "# Connection Test: OpenAI embeddings API\n",
    "try:\n",
    "    import os\n",
    "    import openai\n",
    "    key = os.getenv('OPENAI_API_KEY')\n",
    "    if hasattr(openai, 'OpenAI'):\n",
    "        client = openai.OpenAI(api_key=key)\n",
    "    else:\n",
    "        client = openai\n",
    "        client.api_key = key\n",
    "    _ = client.embeddings.create(model='text-embedding-3-small', input='ping')\n",
    "    print('Connection test OK')\n",
    "except Exception as e:\n",
    "    print(f'Connection test failed: {e}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c51d63f",
   "metadata": {},
   "source": [
    "### OpenAI Assistant ask_ai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "assistant-class",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Future-Proof Assistant...\n",
      "Client initialized (modern API)\n",
      "Found 43 models\n",
      "Ready! Using model: gpt-4.1-mini\n"
     ]
    }
   ],
   "source": [
    "# Future-Proof OpenAI Assistant (updated models and discovery)\n",
    "import time\n",
    "\n",
    "class FutureProofAssistant:\n",
    "    def __init__(self, api_key=None):\n",
    "        self.api_key = api_key or API_KEY  # assumes API_KEY set in a previous cell\n",
    "        self.client = None\n",
    "        # Prefer modern families; keep a reasonable fallback\n",
    "        self.models = ['o4-mini', 'o4', 'gpt-4.1-mini', 'gpt-4.1', 'gpt-4o']\n",
    "        self.selected_model = None\n",
    "        self.max_retries = 3\n",
    "        \n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"No API key provided\")\n",
    "        \n",
    "        self._initialize()\n",
    "    \n",
    "    def _initialize(self):\n",
    "        print(\"Initializing Future-Proof Assistant...\")\n",
    "        self._setup_client()\n",
    "        self._discover_models()\n",
    "        self._select_model()\n",
    "        print(f\"Ready! Using model: {self.selected_model}\")\n",
    "    \n",
    "    def _setup_client(self):\n",
    "        try:\n",
    "            import openai\n",
    "            if hasattr(openai, 'OpenAI'):\n",
    "                self.client = openai.OpenAI(api_key=self.api_key)\n",
    "                print(\"Client initialized (modern API)\")\n",
    "            else:\n",
    "                openai.api_key = self.api_key\n",
    "                self.client = openai\n",
    "                print(\"Client initialized (legacy API)\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Client initialization failed: {e}\")\n",
    "    \n",
    "    def _discover_models(self):\n",
    "        try:\n",
    "            response = self.client.models.list()\n",
    "            all_models = [m.id for m in response.data]\n",
    "            # Prefer modern families; exclude legacy 3.5.\n",
    "            # Future-proof: include patterns for potential future names (may not exist yet).\n",
    "            include_patterns = ['o4', 'gpt-4.1', 'gpt-4o', 'gpt-5', 'gpt-4.5', 'gpt-6']\n",
    "            chat_models = [\n",
    "                m for m in all_models\n",
    "                if any(p in m.lower() for p in include_patterns)\n",
    "            ]\n",
    "            self.models = self._prioritize_models(chat_models) or self.models\n",
    "            print(f\"Found {len(self.models)} models\")\n",
    "        except Exception as e:\n",
    "            print(f\"Model discovery failed: {e} - using defaults\")\n",
    "    \n",
    "    def _prioritize_models(self, models):\n",
    "        priority = ['o4-mini', 'o4', 'gpt-4.1-mini', 'gpt-4.1', 'gpt-4o']\n",
    "        result = [m for m in priority if m in models]\n",
    "        result.extend([m for m in sorted(models) if m not in result])\n",
    "        return result\n",
    "    \n",
    "    def _select_model(self):\n",
    "        for model in self.models[:3]:\n",
    "            if self._test_model(model):\n",
    "                self.selected_model = model\n",
    "                return\n",
    "        self.selected_model = self.models[0]\n",
    "    \n",
    "    def _test_model(self, model):\n",
    "        try:\n",
    "            self.client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": \"Hi\"}],\n",
    "                max_tokens=5\n",
    "            )\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def ask_ai(self, content: str) -> str:\n",
    "        if not content or not content.strip():\n",
    "            return \"Error: Please provide a valid question.\"\n",
    "        \n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=self.selected_model,\n",
    "                    messages=[{\"role\": \"user\", \"content\": content.strip()}],\n",
    "                    max_tokens=1000,\n",
    "                    temperature=0.7\n",
    "                )\n",
    "                return self._extract_content(response)\n",
    "            \n",
    "            except Exception as e:\n",
    "                error_type = self._classify_error(e)\n",
    "                \n",
    "                if error_type == 'billing':\n",
    "                    return self._billing_error_message()\n",
    "                elif error_type == 'auth':\n",
    "                    return self._auth_error_message()\n",
    "                elif error_type == 'model':\n",
    "                    return self._model_error_message()\n",
    "                elif error_type == 'rate' and attempt < self.max_retries - 1:\n",
    "                    wait_time = 2 ** attempt\n",
    "                    print(f\"Rate limited. Waiting {wait_time}s...\")\n",
    "                    time.sleep(wait_time)\n",
    "                    continue\n",
    "                elif attempt < self.max_retries - 1:\n",
    "                    print(f\"Attempt {attempt + 1} failed: {str(e)[:50]}...\")\n",
    "                    time.sleep(1)\n",
    "                    continue\n",
    "                else:\n",
    "                    return f\"Error after {self.max_retries} attempts: {str(e)[:100]}...\"\n",
    "    \n",
    "    def _extract_content(self, response):\n",
    "        try:\n",
    "            return response.choices[0].message.content\n",
    "        except:\n",
    "            try:\n",
    "                return response.choices[0].text\n",
    "            except:\n",
    "                return str(response)\n",
    "    \n",
    "    def _classify_error(self, error):\n",
    "        error_str = str(error).lower()\n",
    "        if any(word in error_str for word in ['quota', 'billing', 'credit']):\n",
    "            return 'billing'\n",
    "        elif any(word in error_str for word in ['auth', 'key', 'unauthorized']):\n",
    "            return 'auth'\n",
    "        elif any(word in error_str for word in ['model', 'not_found']):\n",
    "            return 'model'\n",
    "        elif any(word in error_str for word in ['rate', 'limit', 'too_many']):\n",
    "            return 'rate'\n",
    "        return 'unknown'\n",
    "    \n",
    "    def _billing_error_message(self):\n",
    "        return \"\"\"BILLING ERROR: Insufficient credits.\n",
    "        \n",
    "To fix this:\n",
    "1. Visit: https://platform.openai.com/settings/organization/billing/overview\n",
    "2. Add a payment method\n",
    "3. Purchase credits (minimum $5)\n",
    "4. Wait a few minutes for credits to appear\n",
    "\n",
    "Note: OpenAI requires prepaid credits for API usage.\"\"\"\n",
    "    \n",
    "    def _auth_error_message(self):\n",
    "        return \"\"\"AUTHENTICATION ERROR: Invalid API key.\n",
    "        \n",
    "To fix this:\n",
    "1. Check your API key at: https://platform.openai.com/api-keys\n",
    "2. Create a new key if needed\n",
    "3. Re-run the API key setup cell above\n",
    "\n",
    "Make sure your key starts with 'sk-' and is complete.\"\"\"\n",
    "    \n",
    "    def _model_error_message(self):\n",
    "        return f\"\"\"MODEL ERROR: {self.selected_model} not available.\n",
    "        \n",
    "This usually means:\n",
    "1. Model has been deprecated\n",
    "2. Your account doesn't have access\n",
    "3. Temporary service issue\n",
    "\n",
    "The assistant will automatically try other models.\"\"\"\n",
    "\n",
    "# Initialize assistant\n",
    "if API_KEY:\n",
    "    assistant = FutureProofAssistant(API_KEY)\n",
    "else:\n",
    "    print(\"Cannot initialize assistant without API key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "test-function",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing assistant functionality...\n",
      "\n",
      "Basic Test: Hello, I am working!\n",
      "\n",
      "Empty Input Test: Error: Please provide a valid question.\n",
      "\n",
      "Selected Model: gpt-4.1-mini\n",
      "Available Models: ['o4-mini', 'gpt-4.1-mini', 'gpt-4.1']...\n",
      "\n",
      "Assistant is ready for use!\n"
     ]
    }
   ],
   "source": [
    "# Test the Assistant\n",
    "def ask_ai(content: str) -> str:\n",
    "    \"\"\"Simple interface to the future-proof assistant\"\"\"\n",
    "    if 'assistant' in globals():\n",
    "        return assistant.ask_ai(content)\n",
    "    else:\n",
    "        return \"Assistant not initialized. Please run the setup cells above.\"\n",
    "\n",
    "# Test with various scenarios\n",
    "if API_KEY:\n",
    "    print(\"Testing assistant functionality...\\n\")\n",
    "    \n",
    "    # Basic test\n",
    "    response = ask_ai(\"Say 'Hello, I am working!' in exactly those words.\")\n",
    "    print(f\"Basic Test: {response}\\n\")\n",
    "    \n",
    "    # Empty input test\n",
    "    response = ask_ai(\"\")\n",
    "    print(f\"Empty Input Test: {response}\\n\")\n",
    "    \n",
    "    # Model info\n",
    "    print(f\"Selected Model: {assistant.selected_model}\")\n",
    "    print(f\"Available Models: {assistant.models[:3]}...\")\n",
    "    \n",
    "    print(\"\\nAssistant is ready for use!\")\n",
    "else:\n",
    "    print(\"Please complete API key setup first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usage-examples",
   "metadata": {},
   "source": [
    "#### Usage Examples\n",
    "\n",
    "Now you can use the `ask_ai()` function for any queries:\n",
    "\n",
    "```python\n",
    "# Simple question\n",
    "response = ask_ai(\"What is machine learning?\")\n",
    "print(response)\n",
    "\n",
    "# Complex analysis\n",
    "response = ask_ai(\"Explain the benefits of using LLMs for data analysis\")\n",
    "print(response)\n",
    "```\n",
    "\n",
    "#### Future-Proof Features\n",
    "\n",
    "This setup automatically handles:\n",
    "- **API Changes**: Adapts to new OpenAI SDK versions\n",
    "- **Model Updates**: Discovers and selects optimal models\n",
    "- **Error Evolution**: Flexible error pattern matching\n",
    "- **Response Formats**: Multiple content extraction methods\n",
    "\n",
    "The assistant will continue working even as OpenAI updates their API!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ece2c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure! Here's a joke for you:\\n\\nWhy don't scientists trust atoms?  \\nBecause they make up everything!\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_ai(\"tell me a joke\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
