{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3a45970",
   "metadata": {},
   "source": [
    "# How to Run (Chapter 5 Setup)\n",
    "\n",
    "Follow these steps before running any cells:\n",
    "\n",
    "- macOS/Linux\n",
    "  1) Open Terminal\n",
    "  2) cd to this repository root (27July2025)\n",
    "  3) Run: `bash chapter5/setup/setup.sh`\n",
    "  4) Activate: `source .venv-ch5/bin/activate`\n",
    "\n",
    "- Windows (PowerShell)\n",
    "  1) Open PowerShell\n",
    "  2) cd to this repository root (27July2025)\n",
    "  3) Run: `powershell -ExecutionPolicy Bypass -File chapter5/setup/setup.ps1`\n",
    "  4) Activate: `.\\.venv-ch5\\Scripts\\Activate.ps1`\n",
    "\n",
    "- Google Colab\n",
    "  1) Just run the first code cell. It detects Colab and mounts Google Drive\n",
    "  2) Paths are set under: `/content/drive/MyDrive/data-strategy-book/27July2025/`\n",
    "  3) No virtual environment needed in Colab; dependencies install via pip cells as needed\n",
    "\n",
    "Environment selection:\n",
    "- Local notebooks should be run inside `.venv-ch5` for Chapter 5\n",
    "- `.env` is loaded from `chapter5/setup/.env` if present; copy `.env.example` and fill keys as needed\n",
    "\n",
    "After setup, proceed with the Colab/path cell to confirm DB/DATA/TRACE locations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ba58b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reranker providers (commented): enable one, add API key in chapter5/setup/.env, and set cfg['enable_rerank']=True\n",
    "\n",
    "# --- Cohere (hosted cross-encoder) ---\n",
    "# import os\n",
    "# import cohere\n",
    "# COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n",
    "# co = cohere.Client(COHERE_API_KEY) if COHERE_API_KEY else None\n",
    "# def cohere_rerank(query: str, docs: list[str], top_n: int = 5):\n",
    "#     if not co:\n",
    "#         print(\"[rerank] COHERE_API_KEY missing; skipping\")\n",
    "#         return docs[:top_n]\n",
    "#     resp = co.rerank(query=query, documents=docs, top_n=top_n, model=\"rerank-english-v3.0\")\n",
    "#     # Return documents ordered by relevance\n",
    "#     return [docs[r.index] for r in resp.results]\n",
    "\n",
    "# --- Voyage (hosted cross-encoder) ---\n",
    "# import os\n",
    "# import voyageai as vo\n",
    "# VOYAGE_API_KEY = os.getenv(\"VOYAGE_API_KEY\")\n",
    "# vc = vo.Client(api_key=VOYAGE_API_KEY) if VOYAGE_API_KEY else None\n",
    "# def voyage_rerank(query: str, docs: list[str], top_n: int = 5):\n",
    "#     if not vc:\n",
    "#         print(\"[rerank] VOYAGE_API_KEY missing; skipping\")\n",
    "#         return docs[:top_n]\n",
    "#     res = vc.rerank(query=query, documents=docs, model=\"rerank-2-lite\", top_k=top_n)\n",
    "#     # Voyage returns indices sorted by score desc\n",
    "#     return [docs[i] for i in res.indices]\n",
    "\n",
    "# --- Local (open-source; slower on CPU) ---\n",
    "# from rerankers import Reranker\n",
    "# _local_rr = Reranker(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "# def local_rerank(query: str, docs: list[str], top_n: int = 5):\n",
    "#     ranked = _local_rr.rank(query, docs)  # returns list[(doc, score)]\n",
    "#     return [d for d, _ in ranked[:top_n]]\n",
    "\n",
    "# Integration suggestion in demo cell:\n",
    "# if cfg['enable_rerank']:\n",
    "#     docs = [h['text'] for h in raw_hits]\n",
    "#     # choose one provider\n",
    "#     # docs = cohere_rerank(q, docs, cfg['rerank_k'])\n",
    "#     # docs = voyage_rerank(q, docs, cfg['rerank_k'])\n",
    "#     # docs = local_rerank(q, docs, cfg['rerank_k'])\n",
    "#     # Map docs back to hits by text or add IDs to avoid ambiguity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4faa10",
   "metadata": {},
   "source": [
    "# Advanced RAG Techniques — Companion Notebook\n",
    "\n",
    "This notebook accompanies Chapter 5. It layers advanced capabilities on top of Chapter 4 without changing chunking/embeddings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0047a8",
   "metadata": {},
   "source": [
    "# How to Run (Chapter 5 Setup)\n",
    "\n",
    "This notebook builds on Chapter 4. Run these steps before executing cells.\n",
    "\n",
    "- macOS/Linux\n",
    "  1) Open Terminal\n",
    "  2) cd to repo root: data-strategy-book/27July2025\n",
    "  3) Run setup: bash chapter5/setup/setup.sh\n",
    "  4) Activate env: source .venv-ch5/bin/activate\n",
    "  5) Start Jupyter: jupyter lab (or jupyter notebook)\n",
    "  6) Select the Python kernel that points to .venv-ch5 if prompted\n",
    "\n",
    "- Windows (PowerShell)\n",
    "  1) Open PowerShell\n",
    "  2) cd to repo root: data-strategy-book/27July2025\n",
    "  3) Run setup: powershell -ExecutionPolicy Bypass -File chapter5/setup/setup.ps1\n",
    "  4) Activate env: .\\.venv-ch5\\Scripts\\Activate.ps1\n",
    "  5) Start Jupyter: jupyter lab (or jupyter notebook)\n",
    "  6) Select the Python kernel that points to .venv-ch5 if prompted\n",
    "\n",
    "- Google Colab\n",
    "  1) Just run the first code cell; it detects Colab and mounts Google Drive\n",
    "  2) Paths are set to /content/drive/MyDrive/data-strategy-book/27July2025/\n",
    "  3) No virtualenv needed; pip installs happen inline as required\n",
    "\n",
    "Environment selection and keys\n",
    "- Local runs should use the .venv-ch5 environment for Chapter 5\n",
    "- Copy chapter5/setup/.env.example to chapter5/setup/.env and fill keys if needed\n",
    "- You can verify setup by running: python chapter5/setup/validate_setup.py\n",
    "\n",
    "Paths used by this notebook\n",
    "- DB: ch5_db (under repo root or in Drive on Colab)\n",
    "- Traces: chapter5/traces/advanced_rag.jsonl\n",
    "- Data: chapter5/data/\n",
    "\n",
    "After setup, proceed with the “Colab detection and Drive mount + path selection” cell to confirm DB/DATA/TRACE locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dfd324f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths:\n",
      " BASE  = /Users/relhousieny/code/personal/books/data-strategy-book\n",
      " DB    = /Users/relhousieny/code/personal/books/data-strategy-book/ch5_db\n",
      " TRACES= /Users/relhousieny/code/personal/books/data-strategy-book/chapter5/traces/advanced_rag.jsonl\n",
      " DATA  = /Users/relhousieny/code/personal/books/data-strategy-book/chapter5/data\n"
     ]
    }
   ],
   "source": [
    "# Colab detection and Drive mount + path selection\n",
    "from pathlib import Path\n",
    "def in_colab():\n",
    "    try:\n",
    "        import google.colab  # type: ignore\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "if in_colab():\n",
    "    from google.colab import drive  # type: ignore\n",
    "    drive.mount('/content/drive', force_remount=False)\n",
    "    BASE = '/content/drive/MyDrive/data-strategy-book/27July2025'\n",
    "else:\n",
    "    BASE = str(Path.cwd().parents[2])  # repo root heuristic\n",
    "\n",
    "DB_PATH = str(Path(BASE) / 'ch5_db')\n",
    "TRACES_PATH = str(Path(BASE) / 'chapter5' / 'traces' / 'advanced_rag.jsonl')\n",
    "DATA_PATH = str(Path(BASE) / 'chapter5' / 'data')\n",
    "print('Paths:')\n",
    "print(' BASE  =', BASE)\n",
    "print(' DB    =', DB_PATH)\n",
    "print(' TRACES=', TRACES_PATH)\n",
    "print(' DATA  =', DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50b49c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded .env (if present)\n"
     ]
    }
   ],
   "source": [
    "# Kernel fix + silent installs + env load (aligned with Ch1/Ch4 style)\n",
    "import sys, subprocess, os\n",
    "def pip_install(pkg):\n",
    "    try:\n",
    "        subprocess.run([sys.executable, '-m', 'pip', 'install', pkg, '-q'], check=True)\n",
    "    except Exception as e:\n",
    "        print('Install failed:', pkg, e)\n",
    "\n",
    "# Minimal deps expected for this notebook; setup scripts already pin versions\n",
    "for p in ['python-dotenv']:\n",
    "    pip_install(p)\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "env_guess = Path.cwd().parents[2] / 'chapter5' / 'setup' / '.env'\n",
    "if env_guess.exists():\n",
    "    load_dotenv(env_guess)\n",
    "else:\n",
    "    load_dotenv()\n",
    "print('Loaded .env (if present)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73146829",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'chapter5'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Local modules\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchapter5\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcode\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mretrieval\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01madvanced\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      8\u001b[39m     Hit, retrieve, blend_hybrid_scores, apply_rerank, self_query_extract, multi_query_expand,\n\u001b[32m      9\u001b[39m     route, apply_recency_boost, assemble_context\n\u001b[32m     10\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchapter5\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcode\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magents\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01miterative\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m agent_loop\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchapter5\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcode\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprofiles\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build_prompt\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'chapter5'"
     ]
    }
   ],
   "source": [
    "# Imports + config toggles\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Local modules\n",
    "from chapter5.code.retrieval.advanced import (\n",
    "    Hit, retrieve, blend_hybrid_scores, apply_rerank, self_query_extract, multi_query_expand,\n",
    "    route, apply_recency_boost, assemble_context\n",
    ")\n",
    "from chapter5.code.agents.iterative import agent_loop\n",
    "from chapter5.code.prompts.profiles import build_prompt\n",
    "from chapter5.code.safety.filters import pre_filters, post_validators\n",
    "from chapter5.code.observability.trace import TraceRecord, write_trace_jsonl, now_ms\n",
    "from chapter5.code.multimodal.pdf_utils import extract_captions_near_match\n",
    "\n",
    "# Feature toggles\n",
    "cfg = {\n",
    "  'enable_hybrid': True,\n",
    "  'enable_rerank': False,\n",
    "  'rerank_model': 'stub',\n",
    "  'rerank_k': 5,\n",
    "  'enable_multi_query': False,\n",
    "  'enable_self_query': False,\n",
    "  'route_policy': 'auto',\n",
    "  'recency_boost': True,\n",
    "  'prompt_profile': 'grounded_baseline',\n",
    "  'safety_pre': True,\n",
    "  'safety_post': True,\n",
    "  'trace_enabled': True,\n",
    "}\n",
    "cfg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2689164",
   "metadata": {},
   "source": [
    "> Rerank note: To enable reranking, set `cfg['enable_rerank']=True`, fill `.env` keys (COHERE_API_KEY or VOYAGE_API_KEY) in `chapter5/setup/.env`,\n",
    "    and uncomment one provider in the \"Reranker providers\" cell above (Cohere, Voyage, or Local)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d744efa8",
   "metadata": {},
   "source": [
    "### Getting a reranker API key (quick)\n",
    "\n",
    "- **Cohere Rerank**: Create an account → get API key at https://dashboard.cohere.com/api-keys → set `COHERE_API_KEY` in `chapter5/setup/.env`.\n",
    "- **VoyageAI Rerank**: Sign up → get key at https://dashboard.voyageai.com/ → set `VOYAGE_API_KEY` in `.env`.\n",
    "- **Jina AI Rerankers**: Create key at https://cloud.jina.ai/ (if using Jina’s hosted rerankers) → set provider-specific key in `.env`.\n",
    "\n",
    "> Tip: Restart kernel after editing `.env` so the notebook picks up the new key.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96dbb7a",
   "metadata": {},
   "source": [
    "## Connect to Chroma (reuse or create Chapter 5 DB)\n",
    "We will use a local persistent DB. If Chapter 4's DB exists, you can also point to it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51797a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "client = chromadb.PersistentClient(path=DB_PATH)\n",
    "COLL = 'chapter5_demo'\n",
    "try:\n",
    "    collection = client.get_collection(COLL)\n",
    "except Exception:\n",
    "    collection = client.create_collection(name=COLL, metadata={'hnsw:space': 'cosine'})\n",
    "print('Collection:', collection.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdf1761",
   "metadata": {},
   "source": [
    "## Data: tiny samples (personal, enterprise, policies)\n",
    "We add a few records with primitive metadata to keep demos fast and meaningful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792988c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import uuid, time\n",
    "\n",
    "def read_text(p):\n",
    "    try:\n",
    "        return Path(p).read_text(encoding='utf-8')\n",
    "    except Exception:\n",
    "        return ''\n",
    "\n",
    "docs = []\n",
    "base = Path(DATA_PATH)\n",
    "samples = [\n",
    "    base/'personal'/'note1.md',\n",
    "    base/'personal'/'note2.md',\n",
    "    base/'enterprise'/'policy_hr.md',\n",
    "    base/'policies'/'policy_hate.md',\n",
    "]\n",
    "now_iso = datetime.utcnow().isoformat()\n",
    "for sp in samples:\n",
    "    if sp.exists():\n",
    "        docs.append({\n",
    "            'id': sp.stem + '_' + str(uuid.uuid4())[:8],\n",
    "            'text': read_text(sp),\n",
    "            'metadata': {\n",
    "                'source': sp.parent.name,\n",
    "                'doc_type': sp.suffix.replace('.', '') or 'txt',\n",
    "                'created_at': now_iso,\n",
    "                'path': str(sp)\n",
    "            }\n",
    "        })\n",
    "\n",
    "if docs:\n",
    "    collection.add(\n",
    "        ids=[d['id'] for d in docs],\n",
    "        documents=[d['text'] for d in docs],\n",
    "        metadatas=[d['metadata'] for d in docs],\n",
    "    )\n",
    "print('Seeded docs:', len(docs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7b6f82",
   "metadata": {},
   "source": [
    "## Advanced Retrieval demos (hybrid/rerank/routing/multi/self-query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bc510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval wiring to Chroma for this notebook\n",
    "def chroma_search(query: str, n: int = 5):\n",
    "    res = collection.query(query_texts=[query], n_results=n, include=['metadatas', 'documents', 'distances'])\n",
    "    hits = []\n",
    "    for i, doc in enumerate(res.get('documents', [[]])[0]):\n",
    "        md = res['metadatas'][0][i] if res.get('metadatas') else {}\n",
    "        score = 1.0 / (1.0 + res['distances'][0][i]) if res.get('distances') else 0.0\n",
    "        hits.append({'id': md.get('path', f'doc_{i}'), 'text': doc, 'metadata': md, 'score': score})\n",
    "    return hits\n",
    "\n",
    "q = 'When is the follow-up and who attends?'\n",
    "raw_hits = chroma_search(q, n=8)\n",
    "print('Top raw hits:', len(raw_hits))\n",
    "\n",
    "# Hybrid/rerank/multi/self-query stubs (using local functions)\n",
    "diag = {'routed': 'auto'}\n",
    "if cfg['enable_rerank']:\n",
    "    raw_hits = apply_rerank([\n",
    "        __import__('types').SimpleNamespace(**h) for h in raw_hits\n",
    "    ], cfg['rerank_model'], cfg['rerank_k'])\n",
    "print('Diagnostics:', diag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a48aa8",
   "metadata": {},
   "source": [
    "## Iterative / Agentic loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d459f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retriever_for_agent(sub_q: str):\n",
    "    return {'hits': chroma_search(sub_q, n=5), 'diagnostics': {'routed': 'auto'}}\n",
    "out = agent_loop('Summarize meeting action items with attendees', max_hops=2, options={'retriever': retriever_for_agent})\n",
    "out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469cd2c2",
   "metadata": {},
   "source": [
    "## Multi-source / ACL-aware retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d354e78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = chroma_search('PTO policy for contractors', n=5)\n",
    "ctx = assemble_context([__import__('types').SimpleNamespace(**h) for h in hits], max_chars=800, source_filters={'source': 'enterprise'})\n",
    "print(ctx[:400])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d820fa79",
   "metadata": {},
   "source": [
    "## Pragmatic multi-modal (figure/caption)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c58e136",
   "metadata": {},
   "source": [
    "> PDF demo: Setup auto-created `chapter5/data/pdfs/sample_report_with_figure.pdf`. The cell below will look for a PDF under `chapter5/data/pdfs/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655255b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a PDF sample exists under chapter5/data/pdfs, extract nearby snippets for a keyword\n",
    "pdf_dir = Path(DATA_PATH) / 'pdfs'\n",
    "pdfs = list(pdf_dir.glob('*.pdf'))\n",
    "if pdfs:\n",
    "    caps = extract_captions_near_match(str(pdfs[0]), 'figure')\n",
    "    print(caps[:1])\n",
    "else:\n",
    "    print('No PDF sample found; skipping demo.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0269eef",
   "metadata": {},
   "source": [
    "## Freshness + Cache Augmented Generation (CAG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ee7713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recency boost demo (uses created_at metadatas)\n",
    "hits = chroma_search('time off policy', n=8)\n",
    "from chapter5.code.retrieval.advanced import Hit as _Hit\n",
    "hits_cls = [_Hit(id=h['id'], text=h['text'], score=h['score'], metadata=h['metadata']) for h in hits]\n",
    "boosted = apply_recency_boost(hits_cls)\n",
    "[(h.id, round(h.score, 3)) for h in boosted[:5]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb5897c",
   "metadata": {},
   "source": [
    "## Prompt profiles + safety checks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d025ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Do contractors accrue PTO? Please cite.'\n",
    "hits = chroma_search('contractors accrue PTO', n=5)\n",
    "ctx = assemble_context([__import__('types').SimpleNamespace(**h) for h in hits], max_chars=1000)\n",
    "if cfg['safety_pre']:\n",
    "    ctx = pre_filters(ctx, user_ctx={'forbidden_sources': []})\n",
    "prompt = build_prompt(cfg['prompt_profile'], ctx, question)\n",
    "# Here we would call an LLM; we keep a stubbed answer for the skeleton\n",
    "answer = 'Contractors do not accrue PTO. [source=enterprise; id=policy_hr]'\n",
    "res = post_validators(answer, policy={'require_citation': True})\n",
    "res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c89d1c6",
   "metadata": {},
   "source": [
    "## Observability traces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e506101",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = TraceRecord(\n",
    "    query_id='demo-001', timestamp=now_ms(), retriever='chroma', routed='auto',\n",
    "    k_before=8, k_after=5, rerank_used=cfg['enable_rerank'], latency_ms=12.3, cost_usd=0.0,\n",
    "    profile=cfg['prompt_profile'], hops=1, citations=1\n",
    ")\n",
    "write_trace_jsonl(TRACES_PATH, rec)\n",
    "print('Trace written to', TRACES_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587a062a",
   "metadata": {},
   "source": [
    "## Mini end-to-end demos\n",
    "- Multi-step question (agent loop)\n",
    "- Hybrid + rerank (ordering change)\n",
    "- Recency-sensitive (newer outranks)\n",
    "- PDF figure/caption question (if sample PDF present)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ch4-env)",
   "language": "python",
   "name": "ch4-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
